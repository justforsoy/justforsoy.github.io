[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "一名终身学习者"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html",
    "href": "posts/常见多重检验控制方法/index.html",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "",
    "text": "m：总检验假设数\nm0：零假设正确的数量，我们无法得知\nm - m0：备择假设正确的数量\nV：假阳性结论数量\nS：真阳性数量\nT：假阴性数量\nU：真阴性数量\nR = V + S：拒绝零假设数量\n\n在m个假设检验中，m0个零假设为真，R是观察到的显著情况的随机变量，S、T、U、V都是不可观测的随机变量。"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html#控制过程",
    "href": "posts/常见多重检验控制方法/index.html#控制过程",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "控制过程",
    "text": "控制过程\n无论检验间是否独立的，\\(\\alpha \\leq m * \\alpha_{sub}\\)都成立。\n利用这个不等式，可以通过Bonferroni correction、Holm–Bonferroni method来对FWER进行控制。"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html#缺点",
    "href": "posts/常见多重检验控制方法/index.html#缺点",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "缺点",
    "text": "缺点\n由于FWER限制过于严格，会导致power相对比较低，容易错失正确的决策机会。\n例如当两个比较是完全相关，多次比较并不会增加假阳性水平，但是矫正后却增加了假阴性。"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html#控制过程-1",
    "href": "posts/常见多重检验控制方法/index.html#控制过程-1",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "控制过程",
    "text": "控制过程\n最常见的是BH过程。\n\nBenjamini–Hochberg procedure(BH step-up procedure)\n\n将多重比较的P值排序，找到满足\\(P_{(k)} \\leq \\frac{k}{m} {\\alpha}\\) 的最大的\\(k\\)；\n拒绝1 ~ k对应的原假设。\n\n检验间独立或者正相关情况下，HB过程控制结果满足： \\[E(Q) \\leq \\frac{m_0}{m}\\alpha \\leq \\alpha \\]\n如何理解？\n\n\n设共有\\(M\\)个假设，\\(M_0\\)个零假设为真，它们的P值为均匀分布，显著水平为\\(h\\)，则期望的假阳性数量为\\(h * M_0\\);\n红线的斜率为\\(\\alpha / M\\)，红线下方最大的P值对应的序号为\\(L\\)；\n拒绝零假设中，期望的假阳性数为\\(h * M_0 = M_0\\frac{\\alpha * L}{M}\\)，因此: $FDR = / M $\n\nHB过程在每次比较独立或者正相关时是有效的。\n\n\nBenjamini–Yekutieli procedure\n此过程在任意情况下，都能控制假阳性。方式为在BH过程中，引入参数c，找到最大\\(k\\)满足\\(P_{(k)} \\le \\frac{k}{m * {c(m)}}\\alpha\\)。 - 如果检验间独立或者正相关，\\(c(m) = 1\\)； - 其他情况，\\(c(m) = \\sum _{i=1}^{m}\\frac{1}{i}\\)。"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html#缺点-1",
    "href": "posts/常见多重检验控制方法/index.html#缺点-1",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "缺点",
    "text": "缺点\n相对于FWER，有较高的假阳性率。"
  },
  {
    "objectID": "posts/常见多重检验控制方法/index.html#控制过程-2",
    "href": "posts/常见多重检验控制方法/index.html#控制过程-2",
    "title": "多重检验控制策略：FWER/FDR/FCR",
    "section": "控制过程",
    "text": "控制过程\n\nBH过程对应的置信区间修正\n\n将多重比较的P值排序，找到满足\\(P_{(k)} \\leq \\frac{k}{m} {\\alpha}\\) 的最大的\\(k\\)；\n拒绝1 ~ k对应的原假设；\n为每个比较中的参数，构建 \\(1 - \\frac{k}{m} {\\alpha}\\) 水平的置信区间。"
  },
  {
    "objectID": "posts/如何对比实验分析方法好坏/index.html",
    "href": "posts/如何对比实验分析方法好坏/index.html",
    "title": "如何评估假设检验的好坏",
    "section": "",
    "text": "在假说检验中，有一种假说称为“零假设”，记为H0 ，假说检验的目的是利用统计的方式，推翻零假设的成立，也就是备择假设（H1）成立。\n若零假设事实上成立，但统计检验的结果拒绝零假设（接受备择假设），这种错误称为第一型错误(错误率记为α)。若零假设事实上不成立，但统计检验的结果不拒绝零假设（接受零假设），这种错误称为第二型错误(错误率记为β)。\n对假设检验的评估，就是检验正确性、功效是否符合预期。"
  },
  {
    "objectID": "posts/如何对比实验分析方法好坏/index.html#正确性检验aa测试",
    "href": "posts/如何对比实验分析方法好坏/index.html#正确性检验aa测试",
    "title": "如何评估假设检验的好坏",
    "section": "1. 正确性检验——AA测试",
    "text": "1. 正确性检验——AA测试\n实际两组样本来自同一总体，没有区别。如果判断为显著差异，就是假阳性错误。进行大量测试（一般大于1000次），将预设α水平与实际频率进行对比评估。"
  },
  {
    "objectID": "posts/如何对比实验分析方法好坏/index.html#功效检验ab测试",
    "href": "posts/如何对比实验分析方法好坏/index.html#功效检验ab测试",
    "title": "如何评估假设检验的好坏",
    "section": "2. 功效检验——AB测试",
    "text": "2. 功效检验——AB测试\n实际两组两本来自有差异的总体，根据已知的差异、预设的α、β可以计算出样本量。从两个总体中随机抽预设样本量带入检验。将实际频率与预设power进行对比。"
  },
  {
    "objectID": "posts/如何对比实验分析方法好坏/index.html#简单仿真",
    "href": "posts/如何对比实验分析方法好坏/index.html#简单仿真",
    "title": "如何评估假设检验的好坏",
    "section": "1. 简单仿真",
    "text": "1. 简单仿真\n直接通过各种科学计算工具可以进行模拟。"
  },
  {
    "objectID": "posts/如何对比实验分析方法好坏/index.html#实际效果仿真",
    "href": "posts/如何对比实验分析方法好坏/index.html#实际效果仿真",
    "title": "如何评估假设检验的好坏",
    "section": "2. 实际效果仿真",
    "text": "2. 实际效果仿真\n通过成熟模拟产生类似于实际情况的数据往往比较复杂，可以通过历史数据进行模拟测试。\nAA测试：比较简单，可以对干净的历史数据进随机抽样测试。实际没有干预，真实情况没有区别的。\nAB测试：可以对历史数据进行挑选出两个有差异的样本，对这两个样本进行重采样。此时可以认为两个样本就是实际总体，易知实际的总体效果。"
  },
  {
    "objectID": "posts/双样本经验贝叶斯检验/index.html",
    "href": "posts/双样本经验贝叶斯检验/index.html",
    "title": "双样本经验贝叶斯检验",
    "section": "",
    "text": "原文《Objective Bayesian Two Sample Hypothesis Testing for Online Controlled Experiments》。"
  },
  {
    "objectID": "posts/双样本经验贝叶斯检验/index.html#定义",
    "href": "posts/双样本经验贝叶斯检验/index.html#定义",
    "title": "双样本经验贝叶斯检验",
    "section": "定义",
    "text": "定义\n$Z = $\n\\(N_E = \\frac{1}{1/N_T + 1/N_C}\\)\n\\(\\sigma^2 / N_E = \\sigma^2_T/N_T + \\sigma^2_C/N_C\\)\n\\(\\delta = \\Delta / \\sigma\\)\n\\(\\mu = E(\\delta)\\)\n则根据定义：\n$ N ( , 1 / N_E ) $\n\\(Z = \\frac{\\delta} {\\sqrt{1 / N_E}}\\)"
  },
  {
    "objectID": "posts/双样本经验贝叶斯检验/index.html#模型设计",
    "href": "posts/双样本经验贝叶斯检验/index.html#模型设计",
    "title": "双样本经验贝叶斯检验",
    "section": "模型设计",
    "text": "模型设计\n\\(H0:\\mu = 0\\)\n\\(H1:\\mu \\sim \\pi(\\mu)\\)\n\\(H1\\)为真概率为\\(p\\)，则\\(H0\\)概率为\\(1 - p\\)\n\\(P(\\delta|H_1) = \\int _Mf_\\mu(\\delta)\\pi(\\mu)d\\mu\\)\n关于\\(\\mu\\)的先验\\(\\pi\\)，采用一个简单的正态分布模型：\\(\\pi(\\mu) =N(0, V^2)\\)，\n1.\\(\\delta = \\mu + \\sqrt{1 / N_E} * \\varepsilon, \\varepsilon \\sim N(0, 1)\\) 2.$ + V * _0, _0 N(0,1) $\n则\\(\\delta = \\sqrt{1 / N_E} * \\varepsilon+ V * \\varepsilon_0, \\varepsilon_0 \\sim N(0,1) , \\varepsilon \\sim N(0, 1)\\)\n可求得\\(E(\\delta) = 0, Var(\\delta) = 1/N_{E} + V^2\\)，则\\((\\delta|\\pi, N_E) \\sim N(0, 1/N_{E} + V^2)\\)"
  },
  {
    "objectID": "posts/双样本经验贝叶斯检验/index.html#先验概率与v的选取",
    "href": "posts/双样本经验贝叶斯检验/index.html#先验概率与v的选取",
    "title": "双样本经验贝叶斯检验",
    "section": "先验概率与V的选取",
    "text": "先验概率与V的选取\n我们并不知道历史实验中，哪些\\(\\delta_i\\)属于\\(H0\\)哪些属于\\(H1\\)。\n如何根据历史实验求解先验？这种依赖不可观察的隐性变量的概率模型，可以使用最大期望算法：\n\n\\(\\frac{P(H1)}{P(H0)} * \\frac{P(\\Delta|H1)}{P(\\Delta|H0)} = \\frac{p}{1 - p} * \\frac{\\phi (\\delta_i; 0, 1/N_{Ei} + V^2)}{\\phi (\\delta_i; 0, 1/N_{Ei})}\\) 求得\\(P_i = P(H1|\\delta_i;p,V)\\)\n\n将\\(p\\)设置为1中得到的\\(P_i\\)的均值\n\n\\(V^2 =\\frac{\\sum{var(\\delta_i) * P_i}}{\\sum{P_i}} - \\frac{\\sum{1 / N_{Ei} * P_i}}{\\sum{P_i}} = \\frac{\\sum{\\delta_i^2 * P_i}}{\\sum{P_i}} - \\frac{\\sum{1 / N_{Ei} * P_i}}{\\sum{P_i}}\\)\n\n重复上述步骤直到\\(p\\)与\\(V\\)收敛，作为它们的最大似然估计。"
  },
  {
    "objectID": "posts/BMCP_11/index.html",
    "href": "posts/BMCP_11/index.html",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "",
    "text": "这一章是前面章节的补充内容，我准备根据阅读进展持续更新原文链接。"
  },
  {
    "objectID": "posts/BMCP_11/index.html#概率",
    "href": "posts/BMCP_11/index.html#概率",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.1 概率",
    "text": "11.1 概率\n一个骰子的例子：\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nfrom scipy import stats\n\nfrom scipy.special import binom, betaln\n\naz.style.use(\"arviz-grayscale\")\nplt.rcParams['figure.dpi'] = 300\n\nnp.random.seed(14067)\n\n\ndef die():\n    outcomes = [1, 2, 3, 4, 5, 6]\n    return np.random.choice(outcomes)\n\n如果我们怀疑骰子不是均匀的。我们应该如何计算概率？科学的方法是收集数据并计算。\n\ndef experiment(N=10):\n    sample = [die() for i in range(N)]\n\n    for i in range(1, 7):\n        print(f\"{i}: {sample.count(i)/N:.2g}\")\n\nexperiment()\n\n1: 0\n2: 0\n3: 0.3\n4: 0\n5: 0.2\n6: 0.5\n\n\n当 N = 10 时，几乎每次结果都不相同；但是当 N 非常大比如10000时，频率就会趋于相等，我们也会认为骰子是均匀的。\n这两个观察结果并不局限于骰子和机会游戏。如果我们每天称体重，我们会得到不同的数值，因为我们的体重与我们吃的食物的量、我们喝的水、我们上厕所的次数、体重秤的精度、我们穿的衣服和体重有关。因此单次测量可能无法代表我们的体重。\n统计学基本上是研究如何处理实际问题中的不确定性的领域，概率论是统计学的理论支柱之一。概率论帮助我们将讨论形式化，就像我们刚刚进行的讨论一样，并将其扩展到骰子之外。这样我们就可以更好地提出和回答与预期结果相关的问题，例如当我们增加实验数量时会发生什么，什么事件比另一个事件有更高的机会等等。\n\n11.1.1. 概率\n概率是一种数学工具，使我们能够以原则性的方式量化不确定性。与其他数学对象和理论一样，它们可以完全从纯数学角度得到证明。为了思考概率，我们可以用数学集合来思考。 样本空间 \\(\\mathcal{X}\\) 是上面实验的结果集合。任意事件 \\(A\\)都是 \\(\\mathcal{X}\\) 的子集。对上面的骰子来说： \\[\\mathcal{X} = \\{1,2,3,4,5,6\\}\\]\n我们可以定义 \\(\\mathcal{X}\\) 的任意事件子集，比如偶数 \\(A = \\{2,4,6\\}\\) ，用数学表示为 \\(P(A)\\) 或 \\(P(A=)\\{2,4,6\\}\\)。\\(P\\) 是一个函数根据事件和概率空间返回一个0到1的数字。\n正如我们刚才看到的，概率有一个明确的数学定义。对于不同的思想流派，我们如何解释概率是不同的。作为贝叶斯学派，我们倾向于将概率解释为不确定性程度。例如，对于公平骰子，掷骰子时得到奇数的概率为 0.5 ，这意味着我们有一半把握会得到一个奇数。或者我们可以将这个数字解释为如果我们无限次掷骰子，一半的时间我们会得到奇数，一半的时间我们会得到偶数。这是频率论的解释，也是思考概率的有用方式。如果您不想无限次地掷骰子，您可以多次掷骰子，并说您大约会获得一半的几率。最后，我们注意到，对于一个公平的骰子，我们期望得到任何单个数字的概率为\\(\\frac{1}{6}\\)，但对于非公平骰子，此概率可能有所不同。结果的等概率只是一个特例。\n如果概率代表不确定性，那很自然可以提问火星的质量为 \\(6.39 \\times 10^{23}\\)kg 的概率，某处在某天下雨的概率等问题。我们说概率的这种定义是认知性的，因为它不是关于现实世界（无论是什么）的属性，而是关于我们对该世界的知识的属性。我们收集数据并分析它，因为我们认为我们可以根据外部信息更新我们的内部知识状态。\n我们必须意识到包含所有数学概念的柏拉图式思想世界与现实世界不同，比如骰子其实有可能卡在中间的可能，在统计建模中我们不断地在这两个世界之间来回切换。\n\n\n11.1.2. 条件概率\n有 \\(A\\) 和 \\(B\\) 两个概率事件且 \\(P(B) &gt; 0\\)，\\(P(A,B)\\) 是 \\(A\\) 和 \\(B\\) 同时发生的概率，也写作 \\(P(A \\cap B)\\)。\n\\(A\\) 在 \\(B\\) 发生的条件下的概率为： \\[P(A \\mid B) = \\frac{P(A, B)}{P(B)}\\]\n条件概率可以理解为样本空间的缩减。如下图所示，\\(A\\) 和 \\(B\\) 都是样本空间 \\(\\mathcal {x}\\) 里的事件，但是 \\(B\\) 发生后样本空间变化为： \n条件概率的概念是统计学的核心，也是思考我们应该如何根据新数据更新我们对事件的了解的核心。涉及某些假设或模型的所有概率都是有条件的。\n\n\n1.1.3. 概率分布\n我们更感兴趣的是找出骰子所有数字的概率列表而不是事件发生的频率。一旦知道这个就可以计算其他量，比如等于或者大于 5 的概率。这个列表称为概率分布。\n理论概率分布有精确的数学公式。概率分布有自己的分类，类型成员由一个或多个参数定义。\n以下是 Beta 分布的例子，通过两个参数可以控制分布平缓或者集中，但是参数约束为必须都为正数： \n\n\n11.1.4. 离散型随机变量和分布\n随机变量是将样本空间映射到实数的函数。比如如果投掷两次均匀的骰子，我们可以得到概率分布:\n\n当一个随机变量 \\(X\\) 的值是有限的 \\(a_1, a_2, ..., a_n\\) 或者 无限但是满足 \\(\\sum_j P(X = a_j) = 1\\)，则成为离散型随机变量。\n其概率分布称为概率质量函数 Probability Mass Function (PMF) 。\\(X\\) 的 PMF 就是 \\(P(X = x)\\ for\\ x \\in \\mathbb{R}\\) 的函数。我们也可以使用累积分布函数 cumulative distribution function (CDF) 定义离散随机变量 。\n\n11.1.4.1. 离散均匀分布 Discrete Uniform Distribution\n该分布将相等的概率分配给从区间 a 到 b 的有限连续整数集。其PMF为： \\[P(X = x) = {\\frac {1}{b - a + 1}} = \\frac{1}{n}\\]\n其中 \\(x\\) 属于区间 \\([a, b]\\)，\\(n = b - a + 1\\) 为区间内整数的个数。\n\n\n11.1.4.2. 二项分布 Binomial Distribution\n伯努利实验得结果只能为 0 或 1 。如果执行 n 次独立的伯努利实验，每一次得到 1 的概率相等为 \\(p\\) ，则其累计得到 1 的次数记为随机变量 \\(X\\)。则 \\(X\\) 服从概率为 \\(p\\) 的 n 重二项分布，记为 \\(X \\sim Bin(n, p)\\)。其 PMF 为： \\[P(X = x) = \\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}\\]\n当 \\(n = 1\\) 时，二项分布又称为伯努利分布 Bernoulli distribution 。\n\n\n11.1.4.3. 泊松分布 Poisson Distribution\n该分布用于描述单位时间（或者单位空间）内随机事件发生的次数。其 PMF 为： \\[P(X = x)  = \\frac{\\mu^{x} e^{-\\mu}}{x!}, x = 0, 1, 2, \\dots\\]\n其中 \\(\\mu\\) 为单位时间（或者单位空间）内随机事件发生的次数的期望值。\n泊松分布的均值和方差相等，即 \\(\\mu = \\sigma^2\\)。当 \\(\\mu\\) 较大时，泊松分布近似于正态分布。\n当伯努利分布的 \\(n\\) 较大，\\(p\\) 较小时，其近似于泊松分布： \\(\\text{Pois}(\\mu=np) \\approx \\text{Bin}(n, p)\\)。因此泊松分布也被称为小数定律或稀有事件定律。\n\n\n\n11.1.5. 连续型随机变量和分布\n另一种随机变量是连续型随机变量，其值可以是区间内的任意实数，但是每个数值对应的概率为 0。\n连续性随机变量的概率分布称为概率密度函数 Probability Density Function (PDF)，它可以大于1。为了得到概率，我们必须对 PDF 进行积分： \\[P(a \\leq X \\leq b) = \\int_a^b pdf(x)dx\\]\n但是注意当我们仅比较 \\(x_1\\) 和 \\(x_2\\) 哪个更可能得到时，我们可以比较\\(\\frac{pdf(x_1)}{pdf(x_2)}\\)。\n离散和连续随机分布，CDF 和 PDF 的关系如下： \n\n11.1.5.1. 均匀分布 Uniform Distribution\n该分布将相等的概率分配给从区间 a 到 b 的连续实数集。其 PDF 为： \\[p(x \\mid a,b)=\\begin{cases} \\frac{1}{b-a} & if a \\le x \\le b \\\\ 0 &  \\text{otherwise} \\end{cases}\\]\n当 \\(a = 0\\) 且 \\(b=1\\) 时成为标准均匀分布。 \n\n\n11.1.5.2. 正态分布 Gaussian or Normal Distribution\n这也许是最知名的分布，因为一方面由于中心极限定律，另一方面是因为数据计算性质良好。\n正态分布有 \\(\\mu\\) 和 \\(\\sigma\\) 两个参数定义，其 PDF 为： \\[ p (x \\mid \\mu, \\sigma) = \\frac {1} {\\sigma \\sqrt {2 \\pi}} e^{-\\frac {(x -\\mu)^2} {2 \\sigma^2}}\\]\n当 \\(\\mu = 0\\) 且 \\(\\sigma = 1\\) 时称为标准正态分布。 \n\n\n11.1.5.3. 学生t分布 Student’s t-distribution\n从历史上看，这种分布用于在样本量较小时估计正态分布总体的平均值。pdf为： \\[p (x \\mid \\nu, \\mu, \\sigma) = \\frac {\\Gamma (\\frac {\\nu + 1} {2})} {\\Gamma (\\frac{\\nu} {2}) \\sqrt {\\pi \\nu} \\sigma} \\left (1+ \\frac{1}{\\nu} \\left (\\frac {x- \\mu} {\\sigma} \\right)^2 \\right)^{-\\frac{\\nu + 1}{2}}\\]\n其中 \\(\\gamma\\) 为伽玛函数，\\(\\nu\\) 为自由度。当 \\(\\nu\\) 趋向于无穷时，学生t分布趋向于正态分布。\n当 \\(\\nu = 1\\) 时，学生t分布退化为柯西分布。它与高斯分布相似，但尾部下降非常缓慢，以至于该分布没有均值和方差。也就是说如果数据来自柯西分布，则平均值的分散度很大，并且这种分散不会随着样本量的增加而减小。出现这种奇怪行为的原因是，像柯西这样的分布由分布的尾部行为主导，这与高斯分布等相反。\n\n\n\n11.1.5.4. 贝塔分布 Beta Distribution\nBeta 分布定义在区间 [0, 1] 内。它可用于对限制在有限区间内的随机变量的行为进行建模，例如对比例或百分比进行建模。 \\[p (x \\mid \\alpha, \\beta) = \\frac {\\Gamma (\\alpha + \\beta)} {\\Gamma(\\alpha) \\Gamma (\\beta)} \\, x^{\\alpha-1} (1 -x)^{\\beta-1}\\]\n当 \\(\\alpha = 1\\) 且 \\(\\beta = 1\\) 时，Beta分布退化为均匀分布。 \n\n\n\n11.1.6. 联合分布、条件分布、边缘分布\n联合分布是多个随机变量的概率分布。联合分布使我们能够描述同一实验中产生的多个随机变量的行为。\n联合 PMF 为： \\[p_{X,Y}(x, y) = P(X = x, Y = y)\\]\n满足： \\[\\sum_x \\sum_y P(X=x, Y=y) = 1\\]\n类似的 CDF 为： \\[F_{X,Y}(x, y) = P(X \\le x, Y \\le y)\\]\n当已知一个变量值是多少时，我们可以计算另一个变量的条件分布。\n基于联合分布计算边缘分布： \\[P(X=x) = \\sum_y P(X=x, Y=y)\\]\n\n对连续型用积分计算： \\[pdf_X(x) = \\int pdf_{X,Y} (x, y)dy\\]\n\n\n\n11.1.7. 概率积分变换 Probability Integral Transform (PIT)\n如果已知随机变量 \\(X\\) 和它的 CDF 函数 \\(F_Z\\)，我们可以定义随机变量 \\(Y\\) ：\\[ Y = F_X(X)\\]\nY的CDF定义为：\\[F_Y(y) = P(Y \\leq y)\\] 则：\\[F_Y(y) = P(F_X(X) \\leq y)\\] 则：\\[F_Y(y) = F_X (F^{-1}_X (y))\\] 最后我们得到：\\[F_Y(y) = y\\]\n\nxs = (np.linspace(0, 20, 200), np.linspace(0, 1, 200), np.linspace(-4, 4, 200))\ndists = (stats.expon(scale=5), stats.beta(0.5, 0.5), stats.norm(0, 1))\n\n\n_, ax = plt.subplots(3, 3)\n\nfor idx, (dist, x) in enumerate(zip(dists, xs)):\n    draws = dist.rvs(100000)\n    data = dist.cdf(draws)\n    # PDF original distribution\n    ax[idx, 0].plot(x, dist.pdf(x))\n    # Empirical CDF\n    ax[idx, 1].plot(np.sort(data), np.linspace(0, 1, len(data)))\n    # Kernel Density Estimation\n    az.plot_kde(data, ax=ax[idx, 2])\n\n\n\n\n\n\n11.1.8. 期望类 Expectations\n期望是总结随机分布质量中心的数值。对于离散型随机变量，期望为：\\[\\mathbb{E}(X) = \\sum_x x P(X = x)\\]\n统计上还经常要评估离散程度。常用方差来表示，它同样是一种期望：\\[\\mathbb{V}(X) = \\mathbb{E}(X - \\mathbb{E}X)^2 = \\mathbb{E}(X^2 ) - (\\mathbb{E}X)^2\\]\n期望的几个性质： \\[\\mathbb{E}(cX) = c\\mathbb{E}(X)\\]\n其中 c 为常数。 \\[\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y)\\]\n无论 X 和 Y 是否独立。\n我们定义 \\(X\\) 的 n 阶距为 \\(\\mathbb{E}(X^n)\\)，其中 \\(n\\) 为正整数。 \\(X\\) 的期望值是一阶距，方差是二阶距。三阶距是偏度，期望为 \\(\\mu\\) 和标准差为 \\(\\sigma\\) 随机变量 \\(X\\) 的三阶距为： \\[\\text{skew}(X) = \\mathbb{E}\\left(\\frac{X -\\mu}{\\sigma}\\right)^3\\]\n将偏斜计算为标准化量（即减去平均值并除以标准差）的原因是为了使偏斜独立于 \\(X\\)。\n举例：Beta(2,2) 偏度为0，代表分布是对称的；Beta(2,5) 偏度大于0，；Beta(5,2) 偏度小于0。\n\nxs = (np.linspace(0, 1, 200), np.linspace(0, 1, 200), np.linspace(0, 1, 200))\ndists = (stats.beta(2,2), stats.beta(2, 5), stats.beta(5, 2))\n\n\n_, ax = plt.subplots(1, 3, figsize = (12, 4))\n\nfor idx, (dist, x) in enumerate(zip(dists, xs)):\n    draws = dist.rvs(100000)\n    data = dist.cdf(draws)\n    ax[idx].plot(x, dist.pdf(x))\n\n\n\n\n四阶距是峰度 kurtosis，描述尾部的行为： \\[\\text{Kurtosis}(X) = \\mathbb{E}\\left(\\frac{X -\\mu}{\\sigma}\\right)^4 - 3 \\]\n公式中减3的是为了让高斯分布的峰度为0，因此公式表达的是本分布的峰度与高斯分布的峰度的差异。\n\n\n11.1.9. 转换\n将随便变量 \\(X\\) 带入函数 \\(g\\)，得到新的随机变量 \\(Y = g(X)\\)。如果我们知道 \\(X\\) 的分布函数，如何求出 \\(Y\\) 的分布呢？\n最简单的方法是从 \\(X\\) 抽样转换并绘制分布图。还有其它方法，其中之一是变量变换方法 change of variables。\n如果 \\(X\\) 是连续型随机变量，而 \\(g\\) 是单调函数，那么 \\(Y\\) 的 PDF 为：\\[p_Y(y) = p_X(x) \\left| \\frac{dx}{dy} \\right|\\]\n推导如下： \\[\n\\begin{split}\n   F_Y(y) =& P(Y \\le y) \\\\\n          =& P(g(X) \\le y) \\\\\n          =& P(X \\le g^{-1}(y)) \\\\\n          =& F_X(g^{-1}(y)) \\\\\n          =& F_X(x) \\\\\n\\end{split}\n\\]\n然后应用链式法则： \\[p_Y(y) = p_X(x) \\frac{dx}{dy}\\]\n多元随机变量也类似，省略。\n\n\n11.1.10. 极限\n大数定律和中心极限定律是最知名的两条定律。\n\n11.1.10.1. 大数定律 Law of Large Numbers (LLN)\n大数定律告诉我们，随着样本数量的增加，独立同分布随机变量的样本均值收敛到随机变量的期望值。\n注意：这对于某些分布（例如柯西分布（没有均值或有限方差））而言不成立。\n\n\n11.1.10.2. 中心极限定律 Central Limit Theorem (CLT)\n中心极限定理告诉我们，随着样本数量的增加，独立同分布随机变量的样本均值的分布收敛到正态分布。 \\[\\bar X_n \\dot \\sim \\mathcal{N} \\left (\\mu, \\frac{\\sigma^2} {n} \\right)\\]\n满足中心极限定理，必须满足以下假设：\n\n这些值是独立采样的\n每个值都来自相同的分布\n分布的平均值和标准差必须是有限的\n\n注意：标准1和2可以放宽一些，我们仍然会得到近似高斯分布，但无法摆脱标准3。对于没有定义均值或方差的分布（例如柯西分布），该定理不适用。柯西分布的样本均值仍然服从柯西分布。\n\n\n\n11.1.11. 马尔科夫链 Markov Chains\n马尔科夫链是一种随机过程，未来状态仅取决于当前状态：\\[P(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1} , \\dots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i)\\]\n马尔可夫链可视化的一种有效的方法是想象你或某个物体在空间中移动。如果空间有限，这个类比就更容易理解。\n例如像跳棋一样移动方板上的棋子或访问不同城市的销售人员。这种情况下可以提出以下问题：访问一个州（棋盘上的特定方块、城市等）的可能性有多大？如果我们不断从一个州转移到另一个州，从长远来看我们将在每个州花费多少时间？\n以下是四个马尔科夫链的例子： \n研究马尔科夫链的一种便捷方法是收集每一步的转移概率并将其组合成转移矩阵。对于上面的a例子转移矩阵为： \\[\\begin{bmatrix}\n0.9 & 0.1 \\\\\n0.8 & 0.2\n\\end{bmatrix}\\]\n而b例子转移矩阵为： \\[\\begin{bmatrix}\n0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n2 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n3 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n4 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n5 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{bmatrix}\\]\n矩阵的第 i 行第 j 列的元素是从状态 i 转移到状态 j 的概率。\n在研究马尔可夫链时，我们有理由定义单个状态的属性以及整个链的属性。例如，如果一个链反复返回到一个状态，我们称该状态为常返状态。相反，一个瞬态状态是链最终会永远离开的状态，例如在上图的例子(d)，除了0或N的所有状态都是瞬态的。此外，我们也可以称一个链为不可约的，如果它可以在有限步骤内从任何状态到达任何其他状态。例如例子(c)，它不是不可约的，因为状态1、2和3与状态A和B是断开的。\n理解马尔可夫链的长期行为是有意义的。前面提到的常返和瞬态的概念对于理解这种长期运行行为非常重要。如果我们有一个包含瞬态和常返状态的链，该链可能会在瞬态状态中花费时间，但最终会在常返状态中花费所有的时间。我们可以自然地提问，链将在每个状态中停留多长时间。答案是通过找到链的稳态分布 stationary distribution 。\n对有限状态空间的马尔可夫链，稳态分布 \\(s\\) 满足 \\(sT = s\\)。也就是对本分布来说，不受状态转移矩阵 \\(T\\) 的变换影响。\n有趣的是在一定条件下，马尔可夫链的稳态分布是唯一的。这些条件是：链必须是不可约的和正常的。\n比如上图例子中，(d) 的稳定分布不唯一，分别是 \\(s_0=(1, 0, \\dots , 0)\\) 和 \\(s_N=(0, 0, \\dots , 1)\\)，它代表了赌徒A或B输光了所有的钱；而 (b) 的稳定分布唯一，\\(s=(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\\)\n如果概率质量函数满足可逆性条件（也称为详细平衡），即对所有的i和j都有 \\(s_i t_{ij} = s_j t_{ji}\\)，可以保证 \\(s\\) 这是马尔可夫链转移矩阵 \\(T = t_{ij}\\) 的稳态分布。这样的马尔可夫链被称为可逆的。在推理方法一节中，我们将使用这个属性来说明为什么Metropolis-Hastings能够保证在渐进意义上有效。\n马尔科夫链满足中心极限定律，但是要除以有效样本量 effective sample size (ESS)。"
  },
  {
    "objectID": "posts/BMCP_11/index.html#熵-entropy",
    "href": "posts/BMCP_11/index.html#熵-entropy",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.2. 熵 Entropy",
    "text": "11.2. 熵 Entropy\n在维也纳的Zentralfriedhof，我们可以找到路德维希·玻尔兹曼的墓碑。他的墓碑上刻着 \\(S = k \\log W\\)，这是一种美妙的方式，表明热力学第二定律是概率定律的结果。玻尔兹曼通过这个等式为现代物理学的一个支柱 —— 统计力学的发展做出了贡献。统计力学描述了如温度这样的宏观观测如何与微观的分子世界相关。想象一下一杯水，我们的感官感知到的基本上是杯子里大量水分子的平均行为。水分子排列数量会与温度相关。随着我们降低温度，可能的排列会越来越少，直到仅有找一种。此时温度为达到了0开尔文，这是宇宙中可能的最低温度！如果我们增加问题，我们会发现分子有越来越多的排列方式。\n\n当温度为0开尔文时，水分子的排列方式只能有一种，状态是确定性的；当温度越来越高时，水分子的排列可能越来越多，状态越来越不确定。由此，我们可以将熵视为不确定性的衡量方式。\n熵的概念不仅适用于分子。它还可以应用于像素的排列、文本中的字符、音符、袜子、酵母面包中的气泡等等。熵如此灵活的原因是它量化了对象的排列， 这一底层分布的属性。分布的熵越大，该分布的信息量就越少。“42”比“42±5”更确定，而后者比“任意实数”更确定。熵可以将这些定性观察转化为定量数字。\n熵的概念适用于连续分布和离散分布，但使用离散状态更容易思考它，我们将在本节的其余部分看到一些示例。但请记住，相同的概念适用于连续情况。\n对有 \\(n\\) 种可能得分布 \\(p\\) 来说，熵的定义是： \\[H(p) = - \\mathbb{E}[\\log{p}] = -\\sum_{i}^n p_i \\log{p_i}\\]\n这只是 \\(S = k \\log W\\) 的另一种写法。使用 \\(H\\) 替换掉 \\(S\\) 并且设置 \\(k = 1\\)，而玻尔兹曼的 \\(W\\) 是所有可能不同结果的总数： \\[W = \\frac{N!}{n_1!n_2! \\cdots n_t!}\\]\n可以理解为投掷一个 \\(t\\) 面的骰子 \\(N\\) 次。当 \\(N\\) 特别大时，可以用斯特林近似 \\(x! \\approx (\\frac{x}{e})^x\\)。 \\[W =  \\frac{N^N}{n_1^{n_1} n_2^{n_2} \\cdots n_t^{n_t}} e^{(n_1 n_2 \\cdots n_t-N)}\\]\n由于 \\(p_i = \\frac{n_i}{N}\\) \\[W = \\frac{1}{p_1^{n_1} p_2^{n_2} \\cdots p_t^{n_t}}\\]\n最终转换为 \\[\\log W = -\\sum_{i}^n p_i \\log{p_i}\\]\n下面用python演示如何计算熵\n\nx = range(0, 26)\nq_pmf = stats.binom(10, 0.75).pmf(x)\nqu_pmf = stats.randint(0, np.max(np.nonzero(q_pmf))+1).pmf(x)\nr_pmf = (q_pmf + np.roll(q_pmf, 12)) / 2\nru_pmf = stats.randint(0, np.max(np.nonzero(r_pmf))+1).pmf(x)\ns_pmf = (q_pmf + np.roll(q_pmf, 15)) / 2\nsu_pmf = (qu_pmf + np.roll(qu_pmf, 15)) / 2\n\n_, ax = plt.subplots(3, 2, figsize=(12, 5), sharex=True, sharey=True,\n                     constrained_layout=True)\nax = np.ravel(ax)\n\nzipped = zip([q_pmf, qu_pmf, r_pmf, ru_pmf, s_pmf, su_pmf],\n             [\"q\", \"qu\", \"r\", \"ru\", \"s\", \"su\"])\nfor idx, (dist, label) in enumerate(zipped):\n    ax[idx].vlines(x, 0, dist, label=f\"H = {stats.entropy(dist):.2f}\")\n    ax[idx].set_title(label)\n    ax[idx].legend(loc=1, handlelength=0)\n\n\n\n\n以上是 6 个分布及对应熵。\n\n最集中向中心的且离散度最小的是 \\(q\\) ， 它的熵最小；\n\\(qu\\) 同样有11种可能但是均匀分布，熵比前者要大，且11种可能得分布中没有比均匀分布更大熵的分布；\n\\(r\\) 是 \\(qu\\) 继续加工出来的，比 \\(qu\\) 变换过来的，有更多种取值可能，分布更离散，熵也更大；\n\\(ru\\) 与 \\(r\\) 取值空间相同的均分分布，熵继续增加；\n\\(s\\) 与 \\(r\\) 类似，但是两峰间距离更远，熵与 \\(r\\) 相同；\n\\(su\\) 是 \\(qu\\) 加工的，它虽然更离散但是取值可能性比 \\(qu\\) 少，熵小于 \\(qu\\)"
  },
  {
    "objectID": "posts/BMCP_11/index.html#kl散度-kullback-leibler-divergence",
    "href": "posts/BMCP_11/index.html#kl散度-kullback-leibler-divergence",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.3. KL散度 Kullback-Leibler Divergence",
    "text": "11.3. KL散度 Kullback-Leibler Divergence\n在统计中常常用一个分布 \\(q\\) 去代表另一个分布 \\(p\\)，比如 \\(p\\) 未知但是可以用 \\(q\\) 近似，后者 \\(p\\) 比较难计算时。此时产生一个问题，\\(q\\) 代替 \\(p\\) 损失了多少信息，或者说引入了多少额外的不确定性。\n根据熵的定义，我们可以通过计算 \\(log(p)\\) 和 \\(log(q)\\) 的差异来衡量。这被称为 KL散度： \\[\\mathbb{KL}(p \\parallel q) = \\mathbb{E}_p[\\log{p}-\\log{q}]\\]\n\\(\\mathbb{KL}(p \\parallel q)\\) 给出了 \\(q\\) 代替 \\(p\\) 时的对数概率平均差异。因为事件实际是以 \\(p\\) 的概率发生的，所以对离散分布来说： \\[\\mathbb{KL}(p \\parallel q) = \\sum_{i}^n p_i (\\log{p_i} - \\log{q_i})\\]\n使用对数计算的性质，可以转为更常见的表示方法： \\[\\mathbb{KL}(p \\parallel q)  = \\sum_{i}^n p_i \\log{\\frac{p_i}{q_i}}\\]\n也可以转为： \\[\\mathbb{KL}(p \\parallel q) = - \\sum_{i}^n p_i (\\log{q_i} - \\log{p_i})\\]\n将其展开可以得到： \\[\\mathbb{KL}(p \\parallel q) =  \\overbrace{-\\sum_{i}^n p_i \\log{q_i}}^{H(p, q)} -  \\overbrace{\\left(-\\sum_{i}^n p_i \\log{p_i}\\right)}^{H(p)}\\]\n其中 \\(H(p)\\) 代表 \\(p\\) 分布的熵，\\(H(p, q) = - \\mathbb{E}_p[\\log{q}]\\) 有点像计算 \\(q\\) 的熵但是每种可能出现的概率是 \\(p\\)。\n由上可以得到： \\[H(p, q) = H(p) + D_\\text{KL}(p \\parallel q)\\]\n这表明 KL 散度可以有效地解释为 \\(q\\) 代替 \\(p\\) 增加的熵。\n为了更加指标，我们将计算 KL 散度的一些值并绘制它们，继续使用熵一节中的例子：\n\ndists = [q_pmf, qu_pmf, r_pmf, ru_pmf, s_pmf, su_pmf]\nnames = [\"q\", \"qu\", \"r\", \"ru\", \"s\", \"su\"]\n\nfig, ax = plt.subplots()\nKL_matrix = np.zeros((6, 6))\nfor i, dist_i in enumerate(dists):\n    for j, dist_j in enumerate(dists):\n        KL_matrix[i, j] = stats.entropy(dist_i, dist_j)\n\nax.set_xticks(np.arange(len(names)))\nax.set_yticks(np.arange(len(names)))\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nplt.set_cmap(\"viridis\")\ncmap = plt.cm.get_cmap()\ncmap.set_bad('w', 0.3)\nim = ax.imshow(KL_matrix)\nfig.colorbar(im, extend=\"max\");\n\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_95623/3045023848.py:15: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = plt.cm.get_cmap()\n\n\n\n\n\n首先上图不是对称的，因为 \\(\\mathbb{KL}(p \\parallel q)\\) 并不一定与 \\(\\mathbb{KL}(q \\parallel p)\\) 相等；其次有一些空白区域，它们代表无穷大。KL 散度的定义使用中有以下约定： \\[0 \\log \\frac{0}{0} = 0, \\quad\n0 \\log \\frac{0}{q(\\boldsymbol{x})} = 0, \\quad\np(\\boldsymbol{x}) \\log \\frac{p(\\boldsymbol{x})}{0} = \\infty\\]\n我们可以基于 KL 散度，在计算预期对数逐点预测密度时使用 log-score 。假设我们有 \\(k\\) 个模型 \\(\\{q_{M_1}, q_{M_2}, \\cdots q_{M_k}\\}\\)，并且假设我们知道真实的模型 \\(M_0\\)，则我们可以计算： \\[\n\\begin{split}\n        \\mathbb{KL}(p_{M_0} \\parallel q_{M_1}) =&\\; \\mathbb{E}[\\log{p_{M_0}}] - \\mathbb{E}[\\log{q_{M_1}}] \\\\\n        \\mathbb{KL}(p_{M_0} \\parallel q_{M_2}) =&\\; \\mathbb{E}[\\log{p_{M_0}}] - \\mathbb{E}[\\log{q_{M_2}}] \\\\\n        &\\cdots \\\\\n        \\mathbb{KL}(p_{M_0} \\parallel q_{M_k}) =&\\; \\mathbb{E}[\\log{p_{M_0}}] - \\mathbb{E}[\\log{q_{M_k}}]\n    \\end{split}\n\\]\n以上似乎没有用，因为显示中我们不知道 \\(M_0\\)。但是由于所有比较中的 \\(p_{M_0}\\) 都是相同的，所以基于KL散度构建一个排名等同于基于 log-score 构建一个排名。这是一个技巧，它意味着我们可以通过比较 log-score 来间接比较KL散度，即使我们可能无法直接计算KL散度。这在模型选择或比较中是非常有用的，因为 log-score 通常比KL散度更容易计算。"
  },
  {
    "objectID": "posts/BMCP_11/index.html#信息准则-information-criterion",
    "href": "posts/BMCP_11/index.html#信息准则-information-criterion",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.4. 信息准则 Information Criterion",
    "text": "11.4. 信息准则 Information Criterion\n信息准则是统计模型预测准确性的度量。它考虑模型对数据的拟合程度，并按模型的复杂性进行惩罚。有很多种信息准则，其中非贝叶斯领域最出名的是赤池信息准则 Akaike Information Criterion (AIC)。它由两部分组成，第一部分是模型对数据的拟合程度，第二部分是模型的复杂度： \\[AIC = -2 \\sum_{i}^{n} \\log p(y_i \\mid \\hat{\\theta}_{mle}) + 2 p_{AIC}\\]\n其中 \\(\\hat{\\theta}_{mle}\\) 是参数 \\(\\theta\\) 的最大似然估计，\\(p_{AIC}\\) 是模型的参数数量。\nAIC 在非贝叶斯环境中相当流行，但通用性不足以处理贝叶斯模型。它不使用完整的后验分布，因此丢弃了潜在有用的信息。一般来说，当我们从平坦先验转向弱信息或信息丰富的先验时，或如果我们在模型中添加更多结构（例如分层模型），AIC 的表现会越来越差。AIC 假设后验可以用高斯分布很好地表示（至少渐进地），但是对于许多模型来说情况并非如此，包括分层模型、混合模型、神经网络等。总之，我们希望使用一些更好的模型备择方案。\n广泛适用的信息准则 Widely applicable Information Crieria (WAIC) 可以被视为是 AIC 的贝叶斯版本。同样有两部分组成，最大的不同是第一部分使用完整的后验分布： \\[WAIC =  \\sum_i^n \\log \\left(\\frac{1}{s} \\sum_{j}^S p(y_i \\mid \\boldsymbol{\\theta}^j) \\right) \\; - \\sum_i^n  \\left(\\mathop{\\mathbb{V}}_{j}^s \\log p(Y_i \\mid \\boldsymbol{\\theta}^j) \\right)\\]\n其中第一项是逐点计算的对数似然，通过 \\(s\\) 次后验分布抽样参数来计算以保持不确定性，它是现实中计算 ELPD 的可行方法。\n第二项有些奇怪，它是 \\(s\\) 次后验分布抽样参数下的方差。抽样对后验细节阅敏感，惩罚就越大。我们还可以从另一个等价的角度来看这一点；更灵活的模型是能够有效容纳更多数据集的模型。例如，包含直线但也包含向上曲线的模型比仅允许直线的模型更灵活；因此，在后面的模型上通过后验评估的那些观察值的对数似然平均而言将具有更高的方差。如果更灵活的模型无法通过更高的估计 ELPD 来补偿这种损失，那么更简单的模型将被我们列为更好的选择。因此，方程中的方差项通过惩罚过于复杂的模型来防止过度拟合，并且可以将其宽松地解释为 AIC 中的参数的有效数量。\nAIC 和 WAIC 都没有试图衡量模型是否真实，它们只是比较替代模型的相对衡量标准。从贝叶斯的角度来看，先验是模型的一部分，但 WAIC 是根据后验进行评估的，并且先验效果只是通过影响所得后验的方式来间接考虑。还有其他信息标准，例如 BIC 和 WBIC 试图回答这个问题，并且可以被视为边际可能性的近似值，但我们不会在本书中讨论它们。"
  },
  {
    "objectID": "posts/BMCP_11/index.html#深入loo",
    "href": "posts/BMCP_11/index.html#深入loo",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.5. 深入LOO",
    "text": "11.5. 深入LOO\n正如本书中交叉验证和 LOO 一节中所讨论的，我们使用术语 LOO 来指代一种近似留一交叉验证 (LOO-CV) 的特定方法，称为帕累托平滑重要性采样留一次交叉验证 ( PSIS-LOO-CV)。\nLOO是WAIC的替代方案，实际上可以证明它们渐近收敛到相同的数值。而且 LOO 为从业者带来了两个重要的优势。它在有限样本设置中更加稳健，并且在计算过程中提供有用的诊断。\n在 LOO-CV 下新数据集的预期对数逐点预测密度为： \\[\n\\text{ELPD}_\\text{LOO-CV} = \\sum_{i=1}^{n} \\log\n    \\int \\ p(y_i \\mid \\boldsymbol{\\theta}) \\; p(\\boldsymbol{\\theta} \\mid y_{-i}) d\\boldsymbol{\\theta}\n\\]\n其中 \\(y_{-i}\\) 代表排除 \\(i\\) 后的数据集。\n现实中无法获取 \\(\\theta\\)，所以我们使用后验分布的抽样来近似： \\[\\sum_{i}^{n} \\log\n    \\left(\\frac{1}{s}\\sum_j^s \\ p(y_i \\mid \\boldsymbol{\\theta_{-i}^j}) \\right)\\]\n上述公式非常像 WAIC 中的第一项，只是每次排除一个样本，因此它不需要惩罚项。\n以上公式计算消耗非常大，好在 \\(n\\) 次观测是条件独立的，可以用以下近似： \\[\\text{ELPD}_{psis-loo} = \\sum_i^n \\log \\sum_j^s w_i^j p(y_i \\mid \\boldsymbol{\\theta}^j)\\]\n其中 \\(w\\) 是归一化权重向量。\n计算 \\(w\\) 需要通过重要性采样（Importance Sampling），它是一种用于估计目标分布属性的技术。如果我们有随机变量 \\(X\\) 的样本，而且可以按每个点计算 \\(f(x)\\) 和 \\(g(x)\\)，则重要性权重为： \\[w_i = \\frac{f(x_i)}{g(x_i)}\\]\n重要性采样（Importance Sampling）的计算步骤：\n\n从分布 \\(g\\) 中抽取 \\(N\\) 个样本 \\(x_i\\)：这是从我们选择的易于采样的分布（也称为提议分布）中抽取样本的步骤；\n计算每个样本的概率 \\(g(x_i)\\)：这是计算每个样本在提议分布 \\(g\\) 下的概率；\n在 \\(N\\) 个样本 \\(x_i\\) 上评估函数 \\(f\\)：这是计算目标函数 \\(f\\) 在每个样本点上的值；\n返回 \\(N\\) 个样本对应的 \\((x_i, w_i)\\)，带入需要的评估器中。\n\n下图显示了使用两个不同的提案分布来近似相同目标分布（虚线）的示例。在第一行，提案比目标分布更宽。在第二行，提案比目标分布更窄。正如我们所看到的，第一种情况的近似值更好。这是重要性抽样的一般特征。 \n回到 LOO，我们计算的分布是后验分布。为了评估模型，我们需要来自留一后验分布的样本，因此我们要计算的重要性权重是： \\[w_i^j = \\frac{p(\\theta^j \\mid y{-i} )}{p(\\theta^j \\mid y)} \\propto \\frac{1}{p(y_i \\mid \\theta^j)}\\]\n注意后验可能比 leave-one-out分布 有更细的尾部，正如我们在上图看到的那样，这可能会导致估计结果很差。从数学上讲，问题在于重要性权重可能具有很高甚至无限的方差。为了控制方差，LOO 应用了平滑过程，其中涉及用估计的帕累托分布中的值替换最大的重要性权重。而且要注意估计参数 \\(\\hat{\\kappa}\\) 检测极具影响力的观察结果，即当被排除时对预测分布有很大影响的观察结果。一般来说大的 \\(\\hat{\\kappa}\\) 代表数据或者模型有问题，特别是当 \\(\\hat{\\kappa} \\ge 0.7\\) 时。"
  },
  {
    "objectID": "posts/BMCP_11/index.html#杰弗里斯先验的推导",
    "href": "posts/BMCP_11/index.html#杰弗里斯先验的推导",
    "title": "【Bayesian Modeling and Computation in Python】11.相关主题",
    "section": "11.6. 杰弗里斯先验的推导",
    "text": "11.6. 杰弗里斯先验的推导\n单变量下 JP 的定义为： \\[p(\\theta) = \\sqrt{I(\\theta)}\\]\n其中 \\(I(\\theta)\\) 是 Fisher 信息： \\[I(\\theta) = - \\mathbb{E_{Y}}\\left[\\frac{d^2}{d\\theta^2} \\log p(Y \\mid \\theta)\\right]\\]\n\n11.6.1. 二项分布参数的杰弗里斯先验\n二项分布可以表示为： \\[p(Y \\mid \\theta) \\propto \\theta^{y} (1-\\theta)^{n-y}\\]\n其中 \\(y\\) 是成功次数，\\(n\\) 是总次数。\n为了计算 Fisher 信息，我们需要计算对数似然： \\[\\ell = \\log(p(Y \\mid \\theta)) \\propto y \\log(\\theta) + (n-y) \\log(1-\\theta)\\]\n计算其二阶导数： \\[\n\\begin{aligned}\n\\begin{split}\n\\frac{d \\ell}{d\\theta} &= \\frac{y}{\\theta} - \\frac{n-y}{1-\\theta} \\\\\n\\frac{d^{2} \\ell}{d \\theta^{2}} &= -\\frac{y}{\\theta^{2}} - \\frac{n-y}{ (1-\\theta)^{2}}\n\\end{split}\\end{aligned}\n\\]\n将其带入 Fisher 信息公式： \\[I(\\theta) = - \\mathbb{E}_{Y}\\left[-\\frac{y}{\\theta^{2}} + \\frac{n-y}{ (1-\\theta)^{2}} \\right]\\]\n由于 \\(\\mathbb{E}[y] = n\\theta\\)，可写成： \\[I(\\theta)= \\frac{n\\theta}{\\theta^{2}} - \\frac{n - n \\theta}{(1-\\theta)^{2}}\\]\n化简得： \\[I(\\theta)= \\frac{n}{\\theta} - \\frac{n (1 -\\theta)}{(1-\\theta)^{2}} = \\frac{n}{\\theta} - \\frac{n}{(1-\\theta)}\\]\n将分母通分得： \\[I(\\theta)= \\frac{n(1-\\theta) - n\\theta}{\\theta(1-\\theta)} = \\frac{n}{\\theta(1-\\theta)}\\]\n如果忽略常数 \\(n\\)，则有： \\[I(\\theta) \\propto \\frac{1}{\\theta (1-\\theta)} = \\theta^{-1} (1-\\theta)^{-1}\\]\n将其带入 JP 公式，最终得到结果： \\[p(\\theta) \\propto \\sqrt{I(\\theta)} \\propto \\sqrt{\\theta^{-1} (1-\\theta)^{-1}} = \\theta^{-1/2} (1-\\theta)^{-1/2}\\]\n\n\n11.6.2. 二项分布比例 \\(\\kappa\\) 的杰弗里斯先验\n替换 \\(\\theta = \\frac{\\kappa}{\\kappa + 1}\\)： \\[p(Y \\mid \\kappa) \\propto \\left({\\frac{\\kappa}{\\kappa + 1}}\\right)^{y} \\left(1-{\\frac{\\kappa}{\\kappa +1}}\\right)^{n-y}\\]\n可以写为： \\[p(Y \\mid \\kappa) \\propto \\kappa^y (\\kappa + 1)^{-y} (\\kappa +1)^{-n + y}\\]\n整理后： \\[p(Y \\mid \\kappa) \\propto \\kappa^y (\\kappa + 1)^{-n}\\]\n取对数： \\[\\ell = \\log(p(Y \\mid \\kappa)) \\propto y \\log{\\kappa} -n \\log{(\\kappa + 1)}\\]\n计算二阶导数： \\[\n\\begin{aligned}\n\\begin{split}\n\\frac{d \\ell}{d{\\kappa}} &= \\frac{y}{\\kappa} - \\frac{n}{\\kappa + 1} \\\\\n\\frac{d^2 \\ell}{d {\\kappa^2}} &= -\\frac{y}{\\kappa^2} + \\frac{n}{(\\kappa+1)^2}\n\\end{split}\\end{aligned}\n\\]\n则： \\[I(\\kappa) = - \\mathbb{E}_Y\\left[-\\frac{y}{\\kappa^2} + \\frac{n}{ (\\kappa+1)^2} \\right]\\]\n由于 \\(\\mathbb{E}[y] = n\\frac{\\kappa}{\\kappa + 1}\\)，可写成： \\[I(\\kappa) = \\frac{n}{\\kappa (\\kappa + 1)} - \\frac{n}{(\\kappa + 1)^2}\\]\n通分得到： \\[I(\\kappa) = \\frac{n(\\kappa + 1) - n\\kappa}{\\kappa(\\kappa + 1)^2} = \\frac{n}{\\kappa(\\kappa + 1)^2}\\]\n最终得到： \\[p(\\kappa) \\propto \\sqrt{I(\\kappa)} \\propto \\sqrt{\\frac{1}{\\kappa(\\kappa + 1)^2}} = \\kappa^{-1/2} (\\kappa + 1)^{-1}\\]\n\n\n11.6.3. 二项分布似然的杰弗里斯后验\n结合 \\(\\theta\\) 的杰弗里斯先验和二项分布似然： \\[p(\\theta \\mid Y) \\propto  \\theta^{y} (1-\\theta)^{n-y} \\theta^{-0.5} (1-\\theta)^{-0.5} = \\theta^{y-0.5} (1-\\theta)^{n-y-0.5}\\]\n类似的结合 \\(\\kappa\\) 的杰弗里斯先验和二项分布似然： \\[p(\\kappa \\mid Y) \\propto \\kappa^y (\\kappa + 1)^{-n}  \\kappa^{-0.5} (1 + \\kappa)^{-1} = \\kappa^{(y-0.5)}  (\\kappa + 1)^{(-n-1)})\\]"
  },
  {
    "objectID": "posts/sqr/index.html",
    "href": "posts/sqr/index.html",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "",
    "text": "为了加速实验迭代，需要兼顾：速度、质量、风险，Linkin提出了SQR框架：SQR: Balancing Speed, Qality and Risk in Online Experiments。"
  },
  {
    "objectID": "posts/sqr/index.html#关于实验放量的三个误区",
    "href": "posts/sqr/index.html#关于实验放量的三个误区",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "1.1. 关于实验放量的三个误区",
    "text": "1.1. 关于实验放量的三个误区\n\n误区#1：让实验一直跑直到显著\n\n多重检验导致的假阳性问题；\n样本量随时间增加速度越来越慢。 \n\n\n\n误区#2: 小流量实验的消耗很低\n长期的小流量实验消耗很大：\n\n机会消耗：让创新变少变慢\n平台消耗：运行实验数更多\n商业消耗：命中用户长期处于较差体验导致流失\n\n\n\n误区#3：10%流量就够了\n许多实验都是面向用户子集，而且付费相关的指标需要更大量的用户"
  },
  {
    "objectID": "posts/sqr/index.html#sqr原则",
    "href": "posts/sqr/index.html#sqr原则",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "2.2. SQR原则",
    "text": "2.2. SQR原则\n做实验的原因：定量测量、减少风险、学习用户\nMaximun Power Ramp(MPR)：最大power的放量\n\n\n原则#1：风险可接受，尽快放量到MPR\n风险影响因素：\n\n先验信念\n采样数据结果\n转换率：实验影响的用户比率\n\n\n\n原则#2：MPR阶段等待足够的时间\n至少一周，存在burn-in效果时更久\n\n\n原则#3：post-MPR阶段尽快结束\n\n\n原则#4：仅在研究目标明确下才进行长期观察实验"
  },
  {
    "objectID": "posts/sqr/index.html#mpr前放量",
    "href": "posts/sqr/index.html#mpr前放量",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "2.1. MPR前放量",
    "text": "2.1. MPR前放量\n在风险可承受之内，尽快放量到MPR阶段。\n\n2.1.1. 风险和可承受风险\n将流量放至q的风险为(其实就是treatment对大盘影响的估计)：\n\\[R(q) = |\\delta| * g(r) * h(q)\\]\n其中： \\[\\delta = \\frac{treatment mean - control mean}{control mean}\\]\n是影响效果， \\[g(r) = \\begin{cases}\n& r, r &gt;= r_0 \\\\\n& r_0, r &lt; r_0\n\\end{cases}\\]\n是左截断的触发率， \\[h(r) = \\begin{cases}\n& q, q &gt;= q_0 \\\\\n& q_0, q &lt; q_0\n\\end{cases}\n\\]\n是左截断的放量比。\n如果满足： \\[R(q) &lt;= \\tau\\]\n就认为风险是可承受的。\n关于\\(\\tau\\)的选择，不同指标选择不同（todo）\n\n\n2.1.2. 假设检验\n\\(Q = \\{q_1, q_2, ...\\}\\)为可能的放量比，在linkedIn一般{1%, 5%, 10%, 25%, 50%}。\n假设模板： \\[H_0^q : R(q) &lt;= \\tau \\\\\nH_0^q : R(q) &gt; \\tau\\]\n\n\n2.1.3. 贯序检验\n使用Generalized Sequential Probability Ratio Test (GSPRT)，任意时刻t的检验统计量： \\[L_t(H_k^q) = \\frac{\\sup_{H^q_k}\\pi_kf_{k}^{t}(X^t)}{\\sum_{j=0}^1\\sup_{H^q_j}\\pi_jf_{j}^{t}(X^t)}, k=0,1\\]\n其中\\(f_{k}^{t}\\)是似然函数，\\(X^t = (X^t_1,X^t_2,...)\\)是t时刻用户级别的指标值，\\(\\pi_k\\)是\\(H_k\\)的先验概率。\n在GSPRT下，\\(H^q_k\\)被接受的条件为： \\[L_t(H^q_k) &gt; \\frac{1}{1 + A_k}\\]\n由于后验概率\\(L_t(H^q_0) + L_t(H^q_1) = 1\\)，所以要选择\\(0 &lt; A_k &lt; 1\\)以保证最多有一个假设被接受。\n\n基于大数定理和终极极限定理，组间均值差\\(\\Delta\\)的分布近似正态，方程转化为（此处方法用的是贝叶斯）： \\[L_t(H_k^q) = \\frac{\\sup_{H^q_k}\\pi_kexp(-\\frac{(\\Delta - \\delta)^2}{2s^2})}{\\sum_{j=0}^1\\sup_{H^q_j}\\pi_jexp(-\\frac{(\\Delta - \\delta)^2}{2s^2})}\\] 其中\\(s^2\\)是\\(\\Delta\\)的方差，\\(\\delta\\)来自假设模板。\n\\(H_0\\)对应的\\(A_0\\)越高，越容易接受原假设，产生二类错误；\n\\(H_1\\)对应的\\(A_1\\)越高，越容易拒绝原假设，产生一类错误。\nlinkedIn的选择：\\(A_0 = 0.2, A_1 = 0.1\\)。\n最终流程：\n1). 如果任意环节q，\\(L_t(H^q_1) &gt; \\frac{1}{1 + A_1}\\)，拒绝原假设，不能继续放量； 2). 如果某些环节，\\(L_t(H^q_0) &gt; \\frac{1}{1 + A_0}\\)，接受原假设，放量到其中最大q阶段； 3). 其他情况，继续观察到t+1，根据\\(L_(t+1)\\)进行决策； 4). 如果直到\\(t = 7\\)都没满足条件，建议放量。\n\n\n2.1.4. 多个指标情况\n通过控制FDR来矫正多重检验问题，通过类似Benjamini-Hochberg方差来处理\\(L_t(H_1^q)\\)：\n1). 将M个指标结果\\(L_t^{(1)}(H_1^q),\\ L_t^{(2)}(H_1^q),\\ L_t^{(3)}(H_1^q)...\\)进行降序排列； 2). 按顺序进行比较： \\[L_t^{(m)}(H_1^q) &gt; \\frac{1}{1 + \\frac{mA_1}{M}}\\]\n至少一个指标满足条件时，接受\\(H_1^q\\)。\n所以放量条件为：\n1). \\(H_1^q\\)未被接受； 2). 主要指标都接受\\(H_0^q\\)。"
  },
  {
    "objectID": "posts/sqr/index.html#mpr阶段的放量",
    "href": "posts/sqr/index.html#mpr阶段的放量",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "2.2. MPR阶段的放量",
    "text": "2.2. MPR阶段的放量\nMPR之前主要关注规避风险，MPR阶段关注速度和决策质量。\n\n2.2.1. MPR时长\n至少一周的时间\n\n\n2.2.2. 指标的影响\n重要的指标：任意指标p小于0.05，就需要仔细研究；\n其他指标：显著性为0.1，并控制错误发现率，如果负向显著就不建议放量到100%。\n\n\n2.2.3. 其他发现的警告\n如果有其他发现，比如burn-in效应、inconsistent results、heterogeneous treatment效应等。这些应该被自动计算，并给出更好、更全面的推荐方案。"
  },
  {
    "objectID": "posts/sqr/index.html#评估",
    "href": "posts/sqr/index.html#评估",
    "title": "SQR：平衡实验速度、质量和风险的框架",
    "section": "2.3. 评估",
    "text": "2.3. 评估\n分两方面评估：\n\n一致性 理想情况下，t阶段放量结论，在t+1阶段依然符合；\n速度 理想情况下，用更少的阶段、合计更短的时间，到达MPR。\n\nLinkedIn收集了484个去年在MPR阶段满一周的实验。由于他们的放量各异，采用了50%流量阶段进行模拟，pre-MPR前取\\(q\\in \\{1\\%,5\\%,10\\%,25\\%\\}\\)。\n\n\n\n5% ramp Day=1 vs Day-7\n\n\n全阶段的模拟："
  },
  {
    "objectID": "posts/BMCP_3/index.html",
    "href": "posts/BMCP_3/index.html",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "",
    "text": "随着概率编程语言的出现，现代贝叶斯建模可以像创建模型然后“按下按钮”一样简单。然而，想要做好需要更多的工作。本章介绍线性模型。线性模型是一类广泛的模型，其中给定观测值的期望值是相关预测变量的线性组合。深刻理解如何拟合和解释线性模型是后续模型的基础。"
  },
  {
    "objectID": "posts/BMCP_3/index.html#比较两个或多个分组",
    "href": "posts/BMCP_3/index.html#比较两个或多个分组",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "3.1. 比较两个或多个分组",
    "text": "3.1. 比较两个或多个分组\n假设在做企鹅相关研究：“每种企鹅的平均质量是多少？”，“这些平均值有多大差异？”，“平均值的离差是多少？”…… Luckily Kristen Gorman 收集了阿德利 (Adelie)、巴布亚 (Gentoo) 和帽带 (Chinstrap) 三种企鹅的数据，记录在 Palmer Penguins 数据集中。\n加载数据集并过滤确实数据的行：\n\nimport pymc as pm\nimport matplotlib.pyplot as plt\nimport arviz as az\nimport pandas as pd\nfrom scipy import special, stats\nimport numpy as np\n\nfrom pytensor import tensor as tt\n\nimport datetime\nprint(f\"Last Run {datetime.datetime.now()}\")\n\nLast Run 2024-01-14 18:18:08.421559\n\n\n\naz.style.use(\"arviz-grayscale\")\nplt.rcParams['figure.dpi'] = 300\n\ndef plot_label_resizer(axes, fontsize=14):\n    \"\"\"Resizes the axes labels of plots\"\"\"\n    for ax in axes.ravel():\n        for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                     ax.get_xticklabels() + ax.get_yticklabels()):\n            item.set_fontsize(fontsize)\n    return\n\n\npenguins = pd.read_csv(\"../data/penguins.csv\")\n\n# Subset to the columns needed\nmissing_data = penguins.isnull()[\n    [\"bill_length_mm\", \"flipper_length_mm\", \"sex\", \"body_mass_g\"]\n].any(axis=1)\n\n# Drop rows with any missing data\npenguins = penguins.loc[~missing_data]\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n统计质量的统计量：\n\nsummary_stats = (penguins.loc[:, [\"species\", \"body_mass_g\"]]\n                         .groupby(\"species\")\n                         .agg([\"mean\", \"std\", \"count\"]))\nsummary_stats\n\n\n\n\n\n\n\n\nbody_mass_g\n\n\n\nmean\nstd\ncount\n\n\nspecies\n\n\n\n\n\n\n\nAdelie\n3706.164384\n458.620135\n146\n\n\nChinstrap\n3733.088235\n384.335081\n68\n\n\nGentoo\n5092.436975\n501.476154\n119\n\n\n\n\n\n\n\n上面得到了统计量的点估计，但是其不确定性是未知的。我们可以通过贝叶斯方法来评估。为此我们需要推测观测值与参数的关系，例如： \\[\\overbrace{p(\\mu, \\sigma \\mid Y)}^{Posterior} \\propto \\overbrace{\\mathcal{N}(Y \\mid \\mu, \\sigma)}^{Likelihood}\\;  \\overbrace{\\underbrace{\\mathcal{N}(4000, 3000)}_{\\mu}\n     \\underbrace{\\mathcal{H}\\text{T}(100, 2000)}_{\\sigma}}^{Prior}\\]\n以上对 \\(\\mu\\) 和 \\(\\sigma\\) 的选择了比较宽的先验分布。在这种情况下，先验是根据观测数据的经验平均值和标准差来选择的。一般来说，高斯分布对于企鹅质量来说是一个合理的可能性选择。\n我们先来分析 Adelie 种群：\n\nadelie_mask = (penguins[\"species\"] == \"Adelie\")\nadelie_mass_obs = penguins.loc[adelie_mask, \"body_mass_g\"].values\n\nwith pm.Model() as model_adelie_penguin_mass:\n    σ = pm.HalfStudentT(\"σ\", 100, 2000)\n    μ = pm.Normal(\"μ\", 4000, 3000)\n    mass = pm.Normal(\"mass\", mu=μ, sigma=σ, observed=adelie_mass_obs)\n\n    prior = pm.sample_prior_predictive(samples=5000)\n    inf_data_adelie_penguin_mass = pm.sample(chains=4)\n\nSampling: [mass, μ, σ]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, μ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 22 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n计算之前要先检查先验分布，确认代码可执行及先验假设是否合理。\n\naz.plot_posterior(prior, group=\"prior\", textsize=20)\n\narray([&lt;Axes: title={'center': 'σ'}&gt;, &lt;Axes: title={'center': 'μ'}&gt;],\n      dtype=object)\n\n\n\n\n\n从先验样本本身来看，也许过于宽泛了，因为均值包含较大范围的负数，可以优化。但是作为一个简单示例，且我们有相当数量的观测结果，我们将继续进行后验分布评估。\n\naz.summary(inf_data_adelie_penguin_mass)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nμ\n3705.420\n37.763\n3634.882\n3775.517\n0.576\n0.407\n4311.0\n2465.0\n1.0\n\n\nσ\n463.265\n27.511\n410.183\n513.074\n0.424\n0.301\n4238.0\n2893.0\n1.0\n\n\n\n\n\n\n\n\naxes = az.plot_trace(inf_data_adelie_penguin_mass, divergences=\"bottom\", kind=\"rank_bars\");\nplot_label_resizer(axes, fontsize=16)\n\n\n\n\n在从模型抽样后，我们得到上面的4个子图，右边两个是Rank图（如果4个链来自相同后验分布，它们混合排序后，各自的排名应该是相似的），左边是 KDE 图。也可以通过表格来进行分析。\n从上来看，模型的拟合是可以接受的。\n\naxes = az.plot_posterior(inf_data_adelie_penguin_mass, textsize=20);\n\n\n\n\n通过上面的贝叶斯估计，我们得到了统计量的不确定性范围。\n我们可以用相同的方法评估其他两个种群。\n\n# pd.categorical makes it easy to index species below\nall_species = pd.Categorical(penguins[\"species\"])\n\nwith pm.Model() as model_penguin_mass_all_species:\n    # Note the addition of the shape parameter\n    σ = pm.HalfStudentT(\"σ\", 100, 2000, shape=3)\n    μ = pm.Normal(\"μ\", 4000, 3000, shape=3)\n    mass = pm.Normal(\"mass\",\n                     mu=μ[all_species.codes],\n                     sigma=σ[all_species.codes],\n                     observed=penguins[\"body_mass_g\"])\n\n    trace = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, μ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 23 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\ntrace = trace.assign_coords(coords={\"μ_dim_0\": all_species.categories,\n                \"σ_dim_0\": all_species.categories})\n\n\naxes = az.plot_trace(trace, compact=False, divergences=\"bottom\", kind=\"rank_bars\");\n\nplot_label_resizer(axes, fontsize=16)\n\n\n\n\n可以通过 az.plot_forest 来更方便的比较不同种群的差异。\n\naxes = az.plot_forest(trace, var_names=[\"μ\"], figsize=(8, 2.5))\naxes[0].set_title(\"μ Mass Estimate: 94.0% HDI\")\n\nText(0.5, 1.0, 'μ Mass Estimate: 94.0% HDI')\n\n\n\n\n\n从上图可知 Gentoo 有更大的均值。让我们来看看标准差。\n\naxes = az.plot_forest(trace, var_names=[\"σ\"], figsize=(8, 2.5))\naxes[0].set_title(\"σ Mass Estimate: 94.0% HDI\")\n\nText(0.5, 1.0, 'σ Mass Estimate: 94.0% HDI')\n\n\n\n\n\n\n3.1.1. 比较两种概率编程语言 PPLs\n后续会使用 PyMC 与 TensorFlow Probability (TFP) 来进行编程。\n学习不同的 PPL 似乎没有必要。然而在本书中选择使用两个 PPL 而不是一个 PPL 是有特定原因的。在不同的 PPL 中看到相同的工作流程将使您对计算贝叶斯建模有更全面的了解，帮助您将计算细节与统计思想分开，并使您成为整体上更强大的建模者。而且，不同的PPL有不同的强度和侧重点。 PyMC3 是一种更高级别的 PPL，可以更轻松地用更少的代码表达模型，而 TFP 则为可组合建模和推理提供较低级别的 PPL。另一个问题是，并非所有 PPL 都能够像彼此一样轻松地表达所有模型。例如，时间序列模型（第 6 章）在 TFP 中更容易定义，而贝叶斯加法回归树在 PyMC（第 7 章）中更容易表达。通过接触多种语言，您将对贝叶斯建模的基本要素以及它们的计算实现方式有更深入的了解。"
  },
  {
    "objectID": "posts/BMCP_3/index.html#线性回归",
    "href": "posts/BMCP_3/index.html#线性回归",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "3.2. 线性回归",
    "text": "3.2. 线性回归\n上一节中我们评估了质量和种群的关系，但是还可以有很多其它数据与质量相关，比如脚蹼的长度等。一种最简单的方法是使用线性回归来评估它们间的关系。\n\\[\\begin{split}\n    \\mu =& \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_m X_m \\\\\nY \\sim& \\mathcal{N}(\\mu, \\sigma)\n\\end{split}\\]\n其中每个 \\(\\beta_i\\) 参数都是一个随机变量。也可以通过矩阵来表示： \\[\\mu = \\mathbf{X}\\boldsymbol{\\beta}\\]\n在非贝叶斯框架下，参数被认为是确定的，并单独讲噪音分开，因此表示为： \\[Y = \\mathbf{X}\\boldsymbol{\\beta} + \\epsilon,\\; \\epsilon \\sim \\mathcal{N}(0, \\sigma)\\]\n\n3.2.1. 线性的企鹅\n我们没有什么先验知识，所以我们选择一个宽泛的先验分布，\\(\\beta_i \\sim \\mathcal{N}(0, 4000)\\)。让我们在 adelie 上考虑脚蹼长度来建模：\n\nadelie_flipper_length_obs = penguins.loc[adelie_mask, \"flipper_length_mm\"]\n\nwith pm.Model() as model_adelie_flipper_regression:\n    # pm.Data allows us to change the underlying value in a later code block\n    adelie_flipper_length = pm.Data(\"adelie_flipper_length\",\n                                    adelie_flipper_length_obs, mutable=True)\n    σ = pm.HalfStudentT(\"σ\", 100, 2000)\n    β_0 = pm.Normal(\"β_0\", 0, 4000)\n    β_1 = pm.Normal(\"β_1\", 0, 4000)\n    μ = pm.Deterministic(\"μ\", β_0 + β_1 * adelie_flipper_length)\n\n    mass = pm.Normal(\"mass\", mu=μ, sigma=σ, observed = adelie_mass_obs)\n\n    inf_data_adelie_flipper_regression = pm.sample(return_inferencedata=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β_0, β_1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 37 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:19&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n为了节省篇幅，这里不进行模型诊断，在真实应用场景下请一定注意诊断。\n\naxes = az.plot_posterior(inf_data_adelie_flipper_regression, var_names = [\"β_0\", \"β_1\"], textsize=20);\n\n\n\n\n从上可知，脚蹼长度与质量呈正相关，每增加1mm质量增加约32g，而且其 94% HDI 不包含0，这支持了脚蹼长度与质量有关的看法。请注意这不代表因果，例如人为手术增加脚蹼长度，质量不会增加。\n我们可以推测，增加脚蹼协变量将有助于更好地预测企鹅的质量。我们可以通过 \\(\\sigma\\) 来验证，对比固定均值模型和线性模型，\\(\\sigma\\) 变小了\n\naxes = az.plot_forest(\n    [inf_data_adelie_penguin_mass, inf_data_adelie_flipper_regression],\n    model_names=[\"mass_only\", \"flipper_regression\"],\n    var_names=[\"σ\"], combined=True, figsize=(8,4))\n\naxes[0].set_title(\"σ Comparison 94.0 HDI\")\n\nText(0.5, 1.0, 'σ Comparison 94.0 HDI')\n\n\n\n\n\n\nfig, ax = plt.subplots()\nalpha_m = inf_data_adelie_flipper_regression.posterior.mean().to_dict()[\"data_vars\"][\"β_0\"][\"data\"]\nbeta_m = inf_data_adelie_flipper_regression.posterior.mean().to_dict()[\"data_vars\"][\"β_1\"][\"data\"]\n\nflipper_length = np.linspace(adelie_flipper_length_obs.min(), adelie_flipper_length_obs.max(), 100)\n\nflipper_length_mean = alpha_m + beta_m * flipper_length\nax.plot(flipper_length, flipper_length_mean, c='C4',\n         label=f'y = {alpha_m:.2f} + {beta_m:.2f} * x')\n\nax.scatter(adelie_flipper_length_obs, adelie_mass_obs)\n\n# Figure out how to do this from inference data\naz.plot_hdi(adelie_flipper_length_obs, inf_data_adelie_flipper_regression.posterior['μ'], hdi_prob=0.94, color='k', ax=ax)\n\nax.set_xlabel('Flipper Length')\nax.set_ylabel('Mass');\n\n\n\n\n\n\n3.2.2. 预测\n上面建立了脚蹼和质量的模型，因此根据脚蹼长度，我们可以预测企鹅的质量。比如我们知道一个企鹅的脚蹼长度为均值，可以预测其后验均值和观测值。\n\nwith model_adelie_flipper_regression:\n    # Change the underlying value to the mean observed flipper length\n    # for our posterior predictive samples\n    pm.set_data({\"adelie_flipper_length\": [adelie_flipper_length_obs.mean()]})\n    posterior_predictions = pm.sample_posterior_predictive(\n        inf_data_adelie_flipper_regression.posterior, var_names=[\"mass\", \"μ\"])\n\nSampling: [mass]\n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\nfig, ax = plt.subplots()\naz.plot_dist(posterior_predictions.posterior_predictive[\"mass\"], label=\"Posterior Predictive of \\nIndividual Penguin Mass\", ax=ax)\naz.plot_dist(posterior_predictions.posterior_predictive[\"μ\"],label=\"Posterior Predictive of μ\", color=\"C4\", ax=ax)\nax.set_xlim(2900, 4500);\nax.legend(loc=2)\nax.set_xlabel(\"Mass (grams)\")\nax.set_yticks([])\n\n[]\n\n\n\n\n\n后验预测分布在贝叶斯背景下是一个特别强大的工具，因为它不仅让我们预测最可能的值，还让我们预测包含我们估计的不确定性的合理值的分布。\n\n\n3.2.3. Centering\n上面的模型效果不错，但可惜的是其 \\(\\beta_0\\) 不是很有实际意义。可以通过变换让它更可解释。\n\nadelie_flipper_length_c = (adelie_flipper_length_obs -\n                           adelie_flipper_length_obs.mean())\n\n\nwith pm.Model() as model_adelie_flipper_regression_c:\n    # pm.Data allows us to change the underlying value in a later code block\n    adelie_flipper_length = pm.Data(\"adelie_flipper_length\",\n                                    adelie_flipper_length_c, mutable=True)\n    σ = pm.HalfStudentT(\"σ\", 100, 2000)\n    β_0 = pm.Normal(\"β_0\", 0, 4000)\n    β_1 = pm.Normal(\"β_1\", 0, 4000)\n    μ = pm.Deterministic(\"μ\", β_0 + β_1 * adelie_flipper_length)\n\n    mass = pm.Normal(\"mass\", mu=μ, sigma=σ, observed = adelie_mass_obs)\n\n    inf_data_adelie_flipper_regression_c = pm.sample(return_inferencedata=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β_0, β_1]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 24 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naxes = az.plot_posterior(inf_data_adelie_flipper_regression_c, var_names = [\"β_0\", \"β_1\"], textsize=20);\n\n\n\n\n重新绘制参数，此时 \\(\\beta_1\\) 无变化， \\(\\beta_0\\) 有了意义，表示种群的平均质量。"
  },
  {
    "objectID": "posts/BMCP_3/index.html#多变量线性回归",
    "href": "posts/BMCP_3/index.html#多变量线性回归",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "3.3. 多变量线性回归",
    "text": "3.3. 多变量线性回归\n很多物种中不同性别的体型有很大差异，因此我们可以考虑性别作为一个协变量，然后看我们的评估能否更加精确。\n\n# Binary encoding of the categorical predictor\nsex_obs = penguins.loc[adelie_mask ,\"sex\"].replace({\"male\":0, \"female\":1})\n\nwith pm.Model() as model_penguin_mass_categorical:\n    σ = pm.HalfStudentT(\"σ\", 100, 2000)\n    β_0 = pm.Normal(\"β_0\", 0, 3000)\n    β_1 = pm.Normal(\"β_1\", 0, 3000)\n    β_2 = pm.Normal(\"β_2\", 0, 3000)\n\n    μ = pm.Deterministic(\n        \"μ\", β_0 + β_1 * adelie_flipper_length_obs + β_2 * sex_obs)\n\n    mass = pm.Normal(\"mass\", mu=μ, sigma=σ, observed=adelie_mass_obs)\n\n    inf_data_penguin_mass_categorical = pm.sample(\n        target_accept=.9, return_inferencedata=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β_0, β_1, β_2]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 49 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:30&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\naz.plot_posterior(inf_data_penguin_mass_categorical, var_names =[\"β_0\", \"β_1\", \"β_2\"], textsize=30);\n\n\n\n\n由于我们将雄性编码为 0，因此后验估计了与具有相同鳍状肢长度的雌性阿德利企鹅相比的质量差异。在解释系数时必须更加小心，如果所有其他协变量保持不变，则系数提供了协变量与响应变量的关系。\n\nfig, ax = plt.subplots()\nalpha_1 = inf_data_penguin_mass_categorical.posterior.mean().to_dict()[\"data_vars\"][\"β_0\"][\"data\"]\nbeta_1 = inf_data_penguin_mass_categorical.posterior.mean().to_dict()[\"data_vars\"][\"β_1\"][\"data\"]\nbeta_2 = inf_data_penguin_mass_categorical.posterior.mean().to_dict()[\"data_vars\"][\"β_2\"][\"data\"]\n\n\nflipper_length = np.linspace(adelie_flipper_length_obs.min(), adelie_flipper_length_obs.max(), 100)\n\nmass_mean_male = alpha_1 + beta_1 * flipper_length\nmass_mean_female = alpha_1 + beta_1 * flipper_length + beta_2\n\nax.plot(flipper_length, mass_mean_male,\n         label=\"Male\")\n\nax.plot(flipper_length, mass_mean_female, c='C4',\n         label=\"Female\")\n\nax.scatter(adelie_flipper_length_obs, adelie_mass_obs, c=[{0:\"k\", 1:\"b\"}[code] for code in sex_obs.values])\n\n# Figure out how to do this from inference data\n#az.plot_hpd(adelie_flipper_length, trace.get_values(varname=\"μ\"), credible_interval=0.94, color='k', ax=ax)\n\nax.set_xlabel('Flipper Length')\nax.set_ylabel('Mass');\nax.legend()\n\n&lt;matplotlib.legend.Legend at 0x17d977e10&gt;\n\n\n\n\n\n验证可发现标准差是否变小了。这种不确定性的减少表明，性别确实为估计企鹅的质量提供了有用信息。\n\naz.plot_forest([inf_data_adelie_penguin_mass,\n        inf_data_adelie_flipper_regression,\n        inf_data_penguin_mass_categorical],\n        model_names=[\"mass_only\", \"flipper_regression\", \"flipper_sex_regression\"],\n        var_names=[\"σ\"], combined=True, figsize=(8,4))\n\naxes[0].set_title(\"σ Comparison 94.0 HDI\");\n\n\n\n\n注意：协变量不是越多越好\n\n所有模型拟合算法都会找到信号，即使它是随机噪声。这种现象称为过度拟合，它描述了一种情况，即算法可以轻松地将协变量映射到所见案例中的结果，但无法推广到新的观察结果。在线性回归中，我们可以通过生成 100 个随机协变量用它们拟合随机模拟数据集。即使没有关系，我们的线性模型表现得也会很好。\n\n\n3.3.1. 反事实\n可以保持其他协变量不变，然后分析单个变量的影响，这称为反事实分析。下面增加喙长度建立多元线性回归模型，并进行反事实分析。"
  },
  {
    "objectID": "posts/BMCP_3/index.html#广义线性模型",
    "href": "posts/BMCP_3/index.html#广义线性模型",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "3.4. 广义线性模型",
    "text": "3.4. 广义线性模型\n以上所有线性模型都假设观测值的分布是条件高斯分布，但是有时候需要其它分布。比如，对 [0,1] 范围内的概率建模，对 {1, 2, 3,…} 数字建模。\n我们可以继续采用线性函数 \\(\\mathbf{X} \\mathit{\\beta}\\)，并且用逆链接函数 \\(\\phi\\) 对它进行处理： $$\n\\[\\begin{split}\n\\mu =& \\phi(\\mathbf{X} \\beta) \\\\\nY \\sim& \\Psi (\\mu, \\theta)\n\n\\end{split}\\]\n$$\n逆链接函数的具体目的是映射实数范围的输出到限制区间范围。换句话说，逆链接函数是我们需要采用线性模型并将其推广到更多模型架构的特定“技巧”。\n\n3.4.1. 逻辑回归\n逻辑回归是一种使用最广泛的广义线性模型之一，用于建模二元分类问题。它通过逆链接函数 logistic 将实数范围的输入映射到 [0,1] 范围的输出。 \\[p = \\frac{1}{1+e^{-\\mathbf{X}\\beta}}\\]\n\n通过逻辑回归，我们能够使用线性模型来估计事件的概率。我们可以使用决策边界来在集合中进行预测 0 或 1 。如果决策边界设置为 0.5 ，对于具有截距和一个协变量的模型，我们有： \\[\n\\begin{split}\n0.5 &= logistic(\\beta_{0} + \\beta_{1}*x) \\\\\nlogit(0.5) &= \\beta_{0} + \\beta_{1}*x \\\\\n0 &= \\beta_{0} + \\beta_{1}*x \\\\\nx &= -\\frac{\\beta_{0}}{\\beta_{1}} \\\\\n\\end{split}\n\\]\n其中 logit 是 logistic 的逆函数，也就是说模型训练后，我们也可以通过 \\(\\beta_0\\) 和 \\(\\beta_1\\) 来计算 \\(x\\) 的决策边界。\n\n\n3.4.2. 企鹅分类\n如果给出企鹅的质量、性别、喙长度和脚蹼长度，我们能否预测其种类么？下面用 Adelie 和 Chinstrap 企鹅做二分类任务\n\nspecies_filter = penguins[\"species\"].isin([\"Adelie\", \"Chinstrap\"])\nbill_length_obs = penguins.loc[species_filter, \"bill_length_mm\"].values\nspecies = pd.Categorical(penguins.loc[species_filter, \"species\"])\n\nwith pm.Model() as model_logistic_penguins_bill_length:\n    β_0 = pm.Normal(\"β_0\", mu=0, sigma=10)\n    β_1 = pm.Normal(\"β_1\", mu=0, sigma=10)\n\n    μ = β_0 + pm.math.dot(bill_length_obs, β_1)\n\n    # Application of our sigmoid  link function\n    θ = pm.Deterministic(\"θ\", pm.math.sigmoid(μ))\n\n    # Useful for plotting the decision boundary later\n    bd = pm.Deterministic(\"bd\", -β_0/β_1)\n\n    # Note the change in likelihood\n    yl = pm.Bernoulli(\"yl\", p=θ, observed=species.codes)\n    \n    loglik = pm.Deterministic('log_likelihood', pm.logp(yl, species.codes))\n\n    prior_predictive_logistic_penguins_bill_length = pm.sample_prior_predictive(samples=10000)\n    trace_logistic_penguins_bill_length = pm.sample(5000, random_seed=0, chains=2)\n    posterior_predictive_logistic_penguins_bill_length = pm.sample_posterior_predictive(trace_logistic_penguins_bill_length)\n    trace_logistic_penguins_bill_length.extend(posterior_predictive_logistic_penguins_bill_length)\n\nSampling: [yl, β_0, β_1]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 4 jobs)\nNUTS: [β_0, β_1]\nSampling 2 chains for 1_000 tune and 5_000 draw iterations (2_000 + 10_000 draws total) took 27 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nSampling: [yl]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:15&lt;00:00 Sampling 2 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [10000/10000 00:00&lt;00:00]\n    \n    \n\n\n在泛化线性模型中，先验模型参数与结果的关系更难理解了。我们可以利用先验的预测样本来可视化预期的观察结果。\n\nax = az.plot_dist(prior_predictive_logistic_penguins_bill_length.prior_predictive.data_vars['yl'], color=\"C2\")\nax.set_xticklabels([\"Adelie: 0\", \"Chinstrap: 1\"] )\n\n[Text(0.0, 0, 'Adelie: 0'), Text(1.0, 0, 'Chinstrap: 1')]\n\n\n\n\n\n从上图看，先验中认为两种企鹅可能性差不多，这是符合预期的。\n\naz.plot_trace(trace_logistic_penguins_bill_length, var_names=[\"β_0\", \"β_1\"], kind=\"rank_bars\");\n\n\n\n\n在训练模型后，可以通过 az.summary 来查看参数的后验分布。可以发现 \\(\\beta_1\\) 的 HDI 不包含0，并且44mm的喙长度大概是分类边界。\n\naz.summary(trace_logistic_penguins_bill_length, var_names=[\"β_0\", \"β_1\"], kind=\"stats\")\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nβ_0\n-34.557\n4.315\n-43.199\n-27.244\n\n\nβ_1\n0.781\n0.099\n0.606\n0.974\n\n\n\n\n\n\n\n用下图展示更加直接。\n\nfig, ax = plt.subplots()\n\ntheta = trace_logistic_penguins_bill_length.posterior[\"θ\"].values.reshape((-1,214)).mean(axis=0)\n\n\nidx = np.argsort(bill_length_obs)\n\n# Decision Boundary\nax.vlines(trace_logistic_penguins_bill_length.posterior[\"bd\"].values.mean(), 0, 1, color='k')\nbd_hpd = az.hdi(trace_logistic_penguins_bill_length.posterior[\"bd\"].values.flatten(), ax=ax)\nplt.fill_betweenx([0, 1], bd_hpd[0], bd_hpd[1], color='C2', alpha=0.5)\n\n\nfor i, (label, marker) in enumerate(zip(species.categories, (\".\", \"s\"))):\n    _filter = (species.codes == i)\n    x = bill_length_obs[_filter]\n    y = np.random.normal(i, 0.02, size=_filter.sum())\n    ax.scatter(bill_length_obs[_filter], y, marker=marker, label=label, alpha=.8)\n\naz.plot_hdi(bill_length_obs, trace_logistic_penguins_bill_length.posterior[\"θ\"].values, color='C4', ax=ax, plot_kwargs={\"zorder\":10})\nax.plot(bill_length_obs[idx], theta[idx], color='C4', zorder=10)\n\nax.set_xlabel(\"Bill Length (mm)\")\nax.set_ylabel('θ', rotation=0)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x17e42a790&gt;\n\n\n\n\n\n如果用重量来预测呢？\n\nmass_obs = penguins.loc[species_filter, \"body_mass_g\"].values\n\nwith pm.Model() as model_logistic_penguins_mass:\n    β_0 = pm.Normal(\"β_0\", mu=0, sigma=10)\n    β_1 = pm.Normal(\"β_1\", mu=0, sigma=10)\n\n    μ = β_0 + pm.math.dot(mass_obs, β_1)\n    θ = pm.Deterministic(\"θ\", pm.math.sigmoid(μ))\n    bd = pm.Deterministic(\"bd\", -β_0/β_1)\n\n    yl = pm.Bernoulli(\"yl\", p=θ, observed=species.codes)\n\n    inf_data_logistic_penguins_mass = pm.sample(\n        5000, target_accept=.9, return_inferencedata=True)\n    \n    loglik = pm.Deterministic('log_likelihood', pm.logp(yl, species.codes))\n    \n    trace_logistic_penguins_mass = pm.sample(\n        5000, random_seed=0, chains=2, target_accept=.9)\n    posterior_predictive_logistic_penguins_mass = pm.sample_posterior_predictive(\n        trace_logistic_penguins_mass)\n    trace_logistic_penguins_mass.extend(posterior_predictive_logistic_penguins_mass)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [β_0, β_1]\nSampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 33 seconds.\nThe rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\nThe effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\nThere were 5000 divergences after tuning. Increase `target_accept` or reparameterize.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 4 jobs)\nNUTS: [β_0, β_1]\nSampling 2 chains for 1_000 tune and 5_000 draw iterations (2_000 + 10_000 draws total) took 24 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nSampling: [yl]\n\n\n\n\n\n\n\n    \n      \n      100.00% [24000/24000 00:14&lt;00:00 Sampling 4 chains, 5,000 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:13&lt;00:00 Sampling 2 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [10000/10000 00:01&lt;00:00]\n    \n    \n\n\n\naz.summary(inf_data_logistic_penguins_mass, var_names=[\"β_0\", \"β_1\"], kind=\"stats\")\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nβ_0\n-1.145\n1.111\n-3.532\n0.911\n\n\nβ_1\n0.081\n0.140\n-0.000\n0.324\n\n\n\n\n\n\n\n\ntheta = inf_data_logistic_penguins_mass.posterior['θ'].values\nbd = inf_data_logistic_penguins_mass.posterior['bd'].values\n\n\nfig, ax = plt.subplots()\ntheta = theta.reshape(-1,214).mean(axis=0)\nidx = np.argsort(mass_obs)\n\nax.plot(mass_obs[idx], theta[idx], color='C4', lw=3)\nfor i, (label, marker) in enumerate(zip(species.categories, (\".\", \"s\"))):\n    _filter = (species.codes == i)\n    x = mass_obs[_filter]\n    y = np.random.normal(i, 0.02, size=_filter.sum())\n    ax.scatter(mass_obs[_filter], y, marker=marker, label=label, alpha=.8)\n\naz.plot_hdi(mass_obs, inf_data_logistic_penguins_mass.posterior['θ'], color='C4', ax=ax)\n\nax.set_xlabel(\"Mass (Grams)\")\nax.set_ylabel('θ', rotation=0)\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x17cd8da50&gt;\n\n\n\n\n\n通过以上统计结果及图可知，重量无法对分类提供有效的信息。试试结合喙长度和重量一起。\n\nX = penguins.loc[species_filter, [\"bill_length_mm\", \"body_mass_g\"]]\n\n# Add a column of 1s for the intercept\nX.insert(0,\"Intercept\", value=1)\nX = X.values\n\nwith pm.Model() as model_logistic_penguins_bill_length_mass:\n    β = pm.Normal(\"β\", mu=0, sigma=20, shape=3)\n\n    μ = pm.math.dot(X, β)\n\n    θ = pm.Deterministic(\"θ\", pm.math.sigmoid(μ))\n    bd = pm.Deterministic(\"bd\", -β[0]/β[2] - β[1]/β[2] * X[:,1])\n\n    yl = pm.Bernoulli(\"yl\", p=θ, observed=species.codes)\n    loglik = pm.Deterministic('log_likelihood', pm.logp(yl, species.codes))\n\n    trace_logistic_penguins_bill_length_mass = pm.sample(\n        5000, random_seed=0, chains=2, target_accept=.9)\n    posterior_predictive_logistic_penguins_bill_length_mass = pm.sample_posterior_predictive(\n        trace_logistic_penguins_bill_length_mass)\n    trace_logistic_penguins_bill_length_mass.extend(posterior_predictive_logistic_penguins_bill_length_mass)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 4 jobs)\nNUTS: [β]\nSampling 2 chains for 1_000 tune and 5_000 draw iterations (2_000 + 10_000 draws total) took 49 seconds.\nWe recommend running at least 4 chains for robust computation of convergence diagnostics\nSampling: [yl]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:40&lt;00:00 Sampling 2 chains, 63 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [10000/10000 00:00&lt;00:00]\n    \n    \n\n\n\naz.summary(trace_logistic_penguins_bill_length_mass, var_names=[\"β\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nβ[0]\n-46.301\n9.632\n-64.668\n-28.973\n0.218\n0.159\n2039.0\n2089.0\n1.0\n\n\nβ[1]\n1.887\n0.406\n1.123\n2.623\n0.010\n0.007\n1598.0\n1717.0\n1.0\n\n\nβ[2]\n-0.010\n0.003\n-0.015\n-0.005\n0.000\n0.000\n1786.0\n2106.0\n1.0\n\n\n\n\n\n\n\n\nfig,ax  = plt.subplots()\nidx = np.argsort(X[:,1])\nbd = trace_logistic_penguins_bill_length_mass.posterior[\"bd\"].values.reshape((-1,214)).mean(axis=0)[idx]\n\nspecies_filter = species.codes.astype(bool)\n\n# Linear fit\nax.plot(X[:,1][idx], bd, color='C4');\naz.plot_hdi(X[:,1], trace_logistic_penguins_bill_length_mass.posterior[\"bd\"].values.reshape((-1,214)), color='C4', ax=ax)\n\n# Scatter\nax.scatter(X[~species_filter,1], X[~species_filter,2], alpha=.8,  label=\"Adelie\", zorder=10)\nax.scatter(X[species_filter,1], X[species_filter,2], marker=\"s\", label=\"Chinstrap\", zorder=10)\n\nax.set_ylabel(\"Mass (grams)\")\nax.set_xlabel(\"Bill Length (mm)\")\n\nax.legend()\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n\n\n&lt;matplotlib.legend.Legend at 0x17d854d90&gt;\n\n\n\n\n\n可以通过 separation plot 来更直观的看到分类效果。如果模型分类特别好，图形会是两个分离的长方体。\n\ntrace_logistic_penguins_bill_length.add_groups({\"log_likelihood\": {\"y\":trace_logistic_penguins_bill_length.posterior.log_likelihood}})\ntrace_logistic_penguins_mass.add_groups({\"log_likelihood\": {\"y\":trace_logistic_penguins_mass.posterior.log_likelihood}})\ntrace_logistic_penguins_bill_length_mass.add_groups({\"log_likelihood\": {\"y\":trace_logistic_penguins_bill_length_mass.posterior.log_likelihood}})\n\n\nmodels = {\"bill\": trace_logistic_penguins_bill_length,\n          \"mass\": trace_logistic_penguins_mass,\n          \"mass bill\": trace_logistic_penguins_bill_length_mass}\n\n_, axes = plt.subplots(3, 1, figsize=(12, 4), sharey=True)\nfor (label, model), ax in zip(models.items(), axes):\n    az.plot_separation(model, y=\"yl\", y_hat=\"yl\", ax=ax, color=\"C4\")\n    ax.set_title(label)\n\n\n\n\n也可以通过 LOO 来比较模型的分类效果。\n\naz.compare({\"mass\": trace_logistic_penguins_mass,\n            \"bill\": trace_logistic_penguins_bill_length,\n            \"mass_bill\": trace_logistic_penguins_bill_length_mass}).round(1)\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmass_bill\n0\n-11.2\n1.6\n0.0\n1.0\n3.1\n0.0\nTrue\nlog\n\n\nbill\n1\n-28.0\n1.0\n16.7\n0.0\n5.0\n3.9\nFalse\nlog\n\n\nmass\n2\n-135.7\n1.9\n124.5\n0.0\n5.3\n5.8\nFalse\nlog\n\n\n\n\n\n\n\n\n\n3.4.3. 对数比率 Log Odds 的解释\n在逻辑回归中，斜率告诉您当 x 增加一个单位时对数比率的增加。最简单的赔率是发生概率与不发生概率之间的比率。比如，我们从 Adelie 和 Chinstrap 企鹅中随机抽取一个企鹅，它是 Chinstrap 的概率是0.68。\n\n# Class counts of each penguin species\ncounts = penguins[\"species\"].value_counts()\nadelie_count = counts[\"Adelie\"],\nchinstrap_count = counts[\"Chinstrap\"]\nadelie_count / (adelie_count + chinstrap_count)\n\narray([0.68224299])\n\n\n同一事件的比率是：\n\nadelie_count / chinstrap_count\n\narray([2.14705882])\n\n\n利用我们对比率的了解，我们可以定义 logit。 logit 是赔率的自然对数。则： \\[p = \\frac{1}{1+e^{-\\mathbf{X}\\beta}}\\] \\[\\log \\left(\\frac{p}{1-p} \\right) = \\boldsymbol{X} \\beta\\]\n这种替代公式让我们将逻辑回归的系数解释为对数比率的变化。"
  },
  {
    "objectID": "posts/BMCP_3/index.html#为回归模型选择先验",
    "href": "posts/BMCP_3/index.html#为回归模型选择先验",
    "title": "【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言",
    "section": "3.5. 为回归模型选择先验",
    "text": "3.5. 为回归模型选择先验\n现在我们已经熟悉了广义线性模型，让我们关注先验及其对后验估计的影响。我们将借用一项研究，其探讨了父母的吸引力与这些父母生下女孩的百分比之间的关系。在这项研究中，研究人员按照五分制评估了美国青少年的吸引力。最终，这些受试者中的许多人有了孩子，计算了每个吸引力类别的性别比例。然而，这一次，要特别关注如何一起评估先验和可能性，而不是独立评估。\n先选择一个非常宽的先验（近似无信息先验）：\n\nx = np.arange(-2, 3, 1)\ny = np.asarray([50, 44, 50, 47, 56])\n\nwith pm.Model() as model_uninformative_prior_sex_ratio:\n    σ = pm.Exponential(\"σ\", .5)\n    β_1 = pm.Normal(\"β_1\", 0, 20)\n    β_0 = pm.Normal(\"β_0\", 50, 20)\n\n    μ = pm.Deterministic(\"μ\", β_0 + β_1 * x)\n\n    ratio = pm.Normal(\"ratio\", mu=μ, sigma=σ, observed=y)\n\n    prior_predictive_uninformative_prior_sex_ratio = pm.sample_prior_predictive(\n        samples=10000\n    )\n    trace_uninformative_prior_sex_ratio = pm.sample()\n    trace_uninformative_prior_sex_ratio.extend(prior_predictive_uninformative_prior_sex_ratio)\n\nSampling: [ratio, β_0, β_1, σ]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β_1, β_0]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 24 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nimport matplotlib.ticker as mtick\nfig, axes = plt.subplots(2,1, figsize=(5.5, 6), sharex=True)\n\nnp.random.seed(0)\n# Take 50 samples from posterior\nnum_samples = 50\nchain_sample = trace_uninformative_prior_sex_ratio.prior.chain.to_series().sample(num_samples, replace=True)\ndraw_sample = trace_uninformative_prior_sex_ratio.prior.draw.to_series().sample(num_samples, replace=True)\n\nfor chain, draw in zip(chain_sample, draw_sample):\n    b_0_draw = trace_uninformative_prior_sex_ratio.prior[{\"draw\":draw, \"chain\":chain}][\"β_0\"].values\n    b_1_draw = trace_uninformative_prior_sex_ratio.prior[{\"draw\":draw, \"chain\":chain}][\"β_1\"].values\n\n    # Plot Line\n    axes[0].plot(x, b_0_draw+b_1_draw*x, c=\"black\", alpha=.3)\n\n# Add median line later\nb_0_hat = trace_uninformative_prior_sex_ratio.prior[\"β_0\"].values.mean()\nb_1_hat = trace_uninformative_prior_sex_ratio.prior[\"β_1\"].values.mean()\n\naxes[0].plot(x, b_0_hat+b_1_hat*x, c=\"blue\", linewidth=4)\n\n\n# Add scatter plot\naxes[0].scatter(x, y)\naxes[0].set_xticks(x)\naxes[0].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\naxes[0].set_ylim(40, 60)\naxes[0].set_ylabel(\"% of Girl Babies\")\naxes[0].set_title(\"Prior samples from uninformative priors\")\nb_0_hat, b_1_hat\n\nnp.random.seed(0)\n# Take 10 sample from posterior\nnum_samples = 50\nchain_sample = trace_uninformative_prior_sex_ratio.posterior.chain.to_series().sample(num_samples, replace=True)\ndraw_sample = trace_uninformative_prior_sex_ratio.posterior.draw.to_series().sample(num_samples, replace=True)\n\nfor chain, draw in zip(chain_sample, draw_sample):\n    b_0_draw = trace_uninformative_prior_sex_ratio.posterior[{\"draw\":draw, \"chain\":chain}][\"β_0\"].values\n    b_1_draw = trace_uninformative_prior_sex_ratio.posterior[{\"draw\":draw, \"chain\":chain}][\"β_1\"].values\n\n    # Plot Line\n    axes[1].plot(x, b_0_draw+b_1_draw*x, c=\"black\", alpha=.3)\n\n# Add median line later\nb_0_hat = trace_uninformative_prior_sex_ratio.posterior[\"β_0\"].values.mean()\nb_1_hat = trace_uninformative_prior_sex_ratio.posterior[\"β_1\"].values.mean()\n\naxes[1].plot(x, b_0_hat+b_1_hat*x, c=\"blue\", linewidth=4)\n\n\n# Add scatter plot\naxes[1].scatter(x, y)\naxes[1].set_xticks(x)\naxes[1].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\naxes[1].set_ylim(40, 60)\naxes[1].set_xlabel(\"Attractiveness of Parent\")\naxes[1].set_ylabel(\"% of Girl Babies\")\naxes[1].set_title(\"Posterior samples from uninformative priors\")\nb_0_hat, b_1_hat\n\naxes[1].title.set_fontsize(12)\n\nfor ax in axes:\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(12)\n\n\n\n\n经评估，\\(\\beta_1\\) 的影响约1.4。从数学角度来看，这个结果是有效的。但从我们的常识和我们对本研究之外的出生性别比的理解来看，这些结果是值得怀疑的。据测算，出生时的“自然”性别比约为 105 比 100 名女孩（男孩约为 103 至 107 人），这意味着出生时性别比为女性 48.5%，标准差为 0.5。此外，即使是与人类生物学更本质相关的因素也不会对出生率产生如此大的影响，从而削弱了主观吸引力应该产生如此大影响的观念。\n让我们再次运行我们的模型，但这次先验与此常识一致。绘制我们的后验样本时，系数的集中度较小，并且在考虑可能的比率时，绘制的后验线落入更合理的范围内。\n\nwith pm.Model() as model_informative_prior_sex_ratio:\n    σ = pm.Exponential(\"σ\", .5)\n\n    # Note the now more informative priors\n    β_1 = pm.Normal(\"β_1\", 0, .5)\n    β_0 = pm.Normal(\"β_0\", 48.5, .5)\n\n    μ = pm.Deterministic(\"μ\", β_0 + β_1 * x)\n    ratio = pm.Normal(\"ratio\", mu=μ, sigma=σ, observed=y)\n\n    prior_predictive_informative_prior_sex_ratio = pm.sample_prior_predictive(\n        samples=10000\n    )\n    trace_informative_prior_sex_ratio = pm.sample()\n    trace_informative_prior_sex_ratio.extend(prior_predictive_informative_prior_sex_ratio)\n\nSampling: [ratio, β_0, β_1, σ]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β_1, β_0]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nfig, axes = plt.subplots(2,1, figsize=(5.5, 6), sharex=True)\n\nnp.random.seed(0)\n# Take 10 sample from posterior\nnum_samples = 50\nchain_sample = trace_informative_prior_sex_ratio.prior.chain.to_series().sample(num_samples, replace=True)\ndraw_sample = trace_informative_prior_sex_ratio.prior.draw.to_series().sample(num_samples, replace=True)\n\nfor chain, draw in zip(chain_sample, draw_sample):\n    b_0_draw = trace_informative_prior_sex_ratio.prior[{\"draw\":draw, \"chain\":chain}][\"β_0\"].values\n    b_1_draw = trace_informative_prior_sex_ratio.prior[{\"draw\":draw, \"chain\":chain}][\"β_1\"].values\n\n    # Plot Line\n    axes[0].plot(x, b_0_draw+b_1_draw*x, c=\"black\", alpha=.3)\n\n# Add median line later\nb_0_hat = trace_informative_prior_sex_ratio.prior[\"β_0\"].values.mean()\nb_1_hat = trace_informative_prior_sex_ratio.prior[\"β_1\"].values.mean()\n\naxes[0].plot(x, b_0_hat+b_1_hat*x, c=\"blue\", linewidth=4)\n\n\n# Add scatter plot\naxes[0].scatter(x, y)\naxes[0].set_xticks(x)\naxes[0].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\naxes[0].set_ylim(40, 60)\naxes[0].set_ylabel(\"% of Girl Babies\")\naxes[0].set_title(\"Prior samples from informative priors\");\n\n\nnp.random.seed(0)\nnum_samples = 50\nchain_sample = trace_informative_prior_sex_ratio.posterior.chain.to_series().sample(num_samples, replace=True)\ndraw_sample = trace_informative_prior_sex_ratio.posterior.draw.to_series().sample(num_samples, replace=True)\n\nfor chain, draw in zip(chain_sample, draw_sample):\n    b_0_draw = trace_informative_prior_sex_ratio.posterior[{\"draw\":draw, \"chain\":chain}][\"β_0\"].values\n    b_1_draw = trace_informative_prior_sex_ratio.posterior[{\"draw\":draw, \"chain\":chain}][\"β_1\"].values\n\n    # Plot Line\n    axes[1].plot(x, b_0_draw+b_1_draw*x, c=\"black\", alpha=.3)\n\n# Add median line later\nb_0_hat = trace_informative_prior_sex_ratio.posterior[\"β_0\"].values.mean()\nb_1_hat = trace_informative_prior_sex_ratio.posterior[\"β_1\"].values.mean()\n\naxes[1].plot(x, b_0_hat+b_1_hat*x, c=\"blue\", linewidth=4)\n\n# Add scatter plot\naxes[1].scatter(x, y)\naxes[1].set_xticks(x)\naxes[1].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\naxes[1].set_ylim(40, 60)\n\naxes[1].set_xlabel(\"Attractiveness of Parent\")\naxes[1].set_ylabel(\"% of Girl Babies\")\naxes[1].set_title(\"Posterior samples from informative priors\")\n\nfor ax in axes:\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n                 ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(12)\n\n\n\n\n这次我们看到吸引力对性别的估计影响可以忽略不计，根本没有足够的信息来影响后验。正如我们在第一章量化先验信息的几个选项中提到的，选择先验既是一种负担，也是一种祝福。无论您相信哪一种，重要的是要以可解释且有原则的选择来使用此统计工具。"
  },
  {
    "objectID": "posts/BMCP_5/index.html",
    "href": "posts/BMCP_5/index.html",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "",
    "text": "在本章中，我们将讨论样条曲线，它是第 3 章中引入的概念的扩展，旨在增加更多灵活性。\n在第 3 章介绍的模型中，因变量和自变量之间的关系在整个域中是相同的。相比之下，样条曲线可以将问题分解为多个局部解决方案，这些解决方案可以全部组合起来产生有用的全局解决方案。"
  },
  {
    "objectID": "posts/BMCP_5/index.html#多项式回归",
    "href": "posts/BMCP_5/index.html#多项式回归",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.1. 多项式回归",
    "text": "5.1. 多项式回归\n\\[\\mathbb{E}[Y]= \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\cdots + \\beta_m X^m\\]\n以上所有协变量都来自 \\(X\\)，所以就我们的实际问题而言，我们仍然拟合的是单预测器。\\(m\\) 被称为多项式的次数。\n以下是对同样的数据，分别用次数 2，10 和 15 进行多项式回归建模。随着次数提升，曲线变得更灵活。 \n多项式的一个问题是它们在全局范围内起作用，当我们应用次数为 \\(m\\) 的多项式时，我们是在说自变量和因变量之间的关系在整个数据集中都是 \\(m\\) 阶的。当我们的数据的不同区域需要不同级别的灵活性时，这可能会成为问题。例如这可能导致曲线过于灵活。在上图的最后一个面板中（次数=15），我们可以看到拟合曲线呈现出一个深谷，然后在 \\(X\\) 的高值处呈现出一个高峰，即使没有这么低或高值的数据点。\n此外，随着次数的增加，拟合对于点的移除变得更加敏感，或者等效地说，对于未来数据的添加更加敏感。换句话说，随着次数的增加，模型更容易过拟合。"
  },
  {
    "objectID": "posts/BMCP_5/index.html#扩展特征空间",
    "href": "posts/BMCP_5/index.html#扩展特征空间",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.2. 扩展特征空间",
    "text": "5.2. 扩展特征空间\n在概念层面上，我们可以将多项式回归看作是创建新预测因子的一种方法，或者更正式地说，是扩展特征空间的方法。通过进行这种扩展，我们能够在扩展的空间中拟合一条线，这为我们在原始数据空间中提供了一条曲线，非常整洁！然而，特征扩展并不是对统计学无政府主义的邀请，我们不能仅仅对数据应用随机变换，然后期望总是得到好的结果。实际上，正如我们刚刚看到的，应用多项式并非没有问题。\n为了概括特征扩展的思想，除了多项式之外，我们可以将方程扩展为以下形式：\n\\[ \\mathbb{E}[Y]= \\beta_0 + \\beta_1 B_{1}(X_{1}) + \\beta_2 B_{2}(X_{2}) + \\cdots + \\beta_m B_{m}(X_{m}) \\]\n其中 \\(B_i\\) 是任意函数，称为基函数。它们的线性组合让我们得到新的函数 \\(f\\) 。 \\[\\mathbb{E}[Y]= \\sum_i^m \\beta_i B_{i}(X_{i}) = f(X)\\]\n关于 \\(B_{i}\\) 函数的选择有很多种，可以用多项式、对数、开方等等。\n另一种选择是使用指示函数，如 \\(I(c_i \\leq x_k &lt; c_j)\\)，将原始的 \\(\\boldsymbol{X}\\) 预测因子分解为（非重叠的）子集。然后在这些子集内部局部拟合多项式。这个过程导致拟合分段多项式，如下图所示。\n\n在上图的四个面板中，目标是相同的，即逼近蓝色函数。我们首先将函数分成3个子域，用灰色虚线分隔，然后为每个子域拟合一个不同的函数。\n在第一个子面板（分段常数）中，我们拟合一个常数函数，可以将常数函数视为零次多项式。聚合解，被称为阶跃函数。这可能看起来是一个相当粗糙的近似，但这可能就是我们所需要的。例如，如果我们试图找出不连续的结果，如早上、下午和晚上的预期平均温度，阶跃函数可能就可以。或者当我们可以接受非平滑的近似，即使我们认为结果是平滑的。\n在第二个面板（分段线性）中，我们做的和第一个面板一样，但是我们使用的是线性函数，而不是常数函数，这是一个一阶多项式。注意，连续的线性解在虚线处相交，这是有意为之。我们可以将这种限制理解为尽可能使解决方案平滑。\n在第三个面板（分段二次）和第四个面板（分段三次）中，我们使用二次和三次分段多项式。我们可以看到，通过增加分段多项式的次数，我们得到了更加灵活的解决方案，这带来了更好的拟合，但也增加了过拟合的风险。\n因为最终的拟合是一个由局部解（基函数 \\(B_i\\)）构造的函数 \\(f\\)，我们可以更容易地使模型的灵活性适应数据在不同区域的需求。在这个特定的情况下，我们可以使用一个更简单的函数（低阶多项式）来拟合数据在不同区域的数据，同时为整个数据域提供一个良好的整体模型拟合。\n到目前为止，我们假设我们只有一个预测因子 \\(X\\)，但是同样的思想可以扩展到多个预测因子 \\(X_0, X_1, \\cdots, X_p\\)。我们甚至可以添加一个逆链接函数 \\(\\phi\\)，这种形式的模型被称为广义加法模型（GAM）。 \\[\\mathbb{E}[Y]= \\phi \\left(\\sum_i^p f(X_i)\\right)\\]\n总结一下，等式中的 \\(B_i\\) 函数是一种巧妙的统计设备，允许我们拟合更灵活的模型。原则上，我们可以自由选择任意的 \\(B_i\\) 函数，我们可以根据我们的领域知识，作为探索性数据分析阶段的结果，甚至通过试错来做。由于并非所有的转换都具有相同的统计性质，因此能够访问一些在更广泛的数据集上具有良好通用性质的默认函数将是很好的。从下一节开始，直到本章的剩余部分，我们将讨论的基函数限制在一种称为 B-splines 的基函数家族。"
  },
  {
    "objectID": "posts/BMCP_5/index.html#样条线简介",
    "href": "posts/BMCP_5/index.html#样条线简介",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.3. 样条线简介",
    "text": "5.3. 样条线简介\n样条线可以被看作是试图利用多项式的灵活性，但是要对它们进行控制，从而得到一个具有整体良好统计性质的模型。要定义一个样条线，我们需要定义节点。节点的目的是将变量 \\(\\boldsymbol{X}\\) 的域分割成连续的区间。例如，上图中的灰色虚线代表节点。对于我们的目的，样条线是一个被约束为连续的分段多项式，也就是说，我们强制两个连续的子多项式在节点处相交。如果子多项式的次数为 \\(n\\)，我们就说样条线的次数为 \\(n\\)。有时，样条线也被称为它们的阶数，即 \\(n+1\\)。\n我们可以看到，随着我们增加分段多项式的阶数，结果函数的平滑度也在增加。如我们已经提到的，子多项式应该在节点处相交。在第一个面板中，我们可能看起来在不符合，因为每条线之间有一个阶梯，也被称为不连续性，但如果我们在每个区间使用常数值，这是我们能做的最好的。\n在谈论样条线时，子多项式被称为基样条线或简称为B样条线。给定度数的任何样条线函数都可以构造为该度数的基样条线的线性组合。B样条线完全由一组节点和一个度数定义。\nCox-de Boor递归公式定义： \n\n%matplotlib inline\nimport arviz as az\nimport matplotlib.pyplot as plt\nfrom cycler import cycler\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nfrom scipy import stats\nfrom patsy import bs, dmatrix\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\naz.style.use('arviz-grayscale')\nplt.rcParams[\"figure.dpi\"] = 300\nnp.random.seed(435)\nviridish = [(0.2823529411764706, 0.11372549019607843, 0.43529411764705883, 1.0),\n            (0.1843137254901961, 0.4196078431372549, 0.5568627450980392, 1.0),\n            (0.1450980392156863, 0.6705882352941176, 0.5098039215686274, 1.0),\n            (0.6901960784313725, 0.8666666666666667, 0.1843137254901961, 1.0),\n            (0.2823529411764706, 0.11372549019607843, 0.43529411764705883, 0.5),\n            (0.1843137254901961, 0.4196078431372549, 0.5568627450980392, 0.5),\n            (0.1450980392156863, 0.6705882352941176, 0.5098039215686274, 0.5),\n            (0.6901960784313725, 0.8666666666666667, 0.1843137254901961, 0.5),\n            (0.2823529411764706, 0.11372549019607843, 0.43529411764705883, 0.3),\n            (0.1843137254901961, 0.4196078431372549, 0.5568627450980392, 0.3),\n            (0.1450980392156863, 0.6705882352941176, 0.5098039215686274, 0.3),\n            (0.6901960784313725, 0.8666666666666667, 0.1843137254901961, 0.3)]\n\n\nx = np.linspace(-0.0001, 1, 1000)\nknots = [0, 0.2, 0.4, 0.6, 0.8, 1]\n\n_, axes = plt.subplots(4, 1, figsize=(9, 6), sharex=True, sharey=True)\nfor deg, ax in enumerate(axes):\n    b_splines = bs(x, degree=deg, knots=knots, lower_bound=-0.01, upper_bound=1.01)\n    for enu, b_s in enumerate(b_splines.T):\n        ax.plot(x, b_s, color=viridish[enu], lw=2, ls=\"--\")\n    ax.plot(x, b_splines[:,deg], lw=3)\n    ax.plot(knots, np.zeros_like(knots), \"ko\", mec=\"w\", ms=10)\n    for i in range(1, deg+1):\n        ax.plot([0, 1], np.array([0, 0])-(i/15), \"k.\", clip_on=False)\n    ax.plot(knots[:deg+2], np.zeros_like(knots[:deg+2]), \"C4o\", mec=\"w\", ms=10)\nplt.ylim(0)\nplt.xticks([])\nplt.yticks([]);\n\n\n\n\n随着我们增加B样条线的度数，B样条线的域越来越大。因此对于高度样条线来说，我们需要定义更多的节点。注意，在所有情况下，B样条线只在给定的区间内非零。这个属性使得样条线回归比我们从多项式回归得到的更局部。\n随着控制每个B样条线的节点数随度数的增长，对于所有大于0的度数，我们无法在边界附近定义B样条线。这就是为什么在图中，随着我们增加度数，B样条线在右边被突出显示为黑色的原因。这提出了一个潜在的问题，因为它使我们在边界处的B样条线少了，所以我们的近似将在那里受到影响。幸运的是，这个边界问题很容易解决，我们只需要在边界添加节点（参见图中的小点）。所以如果我们的节点是（0,1,2,3,4,5）并且我们想要拟合一个立方样条线（就像图的最后一个子图中那样），我们实际上需要使用节点集（0,0,0,0,1,2,3,4,5,5,5,5）。也就是说，我们在开始时将0填充三次，我们在结束时将5填充三次。这样做，我们现在有了五个必要的节点（0,0,0,0,1）来定义第一个B样条线（参见图最后一个子面板中看起来像指数分布的虚线）。然后我们将使用节点0,0,0,1,2来定义第二个B样条线（看起来像Beta分布的那个），等等。看看第一个完整的B样条线（黑色突出显示）是如何由节点（0,1,2,3,4）定义的，这些节点是蓝色的。注意，我们需要在边界处填充节点，填充的次数与样条线的度数相同。这就是为什么我们对于度数为0的没有额外的节点，对于度数为3的有6个额外的节点。\n每一个单独的B样条线本身并不是很有用，但是所有B样条线的线性组合允许我们拟合复杂的函数。因此，在实践中，拟合样条线需要我们选择B样条线的阶数，节点的数量和位置，然后找到一组系数来权衡每个B样条线。这在下图有所展示。我们可以看到基函数用不同的颜色表示，以帮助个别化每个单独的基函数。节点用每个子图底部的黑点表示。第二行更有趣，因为我们可以看到第一行的相同基函数通过一组\\(\\beta_i\\)系数进行缩放。较厚的连续黑线表示由B样条线的加权和得到的样条线，权重由\\(\\beta\\)系数给出。\n\nx = np.linspace(0., 1., 500)\nknots = [0.25, 0.5, 0.75]\n\nB0 = dmatrix(\"bs(x, knots=knots, degree=0, include_intercept=True) - 1\", \n             {\"x\": x, \"knots\":knots})\nB1 = dmatrix(\"bs(x, knots=knots, degree=1, include_intercept=True) - 1\",\n             {\"x\": x, \"knots\":knots})\nB3 = dmatrix(\"bs(x, knots=knots, degree=3,include_intercept=True) - 1\",\n             {\"x\": x, \"knots\":knots})\n\nnp.random.seed(1563)\n_, axes = plt.subplots(2, 3, figsize=(12, 6), sharex=True, sharey='row')\nfor idx, (B, title) in enumerate(zip((B0, B1, B3),\n                                     (\"Piecewise constant\",\n                                      \"Piecewise linear\",\n                                      \"Cubic spline\"))):\n    # plot spline basis functions\n    for i in range(B.shape[1]):\n        axes[0, idx].plot(x, B[:, i],\n                          color=viridish[i], lw=2, ls=\"--\")\n    # we generate some positive random coefficients \n    # there is nothing wrong with negative values\n    β = np.abs(np.random.normal(0, 1, size=B.shape[1]))\n    # plot spline basis functions scaled by its β\n    for i in range(B.shape[1]):\n        axes[1, idx].plot(x, B[:, i]*β[i],\n                          color=viridish[i], lw=2, ls=\"--\")\n    # plot the sum of the basis functions\n    axes[1, idx].plot(x, np.dot(B, β), color='k', lw=3)\n    # plot the knots\n    axes[0, idx].plot(knots, np.zeros_like(knots), \"ko\")\n    axes[1, idx].plot(knots, np.zeros_like(knots), \"ko\")\n    axes[0, idx].set_title(title)\n\n\n\n\n以上使用Patsy定义了B样条线。在第一行，我们可以看到增加阶数的样条线1（分段常数）、2（分段线性）和4（立方）用灰色虚线表示。为了清晰，每个基函数都用不同的颜色表示。在第二行，我们有第一行的基样条线通过一组系数进行缩放。粗黑线表示这些基函数的和。因为系数的值是随机选择的，我们可以将第二行的每个子面板看作是样条线空间上的先验分布的随机样本。"
  },
  {
    "objectID": "posts/BMCP_5/index.html#用-pasty-构建设计矩阵",
    "href": "posts/BMCP_5/index.html#用-pasty-构建设计矩阵",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.4.用 Pasty 构建设计矩阵",
    "text": "5.4.用 Pasty 构建设计矩阵\n以上绘制了B样条线，但没有说明如何计算它们。主要原因是计算可能很繁琐，而且在像Scipy这样的包中已经有了有效的算法。因此，我们不会讨论如何从头开始计算B样条线，而是依赖于Patsy，这是一个用于描述统计模型的包，特别是线性模型，或者有线性组件的模型，并构建设计矩阵。它深受R编程语言生态系统中广泛使用的 formula mini-language 启发。一个有两个协变量的线性模型可表示为\"y ~ x1 + x2\"，如果我们想要添加一个交互作用，我们可以写为\"y ~ x1 + x2 + x1:x2\"。更多的细节请查看patsy文档。\n在Patsy中，我们需要向dmatrix函数传递一个以 bs()开始的字符串来定义基样条设计矩阵，而这个particle虽然是一个字符串，但是被Patsy解析为一个函数。因此，它也可以接受几个参数，包括数据，一个表示节点位置的类数组，以及样条的度。在以下代码块中，我们定义了3个设计矩阵，一个是度为0的（分段常数），另一个是度为1的（分段线性），最后一个是度为3的（立方样条）。\nx = np.linspace(0., 1., 500)\nknots = [0.25, 0.5, 0.75]\n\nB0 = dmatrix(\"bs(x, knots=knots, degree=0, include_intercept=True) - 1\", \n             {\"x\": x, \"knots\":knots})\nB1 = dmatrix(\"bs(x, knots=knots, degree=1, include_intercept=True) - 1\",\n             {\"x\": x, \"knots\":knots})\nB3 = dmatrix(\"bs(x, knots=knots, degree=3,include_intercept=True) - 1\",\n             {\"x\": x, \"knots\":knots})\n\nfig, axes = plt.subplots(1, 3, sharey=True)\nfor idx, (B, title, ax) in enumerate(zip((B0, B1, B3),\n                                     (\"Piecewise constant\", \n                                      \"Piecewise linear\", \n                                      \"Cubic spline\"),\n                                      axes)):\n    cax = ax.imshow(B, cmap=\"cet_gray_r\", aspect=\"auto\")\n    ax.set_xticks(np.arange(B.shape[1]))\n    ax.set_yticks(np.arange(B.shape[0]))\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.set_title(title)\n\naxes[1].set_xlabel(\"b-splines\")\naxes[0].set_ylabel(\"x\", rotation=0, labelpad=15)\nfig.colorbar(cax, aspect=40, ticks=[0, 0.5, 1])"
  },
  {
    "objectID": "posts/BMCP_5/index.html#基于pymc拟合样条线",
    "href": "posts/BMCP_5/index.html#基于pymc拟合样条线",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.5. 基于PyMC拟合样条线",
    "text": "5.5. 基于PyMC拟合样条线\n以下使用来自加州大学欧文分校机器学习存储库的自行车共享系统的数据集。我们将估计24小时周期内各小时单车出租数量。\n\ndata = pd.read_csv(\"../data/bikes_hour.csv\")\ndata.sort_values(by=\"hour\", inplace=True)\n\n# We standardize the response variable\ndata_cnt_om = data[\"count\"].mean()\ndata_cnt_os = data[\"count\"].std()\ndata[\"count_normalized\"] = (data[\"count\"] - data_cnt_om) / data_cnt_os\n# Remove data, you may later try to refit the model to the whole data\ndata = data[::50]\n\n\n_, ax = plt.subplots(1, 1, figsize=(10, 4))\nax.plot(data.hour, data.count_normalized, \"o\", alpha=0.3)\nax.set_xlabel(\"hour\")\nax.set_ylabel(\"count_normalized\")\n\nText(0, 0.5, 'count_normalized')\n\n\n\n\n\n上图看起来，不同时间段单车出租数量的分布不同，因此我们可以使用样条线来拟合这些数据。我们选择6个节点来均分：\n\nnum_knots = 6\nknot_list = np.linspace(0, 23, num_knots+2)[1:-1]\n\n然后使用 Patsy 定义和构建设计矩阵\n\nB = dmatrix(\n    \"bs(cnt, knots=knots, degree=3, include_intercept=True) - 1\",\n    {\"cnt\": data.hour.values, \"knots\": knot_list[1:-1]})\n\n统计模型为： \\[\n\\begin{aligned}\n\\begin{split}\n    \\tau \\sim& \\; \\mathcal{HC}(1) \\\\\n    \\boldsymbol{\\beta} \\sim& \\; \\mathcal{N}(0, \\tau) \\\\\n    \\sigma \\sim& \\; \\mathcal{HN}(1) \\\\\n    Y \\sim& \\; \\mathcal{N}(\\boldsymbol{B}(X)\\boldsymbol{\\beta},\\sigma)\n\\end{split}\\end{aligned}\n\\]\n以上样条线回归模型与线性模型很像。最困难的工作已经通过设计矩阵 \\(\\boldsymbol{B}\\) 和它的扩展特征空间解决了。\n\nwith pm.Model() as splines:\n    τ = pm.HalfCauchy('τ', 1) \n    β = pm.Normal(\"β\", mu=0, sigma=τ, shape=B.shape[1])\n    μ = pm.Deterministic(\"μ\", pm.math.dot(np.asfortranarray(B), β))\n    σ = pm.HalfNormal(\"σ\", 1)\n    c = pm.Normal(\"c\", μ, σ, observed=data[\"count_normalized\"].values)\n    idata_s = pm.sample(1000, return_inferencedata=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [τ, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\npm.model_to_graphviz(splines)\n\n\n\n\n\n_, ax = plt.subplots(1, 1, figsize=(10, 4))\nax.set_prop_cycle(cycler('color', viridish))\nposterior = idata_s.posterior.stack(samples=['chain', 'draw'])\nax.plot(data.hour, (B*posterior[\"β\"].mean(\"samples\").values * data_cnt_os) + data_cnt_om, lw=2, ls='--')\nax.plot(data.hour, posterior[\"μ\"].mean(\"samples\") * data_cnt_os + data_cnt_om, 'k', lw=3)\nax.set_xlabel(\"hour\")\nax.set_ylabel(\"count\")\nax.plot(knot_list, np.zeros_like(knot_list), 'ko')\n\n\n\n\n使用重叠样条曲线及其不确定性来绘制数据，结果会更加明显。从这个图中我们不难看出，深夜时租赁自行车的数量是最低的。然后可能会随着人们起床去上班而增加。我们在 10 点左右出现第一个高峰，随后趋于平稳，或者可能略有下降，然后随着人们在 18 点左右上下班回家，出现第二个高峰，此后出现稳定下降。\n\n_, ax = plt.subplots(1, 1, figsize=(10, 4))\n\nax.plot(data.hour, data[\"count\"], \"o\", alpha=0.3, zorder=-1)\n# we use data_cnt_os and data_cnt_om to rescale the cnt data and results\nax.plot(data.hour, (posterior[\"μ\"].mean(\"samples\")  * data_cnt_os) + data_cnt_om, color=\"C4\", lw=2)\naz.plot_hdi(data.hour, (posterior[\"μ\"].T  * data_cnt_os) + data_cnt_om,\n            color=\"C0\", smooth=False)\nax.set_xlabel(\"hour\")\nax.set_ylabel(\"count\")\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n\n\nText(0, 0.5, 'count')\n\n\n\n\n\n在这个自行车租赁的例子中，我们正在处理一个循环变量，也就是说第0小时等于第24小时。这对我们来说可能很明显，但是对我们的模型来说肯定不明显。Patsy提供了一个简单的解决方案来告诉我们的模型这个变量是循环的。我们可以使用cc来定义设计矩阵，而不是使用bs，这是一个circular-aware的立方样条。"
  },
  {
    "objectID": "posts/BMCP_5/index.html#为样条线选择结-knots-和先验-prior",
    "href": "posts/BMCP_5/index.html#为样条线选择结-knots-和先验-prior",
    "title": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines",
    "section": "5.6. 为样条线选择结 Knots 和先验 Prior",
    "text": "5.6. 为样条线选择结 Knots 和先验 Prior\n使用养条线建模是我们需要选择 knots 的数量和位置。我们依然可以使用 LOO 来比较哪种选择更好。以下分别使用 3，6，9，12 和 18 个 knots 来拟合数据，然后使用 LOO 比较它们。可以发现12个 Knots 效果最好。\n\n一种有效的建议是根据分位数来划分 knots 而不是均分。比如 knot_list = np.quantile(data.hour, np.linspace(0, 1, num_knots)) 。通过这种方式，我们将在数据较多的地方放置更多的 knots，在数据较少的地方放置更少的 knots。让数据更丰富部分的更灵活的近似。\n\n5.6.1. 样条的正则化先验\n选择太少的节点可能会导致欠拟合，选择太多的节点可能会导致过拟合，因此我们可能希望使用相当大的节点数量，然后选择一个正则化先验。从样条的定义和上图我们可以看到，连续的 \\(\\boldsymbol{\\beta}\\) 系数越接近彼此，得到的函数就会越平滑。想象一下，如果你在上图的设计矩阵中删除了两列连续的列，实际上将这些系数设置为 0，拟合将会变得不够平滑，因为我们在预测器中没有足够的信息来覆盖某个子区域（回想一下，样条是局部的）。因此，我们可以通过为 \\(\\boldsymbol{\\beta}\\) 系数选择一个先验，使得 \\(\\beta_{i+1}\\) 的值与 \\(\\beta_{i}\\) 的值相关，从而得到更平滑的拟合回归线:\n\\[\n\\begin{aligned}\n\\begin{split}\n\\beta_i \\sim& \\mathcal{N}(0, 1) \\\\\n\\tau\\sim& \\mathcal{N}(0,1) \\\\\n\\beta \\sim& \\mathcal{N}(\\beta_{i-1}, \\tau)\n\\end{split}\\end{aligned}\n\\]\n通过 PyMC 我们可以用高斯随机过程来表达：\n\\[\n\\begin{aligned}\n\\begin{split}\n\\tau\\sim& \\mathcal{N}(0, 1) \\\\\n\\beta \\sim& \\mathcal{G}RW(\\beta, \\tau)\n\\end{split}\\end{aligned}\n\\]\n我们基于高斯随机过程来建模：\n\nknot_list = np.arange(1, 23)\n\nB = dmatrix(\n    \"bs(cnt, knots=knots, degree=3, include_intercept=True) - 1\",\n    {\"cnt\": data.hour.values, \"knots\": knot_list},\n)\n\nwith pm.Model() as splines_rw:\n    τ = pm.HalfCauchy('τ', 1) \n    β = pm.GaussianRandomWalk(\"β\", mu=0, sigma=τ, shape=B.shape[1])\n    μ = pm.Deterministic(\"μ\", pm.math.dot(np.asfortranarray(B), β))\n    σ = pm.HalfNormal(\"σ\", 1)\n    c = pm.Normal(\"c\", μ, σ, observed=data[\"count_normalized\"].values)\n    idata_splines_rw = pm.sample(1000)\n    idata_splines_rw.extend(pm.sample_posterior_predictive(idata_splines_rw))\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/pymc/distributions/timeseries.py:293: UserWarning: Initial distribution not specified, defaulting to `Normal.dist(0, 100)`.You can specify an init_dist manually to suppress this warning.\n  warnings.warn(\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [τ, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\nSampling: [c]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n对比普通正态先验：\n\nwith pm.Model() as wiggly:\n    τ = pm.HalfCauchy('τ', 1) \n    β = pm.Normal(\"β\", mu=0, sigma=τ, shape=B.shape[1])\n    μ = pm.Deterministic(\"μ\", pm.math.dot(np.asfortranarray(B), β))\n    σ = pm.HalfNormal(\"σ\", 1)\n    c = pm.Normal(\"c\", μ, σ, observed=data[\"count_normalized\"].values)\n    idata_wiggly = pm.sample(1000)\n    idata_wiggly.extend(pm.sample_posterior_predictive(idata_wiggly))\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [τ, β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n_, ax = plt.subplots(1, 1, figsize=(10, 4))\n\nax.plot(data.hour, data[\"count\"], \"o\", alpha=0.1, zorder=-1)\n\nwiggly_posterior = (idata_wiggly.posterior[\"μ\"] * data_cnt_os) + data_cnt_om\nmean_f = wiggly_posterior.mean(dim=['chain', 'draw'])\nax.plot(data.hour, mean_f , color=\"C0\", lw=3)\n\nsplines_rw = (idata_splines_rw.posterior[\"μ\"] * data_cnt_os) + data_cnt_om\nmean_f = splines_rw.mean(dim=['chain', 'draw'])\nax.plot(data.hour, mean_f, color=\"C4\", lw=3)\n\nax.set_xlabel(\"hour\")\nax.set_ylabel(\"count\")\n\nText(0, 0.5, 'count')\n\n\n\n\n\n我们可以看到，具有平滑先验的样条模型 splines_rw 的样条均值函数（蓝线）比没有平滑先验的样条均值函数（黑色）要平滑，尽管我们承认差异似乎相当小。"
  },
  {
    "objectID": "posts/高斯过程/index.html",
    "href": "posts/高斯过程/index.html",
    "title": "什么是高斯过程",
    "section": "",
    "text": "我们经常遇到这样的推断数据：\n\\[\\mathcal{D} = \\{(\\boldsymbol{x_i},y_i)|i=1,\\ldots,n, \\boldsymbol{x_i} \\in \\mathcal{X}, y_i \\in \\mathbb{R}\\}\\]\n其中 \\(\\boldsymbol{x_i}\\) 是输入，而 \\(y_i\\) 是目标输出，我们希望预测新的输入 \\(\\boldsymbol{x_*}\\) 的输出 \\(y_*\\)。\n从贝叶斯的角度来看，我们可以构建一个模型来定义所有可能函数的分布\\((f: \\mathcal{X} \\rightarrow \\mathbb{R})\\)。我们可以将初始信念编码为这些函数的先验。基于观测数据和贝叶斯定理来推断后验分布。然后基于后验得到输入 \\(\\boldsymbol{x_*}\\) 的对 \\(y_*\\) 的预测分布。\n高斯过程 Gaussian processes (GPs) 是一种函数的概率分布。对于这种分布，我们可以进行可行的推断。\n它们可以被视为高斯概率分布到函数空间的推广。即多元高斯分布定义了有限随机变量集的分布，高斯过程定义了无限随机变量集（例如实数）的分布。GP域不限于实数，任何具有点积的空间都适用。\n与多元高斯分布类似，GP 由其均值 \\(\\mu\\) 和协方差 \\(k\\) 定义。但是对于 GP，这些是函数，而不是向量，即 \\(\\mu: \\mathcal{X} \\rightarrow \\mathbb{R}\\) 和 \\(k: \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}\\)。\n为方便又不是一般性，下面说明中我们假设均值为零，即 \\(\\mu(\\boldsymbol{x}) = 0\\)。\n上图来自具有相同均值和协方差函数的两个高斯过程的样本。这里有 \\(\\mathcal{X} = \\mathbb{R}\\)。先验样本来自没有任何数据的高斯过程，后验样本取自有观测数据高斯过程，其中数据显示为黑色方块。黑色虚线代表过程的平均值，灰色阴影区域覆盖每个输入的标准偏差的两倍。彩色线条是来自过程的样本。\n生成样本的代码如下："
  },
  {
    "objectID": "posts/高斯过程/index.html#协方差函数-k",
    "href": "posts/高斯过程/index.html#协方差函数-k",
    "title": "什么是高斯过程",
    "section": "协方差函数 \\(k\\)",
    "text": "协方差函数 \\(k\\)\n假设均值函数为0，则 GP 由观测数据 \\(\\mathcal{D}\\) 和 协方差函数 \\(k\\) 决定。观测数据是确定的，因此我们只需要定义协方差函数。\n幸运的是，我们有一个庞大的可能协方差函数库，每个协方差函数代表函数空间上的不同先验。\n\n\n\n从具有相同数据和不同协方差函数的 GP 中抽样。不同协方差函数的 GP 后验的样本具有不同的特征。periodic 协方差函数的主要特征是具有周期性。其他协方差函数以不同的方式影响样本的平滑度。\n产生样本的代码如下：\nfrom numpy.random import seed\nfrom infpy.gp import GaussianProcess, gp_1D_X_range, gp_plot_samples_from\nfrom pylab import plot, savefig, title, close, figure, xlabel, ylabel\nfrom infpy.gp import SquaredExponentialKernel as SE\nfrom infpy.gp import Matern52Kernel as Matern52\nfrom infpy.gp import Matern52Kernel as Matern32\nfrom infpy.gp import RationalQuadraticKernel as RQ\nfrom infpy.gp import NeuralNetworkKernel as NN\nfrom infpy.gp import FixedPeriod1DKernel as Periodic\nfrom infpy.gp import noise_kernel as noise\n\n# seed RNG to make reproducible and close all existing plot windows\nseed(2)\nclose('all')\n\n#\n# Part of X-space we will plot samples from\n#\nsupport = gp_1D_X_range(-10.0, 10.01, .125)\n\n#\n# Data\n#\nX = [[-5.], [-2.], [3.], [3.5]]\nY = [2.5, 2, -.5, 0.]\n\ndef plot_for_kernel(kernel, fig_title, filename):\n  figure()\n  plot([x[0] for x in X], Y, 'ks')\n  gp = GaussianProcess(X, Y, kernel)\n  gp_plot_samples_from(gp, support, num_samples=3)\n  xlabel('x')\n  ylabel('f(x)')\n  title(fig_title)\n  savefig('%s.png' % filename)\n  savefig('%s.eps' % filename)\n  \nplot_for_kernel(\n  kernel=Periodic(6.2),\n  fig_title='Periodic',\n  filename='covariance_function_periodic'\n)\n\nplot_for_kernel(\n  kernel=RQ(1., dimensions=1),\n  fig_title='Rational quadratic',\n  filename='covariance_function_rq'\n)\n\nplot_for_kernel(\n  kernel=SE([1]),\n  fig_title='Squared exponential',\n  filename='covariance_function_se'\n)\n\nplot_for_kernel(\n  kernel=SE([3.]),\n  fig_title='Squared exponential (long length scale)',\n  filename='covariance_function_se_long_length'\n)\n\nplot_for_kernel(\n  kernel=Matern52([1.]),\n  fig_title='Matern52',\n  filename='covariance_function_matern_52'\n)\n\nplot_for_kernel(\n  kernel=Matern32([1.]),\n  fig_title='Matern32',\n  filename='covariance_function_matern_32'\n)"
  },
  {
    "objectID": "posts/高斯过程/index.html#协方差函数和噪音数据的结合",
    "href": "posts/高斯过程/index.html#协方差函数和噪音数据的结合",
    "title": "什么是高斯过程",
    "section": "协方差函数和噪音数据的结合",
    "text": "协方差函数和噪音数据的结合\n此外，协方差函数的逐点乘积和本身就是协方差函数。通过这种方式，我们可以组合简单的协方差函数来表示我们对函数的更复杂的信念。\n通常我们正在对一个我们实际上无法获取的目标值 \\(y\\) 建模，我们只有它的有噪音版本 \\(y+\\epsilon\\)。\n如果我们假设 \\(\\epsilon\\) 是一个方差为 \\(\\sigma_n^2\\) 的高斯分布，我们就能将噪音合并进协方差函数中。\n我们的带噪声的高斯过程（noisy GP）的协方差函数 \\(k_{\\textrm{noise}}(x_1,x_2)\\) 需要能够识别输入 \\(x_1\\) 和 \\(x_2\\) 是否相同，因为我们可能在 \\(\\mathcal{X}\\) 的同一点有两个带噪声的测量值。 \\[k_{\\textrm{noise}}(x_1,x_2) = k(x_1,x_2) + \\delta(x_1=x_2) \\sigma_n^2\\\\]\n  \n生成上图的代码：\nfrom numpy.random import seed\nfrom infpy.gp import GaussianProcess, gp_1D_X_range, gp_plot_prediction\nfrom pylab import plot, savefig, title, close, figure, xlabel, ylabel\nfrom infpy.gp import SquaredExponentialKernel as SE\nfrom infpy.gp import noise_kernel as noise\n\n# close all existing plot windows\nclose('all')\n\n#\n# Part of X-space we are interested in\n#\nsupport = gp_1D_X_range(-10.0, 10.01, .125)\n\n#\n# Data\n#\nX = [[-5.], [-2.], [3.], [3.5]]\nY = [2.5, 2, -.5, 0.]\n\ndef plot_for_kernel(kernel, fig_title, filename):\n  figure()\n  plot([x[0] for x in X], Y, 'ks')\n  gp = GaussianProcess(X, Y, kernel)\n  mean, sigma, LL = gp.predict(support)\n  gp_plot_prediction(support, mean, sigma)\n  xlabel('x')\n  ylabel('f(x)')\n  title(fig_title)\n  savefig('%s.png' % filename)\n  savefig('%s.eps' % filename)\n  \nplot_for_kernel(\n  kernel=SE([1.]) + noise(.1),\n  fig_title='k = SE + noise(.1)',\n  filename='noise_mid'\n)\n\nplot_for_kernel(\n  kernel=SE([1.]) + noise(1.),\n  fig_title='k = SE + noise(1)',\n  filename='noise_high'\n)\n\nplot_for_kernel(\n  kernel=SE([1.]) + noise(.0001),\n  fig_title='k = SE + noise(.0001)',\n  filename='noise_low'\n)"
  },
  {
    "objectID": "posts/高斯过程/index.html#学习协方差函数参数",
    "href": "posts/高斯过程/index.html#学习协方差函数参数",
    "title": "什么是高斯过程",
    "section": "学习协方差函数参数",
    "text": "学习协方差函数参数\n大多数常用的协方差函数都是参数化的。如果我们对问题的理解有信心，则可以使用固定参数。或者我们可以将它们视为贝叶斯推理任务中的超参数，并通过最大似然估计或共轭梯度下降等技术对其进行优化。\n \n我们看到第二张图中的预测似乎更准确地拟合数据，这是学习超参数的效果。\n生成上图的代码：\nfrom numpy.random import seed\nfrom infpy.gp import GaussianProcess, gp_1D_X_range\nfrom infpy.gp import gp_plot_prediction, gp_learn_hyperparameters\nfrom pylab import plot, savefig, title, close, figure, xlabel, ylabel\nfrom infpy.gp import SquaredExponentialKernel as SE\nfrom infpy.gp import noise_kernel as noise\n\n# close all existing plot windows\nclose('all')\n\n#\n# Part of X-space we are interested in\n#\nsupport = gp_1D_X_range(-10.0, 10.01, .125)\n\n#\n# Data\n#\nX = [[-5.], [-2.], [3.], [3.5]]\nY = [2.5, 2, -.5, 0.]\n\ndef plot_gp(gp, fig_title, filename):\n  figure()\n  plot([x[0] for x in X], Y, 'ks')\n  mean, sigma, LL = gp.predict(support)\n  gp_plot_prediction(support, mean, sigma)\n  xlabel('x')\n  ylabel('f(x)')\n  title(fig_title)\n  savefig('%s.png' % filename)\n  savefig('%s.eps' % filename)\n  \n#\n# Create a kernel with reasonable parameters and plot the GP predictions\n#\nkernel = SE([1.]) + noise(1.)\ngp = GaussianProcess(X, Y, kernel)\nplot_gp(\n  gp=gp,\n  fig_title='Initial parameters: kernel = SE([1]) + noise(1)',\n  filename='learning_first_guess'\n)\n\n#\n# Learn the covariance function's parameters and replot\n#\ngp_learn_hyperparameters(gp)\nplot_gp(\n  gp=gp,\n  fig_title='Learnt parameters: kernel = SE([%.2f]) + noise(%.2f)' % (\n    kernel.k1.params[0],\n    kernel.k2.params.o2[0]\n  ),\n  filename='learning_learnt'\n)"
  },
  {
    "objectID": "posts/高斯过程/index.html#参考资料",
    "href": "posts/高斯过程/index.html#参考资料",
    "title": "什么是高斯过程",
    "section": "参考资料",
    "text": "参考资料\nWhat are Gaussian processes?"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html",
    "href": "posts/贝叶斯和多臂老虎机/index.html",
    "title": "贝叶斯和多臂老虎机",
    "section": "",
    "text": "多臂老虎机是一个在探索(exploration)和开发(exploitation)过程中寻找最高收益的问题。此类“实验”能力几乎已经成为了优秀实验平台的标配。\n本篇是阅读《A modern Bayesian look at the multi-armed bandit》后结合个人理解的学习总结。它总结了基于贝叶斯的随机概率匹配法和其它相关方法。"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html#背景",
    "href": "posts/贝叶斯和多臂老虎机/index.html#背景",
    "title": "贝叶斯和多臂老虎机",
    "section": "",
    "text": "多臂老虎机是一个在探索(exploration)和开发(exploitation)过程中寻找最高收益的问题。此类“实验”能力几乎已经成为了优秀实验平台的标配。\n本篇是阅读《A modern Bayesian look at the multi-armed bandit》后结合个人理解的学习总结。它总结了基于贝叶斯的随机概率匹配法和其它相关方法。"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html#随机概率匹配rpm",
    "href": "posts/贝叶斯和多臂老虎机/index.html#随机概率匹配rpm",
    "title": "贝叶斯和多臂老虎机",
    "section": "1. 随机概率匹配（RPM）",
    "text": "1. 随机概率匹配（RPM）\n定义\\(Y_t = (y_1, ..., y_t)\\)代表t时为止的奖励序列，\\(a_t\\)代表t时选择的臂，t时刻奖励\\(y_t \\sim f_{a_t}(y|\\theta)\\)，\\(\\theta\\)是一个未知向量。\n\\(y_t \\in (0, 1)\\)情况下两种例子：\n\n伯努利老虎机，\\(\\theta = (\\theta_1, ...,\\theta_k)\\)，\\(f_{a_t}(y|\\theta)\\)参数为\\(\\theta_a\\)\n\nfractional factorial bandit（本文不关注）\n\n定义\\(\\mu_a(\\theta) = E(y_t | \\theta, a_t = a)\\)是\\(f_{a}(y|\\theta)\\)的期望值，最佳策略应该一直选择\\(\\mu_a(\\theta)\\)最大的臂。\n在伯努利分布下，\\(\\theta_a = \\mu_a(\\theta)\\)。\n定义\\(p(\\theta)\\)是\\(\\theta\\)的先验概率密度，此时以$p() \\(产生\\)\\(，\\)$产生y，则0时刻选择a正确概率：\n\\[w_{a0} = Pr(\\mu_a = max\\{\\mu_1,... \\})\\]\n定义\\(I_a(\\theta)\\)为指示函数，\\(\\mu_a = max\\{\\mu_1,...\\mu_k\\}\\)时\\(I_a(\\theta)=1\\)：\n\\[w_{a0} = E(I_a(\\theta)) = \\int I_a(\\theta) p(\\theta) d\\theta\\]\n\n\n\n一个例子，先验可以Beta分布，两臂时为二元\n\n\n如果没有关于\\(\\theta\\)的先验，则先验视为各个\\(\\mu\\)是一样的，\\(w_{a0}\\)是均匀分布。\n观测到奖励情况后，通过贝叶斯方法进行更新，\\(p(\\theta | Y_t ) = \\frac{p(Y_t|\\theta)p(\\theta)}{p(Y_t)}\\)。t时刻：\n\\[p(\\theta | Y_t  ) \\propto  p(\\theta)\\prod _{\\tau = 1}^t f_{a_\\tau}(y|\\theta)\\] 则此时$w_{at} = Pr(_a = max{_1,…} | Y_t ) = E(I_a() | Y_t ) $ （4）\n随机概率匹配用\\(w_{at}\\)来分配a的t+1时观测值，通过一种自然平衡探索与开发的方式。\n\n1.1 概率分配计算\n如果\\(\\theta^{(1)},...,\\theta^{(G)}\\)是来自\\(p(\\theta|Y_t)\\)的独立抽样，则基于大数定理：\n\\[w_{at} = \\lim_{g\\rightarrow \\infty }\\frac{1}{G}\\sum^G_{g=1}I_a(\\theta^g)\\]\n如果\\(f_a\\)是指数族，而且\\(p(\\theta)\\)是它的共轭分布，则可以独立的抽样\\(\\theta\\)，否则可以用马可夫相关的方法进行抽样模拟。\n\\(\\theta\\)的后验抽样足够对概率匹配进行支持。\n\n\n1.2 隐式分配\n（5）可以不用显式计算，从\\(p(\\theta|Y_t)\\)模拟 \\(\\theta^{t}\\)，并选择\\(a = argmax_a\\mu_a(\\theta^t)\\)\n\n\n1.3 探索(exploration)、开发(exploitation)和不确定性\n随机概率匹配自然的包含了不确定性，下图为两臂情况下的情况：\n\n在(a)中，错误选中概率为18%；在(b)中，错误选中概率为0.8%。\n这个例子说明，随着学习的进行，探索的占比会减少。"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html#其它方法",
    "href": "posts/贝叶斯和多臂老虎机/index.html#其它方法",
    "title": "贝叶斯和多臂老虎机",
    "section": "2. 其它方法",
    "text": "2. 其它方法\n\n2.1 The Gittins index(基廷斯指数)\n此方法假设单臂未来的奖励会与一个几何分布有关：\\(\\sum_{t = 0} ^ {\\infty} \\gamma ^ty_t\\)，其中\\(0 \\leq \\gamma &lt; 1\\)\n基廷斯提供了一种计算各个臂价值的算法，得到的结果称为基廷斯指数。它在前提可保证时是最优方案。\n\n\n这部分的数学相关很复杂先跳过，简单了解可参考《算法之美》第二章相关部分。\n对基廷斯指数的三个问题：\n1. 不完全学习，可能最终收敛到次优解；\n2. 各臂的参数需要是固定的；\n3. 奖励减少结构必须是几何分布。\n\n\n2.2 UCB算法(Upper Confidence Bounds)\n计算每个手臂奖励均值及置信区间上限，然后选上限最高的手臂。\n值得注意的是，此上限并不是常见的置信区间算法，而且比较难计算。\n\n\n2.3 启发式策略\n\n2.3.1 平均分配\n次策略均匀的探索每个臂，直到其中一个臂奖励超过某个阈值，然后一直选择此臂。这种方法对\\(\\theta\\)探索效果很好，但是前期成本高，导致整体奖励效果较差。类似于先进行一轮随机实验评估效果，然后选择效果最好的方案。\n\n2.3.2 连胜就继续，输了就换其它\n至少好于随机选择……当最优秀的策略效果也没有特别好时，此方案会过度探索，导致效果很差。\n\n2.3.3 贪心策略\n简单的贪心策略效果很差，比较好的是deterministic probability matching做法。但是在批量更新场景，一个更新周期只能探索一种方案，所以前期会表现特别差。\n\n2.3.4 混合策略\n混合策略是贪心之外，强制进行一定比例的探索，比如Epsilon-greedy或Epsilon-decreasing。不过上两种方法的敏感度不够高，因此还可以参考Softmax learning方法。\n\n\n\n2.4 与概率匹配的对比\n概率匹配结合了2.3中的多种好处。"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html#伯努利老虎机上使用不同策略的对比",
    "href": "posts/贝叶斯和多臂老虎机/index.html#伯努利老虎机上使用不同策略的对比",
    "title": "贝叶斯和多臂老虎机",
    "section": "3. 伯努利老虎机上使用不同策略的对比",
    "text": "3. 伯努利老虎机上使用不同策略的对比\n定义\\(\\theta = (\\theta_1, ...,\\theta_k)\\)，先验为\\(\\theta_a \\sim U(0, 1)\\)，它们之间相互独立。\n\\(Y_{at},N_{at}\\)分别代表t时刻a的累计成功次数和观测次数。\n则\\(\\theta = (\\theta_1, ...,\\theta_k)\\)的后验为：\n\\[p(\\theta|Y_t) =\\prod ^k_{a=1}Be(\\theta_a|Y_{at}+1,N_{at} - Y_{at} + 1)\\]\n其中\\(B_e(\\theta|\\alpha, \\beta)\\)是贝塔分布。此时最佳概率为：\n\\[w_{at} = \\int_{0}^{1}Be(\\theta_a|Y_{at}+1,N_{at} - Y_{at} + 1)\\prod_{j\\neq a}Pr(\\theta_j &lt; \\theta_a | Y_{jt} + 1 - N_{jt} - Y_{jt} + 1)d\\theta_a\\]\n验证主要关注regret，最佳选择\\(\\mu^*(\\theta) = max_a\\{\\mu_a(\\theta) \\}\\)，手臂a在t时刻的观测次数为\\(n_{at}\\)，则t时刻的regret为：\n\\[L_t = \\sum_an_{at}(\\mu^*(\\theta) - \\mu_a(\\theta)) \\]\n则T时段累计regret为\\(L = \\sum_{t= 1}^TL_t\\)。以下是一些模拟对比结果。\n\n3.1 批量更新场景\n\n3.1.1 RPM对比平均分配\n  \n从测试数据看RPM会比后者好得多。\n\n\n3.1.2 RPM对比贪心\n \n可发现在批量更新场景，两种贪心策略效果都是比RPM差的。\n\n\n\n3.2 实时更新场景\n\n平均效果来看，RPM效果最差，但是它的标准差最小，最优解命中率最高；参数为0.999的Gittins index平均效果最好，标准差较大，且最优解的命中率低于RPM。"
  },
  {
    "objectID": "posts/贝叶斯和多臂老虎机/index.html#后记",
    "href": "posts/贝叶斯和多臂老虎机/index.html#后记",
    "title": "贝叶斯和多臂老虎机",
    "section": "后记",
    "text": "后记\nRPM可以用来解决多臂老虎机问题，它基于后验抽样，易于实现、健壮性好，且在批量更新场景表现更佳。"
  },
  {
    "objectID": "posts/app新版本效果/index.html",
    "href": "posts/app新版本效果/index.html",
    "title": "因果推断：准实验法评估App新版本增益",
    "section": "",
    "text": "做A/B实验相关工作中遇到一些问题，其中之一就是如何判断新版本对用户影响，以前的做法：\n1.所有新功能都预埋开关(默认关)，对新版本用户随机分桶后对实验组开启，用标准A/B实验方法评估。但是这在需要很高开发成本，而且容易出错； 2.同时构建两个新版本，a版本不包含任何新功能，b版本包含全部新功能，对用户随机分桶后，分别开放不同版本的升级，之后对a版本用户、b版本用户用随机实验法进行评估。这也需要较高成本，而且对第三方渠道不能自由控制用户是否可以，仅能用在灰度发布阶段，样本量较小； 3.随机分桶后，仅对实验组开放升级，之后与对照组对比，并可对实验组中升级用户作为训练集，通过机器学习方法判断对照组中愿意升级的用户，对他们进行评估。本方法同样存在2中的问题，只是免去了打a版本发布的过程。\n上述问题都有实现难度、成本方面、样本量的问题，那么有没有办法不改变发布流程，科学的评估效果呢？有，LinkedIn用准实验方法做过相同的事情：Evaluating Mobile Apps with A/B and Quasi A/B tests。下面记录下我的个人理解。"
  },
  {
    "objectID": "posts/app新版本效果/index.html#常用的准实验技术",
    "href": "posts/app新版本效果/index.html#常用的准实验技术",
    "title": "因果推断：准实验法评估App新版本增益",
    "section": "1. 常用的准实验技术",
    "text": "1. 常用的准实验技术\n\nOLS类方法 假设指标服从线性模型：\\(Y = \\beta_0 + Z\\beta_1 + X\\beta_2 + \\epsilon\\)\n其中\\(Y = (Y_1,...Y_n)^T\\)是每个用户的结果数据， \\(Z = (Z_1,...Z_n)^T\\)为0/1代表是否接受干预，\\(X = (X_1,...X_n)^T\\)是\\(Y\\)和\\(Z\\)所有相关协变量的矩阵。在此模型下，\\(\\beta_1\\)是干预的影响效果。\n此时如果忽略\\(X\\)，\\(\\beta_1\\)的OLS估计是有偏的，偏差为：\\(bias = (D^TD)^{-1}D^TX\\beta_2\\), \\(D = (1, Z)\\)\n如果将影响\\(Z\\)、\\(Y\\)的协变量作为\\(X\\)带入公式，偏差就可以变小，但是无法证明所有影响因子都包含在了\\(X\\)中。\n\n\n可以优化的点：\n\n效果可能是非线性的，在拟合模型前做Box-Cox transformation；\n泛化为endogenous switching model，对升级和不升级分别拟合： $Y_1 = X_1 _1 + _1 if Z=1 $ $Y_0 = X_0 _0 + _0 if Z=0 $\n\n\n\n基于倾向的方法 偏差基于用户升级的概率进行修正。倾向得分一般通过逻辑回归估计：\\(P(Z=1|X=x) = \\frac{e^{x\\beta}}{1 + e^{x\\beta}}\\)\n分数可以用于：1.匹配或分类，可以构建分层，使每层X与Y相关性减弱；2.计算权值，用逆概率加权方法，将\\(\\frac{ 1 }{P(Z_i=1|X)}\\)作为升级用户权值，将\\(\\frac{1}{P(Z_i=0|X)}\\)作为非升级用户权值，构建反事实输出。"
  },
  {
    "objectID": "posts/app新版本效果/index.html#ios的升级研究",
    "href": "posts/app新版本效果/index.html#ios的升级研究",
    "title": "因果推断：准实验法评估App新版本增益",
    "section": "1. iOS的升级研究",
    "text": "1. iOS的升级研究\n由于当时苹果市场只支持全量发布，是否升级对是用户自身影响因素决定的，所以是一个经典的准实验问题，可以用上述方法解决。关于方案效果测试，可以对之前没有附带新功能的版本进行”A/A”，看能否有效消除偏差。\n\n两个值得注意的点：\n\nwifi的影响 测试发现，很多用户在有wifi的情况下，会自动或者主动升级。有无wifi是一个随机不可预测的时间，所以用户什么时候会升级也不可预测。导致上图的红色曲线，7天来看AUC较高，短期来看AUC较低。此时将预测升级概率很高但是没有升级的用户作为噪音移除，可以得到绿色曲线。\n选择正确的特征 比如将设备版本信息从特征集中移除，曲线就会变成蓝色那条，效果很差。 \n\n测试结果：\n从上图可看到，bias大幅降低，endogenous OLS模型效果最好。"
  },
  {
    "objectID": "posts/app新版本效果/index.html#android的升级研究",
    "href": "posts/app新版本效果/index.html#android的升级研究",
    "title": "因果推断：准实验法评估App新版本增益",
    "section": "2. Android的升级研究",
    "text": "2. Android的升级研究\n谷歌市场可以分阶段配置发布比例，提供给老用户和新用户下载安装，这依然不符合A/B实验要求。\n图中A1、B1代表愿意升级的用户，其它为不愿意升级用户，而A1、A2代表有资格升级的用户(在分阶段发布里命中)，也就是仅有A1群体成功升级。在用户意愿和分阶段发布共同作用下，上述iOS的方案会表现很差。\n这种机制带来了另一种好处，比如在20%放量阶段，对每个升级者来说，期望有4个与他相似的用户。如果我们识别出其它相似用户，那就可以近似为随机实验。所以需要一种低假阳性的识别方法，哪怕假阴性较高(因为有4个相似用户，召回率没有那么重要)。\n\n假设有个选择标准\\(S\\)用于识别升级用户，将它用于A1、A2 + B1 + B2。在高假阳性，低假阴性情况下： \\(S(A_1) = A_1\\) \\(S(A_2 + B_1 + B_2) = S(A_2) + B_1 + S(B_2) &gt; B_1\\) 但是如果低假阳性，高假阴性： \\(S(A_1) \\subset A_1\\) \\(S(A_2 + B_1 + B_2) = S(B_1) \\subset B_1\\)\n\n由于A1与B1是可比较的，S(A1)与S(B1)也是可以比较的，下面介绍两种基于此的策略。\n\n2.1. 几何分布模型\n思路是将愿意升级用户B1从未升级用户中识别出，不同于iOS那边将升级用户参与模型训练，这里仅使用历史数据来训练，对识别出的用户再按是否升级，判断是否属于B1。 由于随着时间推进，用户升级的概率越来越高，我们需要建模获取\\(P_{it}\\)，代表i个用户t日升级概率。假设每日概率恒定为\\(P_i\\)，则：\n\\(P_{it} = (1 - P_i)^{a_{it} - 1}P_i\\)，其中\\(a_{it}\\)代表活跃天数。\n基于历史数据，可以计算\\(P_i\\)的最大似然估计：\n\\(\\hat{P_i} = \\argmax_{P_i}\\prod ^s_{j=1}(1 - P_i)^{k_{ij} - 1}P_i^{I_{ij}} = \\frac{\\sum_jI_{ij}}{\\sum_jI_{ij} + \\sum_jk_{ij}}\\)\n\\(k_{ij}\\)代表用户i在可以升级版本j到升级版本j前的活跃天数，\\(I_{ij}\\)代表用户i是否升级了版本j。\n最后，在发布新版本后，每个用户每天计算累计概率\\(1 - (1 - \\hat{P_i})^{a_{it}}\\)。选择超过阈值的用户认为是会升级用户。\n\n测试结果看，一周来看几乎可以矫正所有的选择性偏差。但是开始几天精度比较低。\n\n\n2.2. Doubly Robust with Matching\n由于非升级组有更多的用户与升级用户相似，直接通过协变量将他们与升级用户匹配变得更容易。最基础的两种匹配方法：\n\n精准匹配：用协变量的值精准匹配；\nNearest neighbor匹配：选择与升级用户距离最近的潜在升级用户。几种方法：(1)局部贪心方法选择最匹配那一个，但是这会与升级用户顺序相关；(2)全局最优方法。\n\n两种策略都不容易通过GPU运算，尤其在有大量协变量时，带来性能上的问题。\n因此，LinkedIn采取了“Doubly Robust” 方法，先进行匹配算法，在其基础之上进行线性回归。第一阶段仅适用10个重要的连续变量进行匹配分桶，线性回归阶段有大量的协变量，对偏斜进行补偿。此方法可以从第一天起就有不错的表现，是LinkedIn的最终方案。\n\n具体步骤：\n\n选择不被升级影响的变量；\n对于所有变量，确保采用者和非采用者群体的共同支持；\n选择10个用于执行精准匹配的变量；\n用于精确匹配的协变量被分桶以减少它们的基数；\n利用endogenous switching model 对匹配的样本中的升级用户、非升级用户分别进行加权线性回归，训练得到两个模型。在将全部匹配用户带入两个模型，两个模型的输出带入反事实框架。最终结果估计：\n\\(DRE = \\frac{1}{\\sum^n_{i=1}w_i} (\\sum^m_{i=1}w_i({y_i - \\hat{y_i}^{0}}) + \\sum^n_{i=m+1}w_i({ \\hat{y_i}^{1} - y_i}) )\\) 其中\\(w_i\\)权重来自匹配阶段，不是一般性1~m代表升级用户。\n\n\n\n\n\nBias of the doubly robust with matching model. Both are for Android 20% roll out.\n\n\n结果看起来很棒，在第一天也只有很小的偏差。"
  },
  {
    "objectID": "posts/app新版本效果/index.html#新奇效应",
    "href": "posts/app新版本效果/index.html#新奇效应",
    "title": "因果推断：准实验法评估App新版本增益",
    "section": "3. 新奇效应",
    "text": "3. 新奇效应\n大的变更会有强的新奇效应，用户开始阶段会进行很多探索。\n需要判断两个问题：1.是否有新奇效应；2.新奇效应持续多久？\n标准ab实验中，可以观测随着效果随着时间的推移是否变弱，以此来判断。在准实验方法中，结合上文相关方法，也可以进行类似的判断。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html",
    "href": "posts/破产问题和简单序贯检验/index.html",
    "title": "赌徒破产和序贯检验",
    "section": "",
    "text": "本文是对Simple Sequential A/B Testing的解读。 该方法归属序贯检测类，可以用于伯努利分布场景，随着抽样持续进行，判断接受零假设或备择假设（关于序贯检测）。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#概率计算",
    "href": "posts/破产问题和简单序贯检验/index.html#概率计算",
    "title": "赌徒破产和序贯检验",
    "section": "概率计算",
    "text": "概率计算\n使用\\(R_{n,d}\\)来表示赌徒起始d元在第n轮输光的概率。 总局：n，输：(n + d) / 2，胜：(n - d) / 2。\n\n赌场可以借钱给赌徒的情况，此时为简单的排列组合关系。\n&gt;\\(R_{n,d} = \\binom{n}{(n + d)/ 2} * 2^{-n}\\)\n赌场不肯借钱给赌徒情况。\n&gt; \\(R_{n,d} = \\frac{d}{n}\\binom{n}{(n + d)/ 2} * 2^{-n}\\)\n\n这是简单序贯检测的基础，将在下面推导。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#随机游走和选举定理",
    "href": "posts/破产问题和简单序贯检验/index.html#随机游走和选举定理",
    "title": "赌徒破产和序贯检验",
    "section": "随机游走和选举定理",
    "text": "随机游走和选举定理\n在此对第二种情况进行计算。\n\n取纵坐标为钱，横坐标为赌博轮次，则过程为一维随机游走。举例：\n\n\n\n此时从A出发到K，满足条件路径数（中途不与0轴接触），等于从K出发到A的路径数。场景转换为从0开始，到d结束。\n\n\n\n在满足中途不触碰0轴条件，第一步必须为正。则从J到A路径数等于从A到K路径数。\n\n如图所示，每一条从J到第一个接触横轴的点的路径，总有一条从K出发到相同点的映射路径，后续都走相同路径。因此J到A经过横轴路径数等于K到A的路径数。\n设从0出发，有p步向上，q步向下。根据3，满足不触碰横轴概率为： $ ( {p - 1} - ) / = $\n\n此公式被称为选举定理。 &gt;将\\(p + q = n, p - q = d\\)带入，原问题最终结果为\\(\\frac{d}{n}\\binom{n}{(n + d)/ 2} * 2^ {-n}\\)"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#与赌徒破产问题的关系",
    "href": "posts/破产问题和简单序贯检验/index.html#与赌徒破产问题的关系",
    "title": "赌徒破产和序贯检验",
    "section": "与赌徒破产问题的关系",
    "text": "与赌徒破产问题的关系\n均等流量的转化率型ab测试场景中，实验组、对照组随着时间推移，都会产生转化。在零假设下，下一次转化发生在实验组或对照组的概率是相等的。因此可以转换为赌徒破产问题。\n每轮次：下一次转化发生； 每轮获胜者：下一次转化所在的组； 破产的轮次n：实验组、对照组转换数之和； 赌徒初始筹码d：因为转换数积累是从零开始的，不能直接套用。可以认为赌徒初始资本为0，输到-d时破产。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#假设检验设计",
    "href": "posts/破产问题和简单序贯检验/index.html#假设检验设计",
    "title": "赌徒破产和序贯检验",
    "section": "假设检验设计",
    "text": "假设检验设计\n以下仅介绍单尾情况，双尾的扩展请参考原文。\n\n原假设\n零假设(H0)：实验组转化率等于对照组转化率（对应未破产情况）； 备择假设(H1)：实验组转化率小于对照组转换率（对应破产情况）。\n\n\n假阳性控制(alpha)\n在零假设假设下，第n轮赌徒破产概率为： \\(R_{n,d} = \\frac{d}{n}\\binom{n}{(n + d)/ 2} * 2^{-n}\\) 在N轮及N轮之前，赌徒破产概率为：\\(\\sum_{n = 1} ^{N}R_{n,d}\\) 利用此公式控制假阳性，通过控N和d的选取，可以控制假阳性水平。\n\n\n假阴性控制(beta)\n控制假阴性，需要预设期望的最小观测效果（mde，此处选相对效果）。当实际提升效果等于MDE时，假阴性概率等于预设值。 在备择假设下，当实验组提升了mde时，下一次转化发生在实验概率为\\(P_t = \\frac {1 + mde} {2 + mde}\\)，对照组概率为\\(P_c = \\frac{1}{2 + mde}\\)。 第n轮破产概率：\\(R_{n,d} = \\frac{d}{n}\\binom{n}{(n + d)/ 2} * P_c ^ {(n - d) / 2}* P_t^{(n + d) / 2}\\)。 在N轮及N轮之前，赌徒破产概率为：\\(\\sum_{n = 1} ^{N}R_{n,d}\\) 取上面的概率为功效(power)，通过次N和d的选取，可以控制假阴性水平。\n\n\n选择结束条件\n联立上述不等式，使N和d满足： &gt; \\(\\sum_{n = 1}^N \\frac{d}{n}\\binom{n}{(n + d)/ 2} * 2^{-n} &lt; \\alpha\\) \\(\\sum_{n = 1}^N \\frac{d}{n}\\binom{n}{(n + d)/ 2} * P_c^{(n - d) / 2}* P_t^{(n + d) / 2} &gt; 1 - \\beta\\)\n不等式很难直接求解，可通过计算机遍历可能的N和d，找到合适的值。\n\n\n具体流程\n\n实验开始，实验组、对照组从0开始计数；\n每有一个转化，对应的组计数+1，并进行判断；\n对照转化数 - 实验组转化数 &gt;= d，接受备择假设；\n对照转化数 + 实验组转化数 = N，接受原假设。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#优点",
    "href": "posts/破产问题和简单序贯检验/index.html#优点",
    "title": "赌徒破产和序贯检验",
    "section": "优点",
    "text": "优点\n\n基于弱假设，易于理解和证明；\n过程易于操作；\n在低转换率时，需要样本量小于固定水平检验需要的样本量；\n不存在“偷看”问题。"
  },
  {
    "objectID": "posts/破产问题和简单序贯检验/index.html#缺点",
    "href": "posts/破产问题和简单序贯检验/index.html#缺点",
    "title": "赌徒破产和序贯检验",
    "section": "缺点",
    "text": "缺点\n\n只适用于近似伯努利分布场景；\n结束条件难以直接计算，需要通过计算机遍历查找；\n在高转化率时，需求样本量大于固定水平检验需要的样本量；\n无法直接给出置信区间和P值。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html",
    "href": "posts/实验设计_多重检验/index.html",
    "title": "A/B实验设计：多重检验",
    "section": "",
    "text": "本文介绍A/B实验中一个常见的错误——多重检验错误，它经常影响实验得到错误的结论。相关数学推导放在文末，跳过不影响理解。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#错误原因",
    "href": "posts/实验设计_多重检验/index.html#错误原因",
    "title": "A/B实验设计：多重检验",
    "section": "错误原因",
    "text": "错误原因\n\n假设检验通建立在统计学原理上，假设检验并不能不产生误判，而是控制误判在我们预设范围之内，称为假阳性错误（α水平，一般选在5%）\n\n每次验证都会有错误的概率，因此只要检验次数增加，遇到至少一次错误的概率也会增加。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#案例分析",
    "href": "posts/实验设计_多重检验/index.html#案例分析",
    "title": "A/B实验设计：多重检验",
    "section": "案例分析",
    "text": "案例分析\n上面的例子中，把各种颜色的糖作为不同实验组，与对照组进行对比。假设有20种糖，假阳性水平控制为5%，预期得到的显著结果为 20 * 5% = 1。我们很容易发现某种颜色糖果“似乎”与粉刺有关系，然而这是错误的。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#合理的设计实验",
    "href": "posts/实验设计_多重检验/index.html#合理的设计实验",
    "title": "A/B实验设计：多重检验",
    "section": "1. 合理的设计实验",
    "text": "1. 合理的设计实验\n设计实验前充分分析、调查，针对相关可能最大的因素进行实验，避免大量无用因素干扰得到错误结论。\n宗旨：尽量减少检验次数，降低犯错概率\n\n控制实验组尽可能少\n不同颜色软糖对粉刺的影响不应该有区别，因此只需要设计一组实验组。\n\n控制指标尽可能少\n我们可以同时检验软糖实验组对粉刺、喉咙痛、高血压…再夸张些，婚姻幸福度、孩子情况…检验的指标越多，得到假阳性结果的可能性同样上升（吃软糖与生女孩相关明显是荒谬的）。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#多次检验校正",
    "href": "posts/实验设计_多重检验/index.html#多次检验校正",
    "title": "A/B实验设计：多重检验",
    "section": "2. 多次检验校正",
    "text": "2. 多次检验校正\n统计学领域已经发明了一些方法来对多次检验进行校正。主要思想是检验次数越多，就要对显著采用更严格的限制，但是都会导致power的损失，降低发现率。\n常用方式：Bonferroni correction、Holm–Bonferroni method。\n缺点：会导致power有所损失（特别是检验结果不独立时）。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#实验后分析",
    "href": "posts/实验设计_多重检验/index.html#实验后分析",
    "title": "A/B实验设计：多重检验",
    "section": "3. 实验后分析",
    "text": "3. 实验后分析\n显著不等于一定正确。实验后需要对实验进行因果分析，结果需要可合理解释（不是编故事）。如果采用了多次检验校正，还需要考虑假阴性问题。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#符号定义",
    "href": "posts/实验设计_多重检验/index.html#符号定义",
    "title": "A/B实验设计：多重检验",
    "section": "符号定义",
    "text": "符号定义\n m：总检验假设数\nm0：零假设正确的数量，我们无法得知\nm - m0：备择假设正确的数量\nV：假阳性结论数量\nS：真阳性数量\nT：假阴性数量\nU：真阴性数量\nR = V + S：拒绝零假设数量\n在m个假设检验中，m0个零假设为真，R是观察到的显著情况的随机变量，S、T、U、V都是不可观测的随机变量。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#相关推导",
    "href": "posts/实验设计_多重检验/index.html#相关推导",
    "title": "A/B实验设计：多重检验",
    "section": "相关推导",
    "text": "相关推导\n如果m次检验是独立的，则产生假阳性的概率为:\n\\(\\alpha = 1 - ( 1 - \\alpha_{sub} )^{m}\\)\n如果检验不是独立的，仍然有：\n\\(\\alpha \\leq m * \\alpha_{sub}\\)"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#bonferroni-correction",
    "href": "posts/实验设计_多重检验/index.html#bonferroni-correction",
    "title": "A/B实验设计：多重检验",
    "section": "Bonferroni correction",
    "text": "Bonferroni correction\n方法：将每次检验的显著性从$ {sub}\\(调整为\\){newSub}$ = $ _{sub} / m$\n原理：根据上述不等式，则有\\(\\alpha \\leq m * \\alpha_{newSub} = \\alpha_{sub}\\) ，因此可以有效将假阳性水平控制在预设之内。\n优点：简单好理解。\n缺点：由于条件过于严格，假阴性错误率升高。"
  },
  {
    "objectID": "posts/实验设计_多重检验/index.html#holmbonferroni-method",
    "href": "posts/实验设计_多重检验/index.html#holmbonferroni-method",
    "title": "A/B实验设计：多重检验",
    "section": "Holm–Bonferroni method",
    "text": "Holm–Bonferroni method\n方法：将得到的P值从小到大排序记序号为i(1 ~ m)，从i = 1开始与 \\(\\alpha / (m - i + 1)\\)比较，小于就继续比较下一个。直到找出不符合条件的i(也可能不存在) ，i之前的全部认为显著，i及i之后的全部不显著。 原理： &gt;1. 将p值从大到小排序；\n&gt;2. 我们只需要关心P值最小的第一个零假设为真的情况：如果被拒绝，产生假阳性；否则，比较过程停止，未产生假阳性；\n&gt;3. 设第一个零假设为真的比较序号为h，则共有h - 1次正确的拒绝零假设，则：\n本次拒绝零假设条件为\\(\\alpha / (m - h + 1)\\) (a);\n\\(h - 1 \\leq m - m0\\)（正确拒绝的次数，一定小于等于备择假设为真的次数）；\n推出\\(\\frac{1}{m - h + 1} \\leq \\frac{1}{m_0}\\) (b)；\n不等式两边乘以\\(\\alpha\\)，得到(a)$ \\(。 &gt;4. 根据相关推导中结论，单次比较\\)_{sub} \\(，又\\)m_0$种等可能情况，则:\n\\(\\alpha_{_{real}} \\leq m_0 * \\alpha_{sub} \\leq \\alpha\\)\n优点：相对简单，假阴性错误率小于等于Bonferroni correction。\n缺点：假阴性依然高于预设（尤其是在检验结果相关情况下）。"
  },
  {
    "objectID": "posts/alpha消耗函数法/index.html",
    "href": "posts/alpha消耗函数法/index.html",
    "title": "成组序贯检验：alpha消耗函数法",
    "section": "",
    "text": "背景\n进行一项某项药物临床实验时，实验关注的是药物的正面效果，但是药物也可能会有严重的副作用，如何进行监控呢？\n衡量药物是否有效通过假设检验来判断，同理容易想到也可以通过假设检验判断药物的负面作用。但是固定水平检验偷看会增加假阳性，如果提前分析会增加假阳性；如果按照正确流程在实验结束后分析，实验中的志愿者可能已经受到了严重的伤害。\n如何完成分析又不增加假阳性呢？医学上的做法叫期中分析，依赖于成组贯序分析，alpha消耗函数是其中一种。\n\n\n解决思路\n如果只是为了控制假阳性，可以将提前比较视为多次比较，使用多重检验方法进行校正。但是实验中数据相关性较强，多重校正会增大假阴性错误，并不合适。\nalpha消耗函数的思路是将假阳性错误按照某种方案分配给每次比较，每次比较消耗一定的假阳性配额，合计后刚好等于预设水平。\n\n\n消耗函数\n设实验对应时间为\\([0, T]\\)，在这期间我们会得到对应信息\\([0, I]\\)。\n观测时间为：\\(0, t_1, t_2, t_3...T\\)；\n对应信息为：\\(0, i_1, i_2, i_3...I\\)；\n信息量占比为(\\(t^*\\))：\\(0, t^*_1 = i_1/I, t^*_2 = i_2/I, t^*_3 = i_3/I, ... 1\\)；\nalpha消耗函数为\\(t^*\\)的函数需要满足:\n\\[\\alpha(0) = 0\\] \\[\\alpha(1) = \\alpha\\]\n每次消耗α为：\\(α^*_1 = \\alpha(t^*_1) - \\alpha(0), α^*_2 = \\alpha(t^*_2) - \\alpha(t^*_1),...,α^*_n = \\alpha(1) - \\alpha(t^*_{n - 1})\\)。\n根据定义可知\\(α^*_1 = \\alpha(t^*_1)\\)，且\\(\\sum \\alpha^* = \\alpha\\)，符合解决思路中的要求。\n\n\n如何联系背景问题\n假阳性是在实际无效果情况下发现显著。以下仅以单样本单尾为例，根据不等式求解每个时刻的显著边界\\(Z_c\\):\n\\[\\\\t_1:P\\{Z(t^*_1) &gt;= Z_c(t^*_1)\\}= \\alpha(t^*_1)\\]\n\\[t_2:P\\{Z(t^*_2) &gt;= Z_c(t^*_2) , Z(t^*_1) &lt; Z_c(t^*_1)\\} \\\\= P\\{Z_c(t^*_2) | Z(t^*_1) )&lt; Z_c(t^*_1)\\} * (1 -  \\alpha(t^*_1))\\\\= \\alpha(t^*_2) -  \\alpha(t^*_1)\\]\n…\n\\[t_n:P\\{Z(t^*_n) &gt;= Z_c(t^*_n) , Z(t^*_1) &lt; Z_c(t^*_1),Z(t^*_2) &lt; Z_c(t^*_2)...,Z(t^*_{n -1}) &lt; Z_c(t^*_{n -1})\\}  \\\\= P\\{Z(t^*_n) &gt;= Z_c(t^*_n) | Z(t^*_1) &lt; Z_c(t^*_1),Z(t^*_2) &lt; Z_c(t^*_2)...,Z(t^*_{n-1}) &lt; Z_c(t^*_{n-1})\\}  * (1 - \\alpha(t^*_{n -1}))\\\\= \\alpha -  \\alpha(t^*_{n-1})\\]\n若检测时大于显著边界\\({Z_c}\\)则认为显著，接受备择假设。\n\n\n如何求解\\({Z_c}\\)\n在样本中个体独立同分布的情况下，信息量\\(I\\)为预设总样本量，每次检验的信息量\\(i\\)为已完成检验的个体数量。\n求解边界并不容易，仅有第一次检测边界可以直接求出：\n\\[t_1:Z_c(t^*_1) = \\phi^{-1}(\\alpha(t^*_1))\\]\n后续边界该如何求解？\n随着实验进行，若每次检验新增抽样都比较大，则新抽样样本的均值与和都服从正态分布，累计值的变化过程服从布朗运动，可以通过伊藤积分或蒙特卡洛模拟进行求解，以下为蒙特卡洛求解的过程：\n1.随机产生N个样本，每个样本有M个标准正态分布抽样的个体，M与N都极大； 2.可直接求得边界\\(Z_c(t^*_1)\\)，对每个样本的前 \\(M * t^*_1\\)个体合计计算\\(Z\\)值，不符合条件的样本标记淘汰； 3.计算第二次的alpha控制目标\\(\\alpha(t^*_2) - \\alpha(t^*_1)\\)，对未淘汰的样本的前 \\(M * t^*_2\\)个体合计计算\\(Z\\)值，排序后取对应分位点的\\(Z\\)值近似认为\\(Z_c(t^*_2)\\)，同样将小于边界的样本标记淘汰； 4.重复上述过程，直至完成。\n通过上述过程，得到了显著边界序列\\([Z_c(t^*_1), Z_c(t^*_2), Z_c(t^*_3)... Z_c(t^*_n)]\\)，可以用作每次检测的边界。\n\n\n后记\n中文网站上关于成组贯序分析的介绍比较少，尤其时alpha消耗函数法更少，以上是阅读相关论文后的个人理解。\n本文仅介绍了最简单的情况，且没有详细介绍为何服从布朗运动，详细推导和展开请继续查阅相关英文资料。"
  },
  {
    "objectID": "posts/荟萃分析简介/index.html",
    "href": "posts/荟萃分析简介/index.html",
    "title": "荟萃分析简介",
    "section": "",
    "text": "进行线上ab实验时，为了确认结果可信，用户常常会复验前一阶段的实验。此时经常遇到复验与原实验结果不完全统一，如何综合评估实验效果？荟萃分析可以解决此类问题。 本文仅简介固定效果假设下关于P值合并的部分。"
  },
  {
    "objectID": "posts/荟萃分析简介/index.html#fishers-method",
    "href": "posts/荟萃分析简介/index.html#fishers-method",
    "title": "荟萃分析简介",
    "section": "Fisher’s method",
    "text": "Fisher’s method\n如果两次实验p值分别为p1、p2。进行在零假设时，它们独立，并服从0~1的均匀分布，则两次实验合并的p值为： \\[p = \\int_{x * y = p1 * p2, 0&lt; x,y&lt;1 }1dxdy = p1*p2(1 - log(p1 * p2))\\]\nFisher将其扩展到更一般场景，对k次实验结果进行合并后服从自由度为2k的卡方分布： \\[-2\\sum_{i = 1}^klog(p_i)  \\sim  \\chi^2(2k)\\]"
  },
  {
    "objectID": "posts/荟萃分析简介/index.html#stouffers-methodz值合并",
    "href": "posts/荟萃分析简介/index.html#stouffers-methodz值合并",
    "title": "荟萃分析简介",
    "section": "Stouffer’s method(z值合并)",
    "text": "Stouffer’s method(z值合并)\n此处直接介绍加权的方法。\n先将\\(p_i\\)值逆计算为\\(z_i\\)，则\\(z_i \\sim N(0, 1)\\)。多个\\(zi\\)加权相加后，依然服从正态分布，则： \\[P_Z = 1 - \\Phi(\\frac{\\sum w_i Z_i}{\\sqrt{\\sum w_i ^ 2}})\\]\n为什么会有权重呢？假如每次实验重视程度不同，那么它们结果按重要性来加权是很自然的。\n如何选择权重？如果实验干预、受众相同，建议使用样本量的平方根做权重。\n\n单样本两次实验的例子：\n检验\\(\\Delta\\)是否为0，做了两次实验分别采集到\\(\\delta_1,\\delta_2\\)，样本量为\\(n_1, n2\\)，样本方差同为\\(\\sigma^2\\)，此时如果$w_1 = ,w2 = $，则可推出\n\\(\\frac{\\sum w_i Z_i}{\\sqrt{\\sum w_i ^ 2}} = (\\delta_1*n_1 + \\delta_2 * n_2) /(n_1 + n_2) / \\sqrt{\\frac{\\sigma^2}{n_1 + n_2}} = Z\\) 即两次实验结果，与将原数据汇总计算结果相同。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html",
    "href": "posts/流量分配与决策优化/index.html",
    "title": "流量分配与决策优化",
    "section": "",
    "text": "以下内容重在描述解决的问题、大概思路和可能收益，详细数学和细节参考引用论文。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#发布决策问题",
    "href": "posts/流量分配与决策优化/index.html#发布决策问题",
    "title": "流量分配与决策优化",
    "section": "1.1. 发布决策问题",
    "text": "1.1. 发布决策问题\nAB实验是否显著依赖假设检验，假设检验会有某种阈值来决定是否显著，比如P值小于0.05。\n但是为什么P值是0.05？这一标准是否是普适的？是否对不同行业不同公司有更优的标准？"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#流量分配问题",
    "href": "posts/流量分配与决策优化/index.html#流量分配问题",
    "title": "流量分配与决策优化",
    "section": "1.2. 流量分配问题",
    "text": "1.2. 流量分配问题\n对大规模实验平台来说，流量始终是一种稀缺资源。如何为实验选择合适的流量？\n常规答案是进行power分析，实验者根据自己选择的最小观测的效果（MDE）结合实验运行时长、样本方差评估出需要多少用户参与实验。\n但这也只是把原问题转换为了另一个形式，实验者应该如何选择自己的MDE？不同场景下是否有科学的MDE选择指南？"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#场景建模",
    "href": "posts/流量分配与决策优化/index.html#场景建模",
    "title": "流量分配与决策优化",
    "section": "2.1. 场景建模",
    "text": "2.1. 场景建模\n此处使用分层模型。\n公司会产生很多创意：i = 1, 2,…,I，每个创意质量对应随机变量\\(\\Delta_i\\)，此处质量指创意全量后提升率；\n这些创意的质量独立同分布，来自质量分布G；\n公司发布一个创意的成本为c；\n对每个创意质量公司通过AB实验进行评估，实验估计提升率为随机变量\\(\\hat{\\Delta}_i \\sim N(\\Delta_i, \\sigma^2/n_i)\\)；\n两个随机变量\\(\\Delta_i\\)和\\(\\hat{\\Delta}_i\\)的值分为别\\(\\delta_i\\)和\\(\\hat{\\delta}_i\\)。\n\n\n\n分层模型示意"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#收益估计",
    "href": "posts/流量分配与决策优化/index.html#收益估计",
    "title": "流量分配与决策优化",
    "section": "2.2. 收益估计",
    "text": "2.2. 收益估计\n根据实验效果和创意质量分布，通过贝叶斯方法可以计算创意质量的条件期望值\\(E[\\Delta_i|\\hat{\\Delta}_i=\\hat{\\delta}_i,n_i,\\sigma^2,G]\\)，记为P(_i, n_i)，它的表达式是创意i的质量函数。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#结论",
    "href": "posts/流量分配与决策优化/index.html#结论",
    "title": "流量分配与决策优化",
    "section": "3.1. 结论",
    "text": "3.1. 结论\n当P(_i, n_i)大于发布成本c时，就对其进行发布。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#解释",
    "href": "posts/流量分配与决策优化/index.html#解释",
    "title": "流量分配与决策优化",
    "section": "3.2. 解释",
    "text": "3.2. 解释\n质量分布与观测值结合，可以实验评估出创意的条件期望质量。\n计算过程采用贝叶斯方法，已经考虑了质量分布有观测质量分布的波动性，并且可以证明此估计值优于单出基于实验观测值的估计。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#微软的研究",
    "href": "posts/流量分配与决策优化/index.html#微软的研究",
    "title": "流量分配与决策优化",
    "section": "3.3. 微软的研究",
    "text": "3.3. 微软的研究\n\n上图示例中微软按实验有两千万用户参与绘制不同的后验效果。\n其中黑色曲线来自微软2019根据历史实验估计得出。它对应的质量分布为自由度为1.3的t分布，期望值为-0.09%，属于肥尾分布；其它是模拟不同质量分布的效果，属于细尾分布。\n此研究为微软提供了以下发现：\n\n微软创意的质量分布为肥尾分布，依据实验效果不同，它会对后验质量产生不同的影响：\n\n对实验效果越弱的创意，使后验质量估计值越趋向0，因为它们更大概率来自运气；\n对实验效果越强的创意，对后验影响估计值影响越少，因为靠运气得到的概率很低。\n\n实验后的后验质量估计可直接通过贝叶斯方式计算，基于后验质量决策有以下影响：\n\n基于以上实验条件，可计算出创意发布的p值阈值： 如果发布成本为零，创意应该被发布的p值阈值为32%； 如果发布成本为质量指标的0.01，创意应该被发布的p值阈值为0.85%； 如果发布成本为质量指标的0.05，创意应该被发布的p值阈值为0.015%；\n根据微软对实验的的回测，基于最优发布策略可提升核心指标收益在5%级别，提升结果是显著的；\n回测发现2%的历史实验提供了74.5%的收益，这是一个极端版的二八定律。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#结论-1",
    "href": "posts/流量分配与决策优化/index.html#结论-1",
    "title": "流量分配与决策优化",
    "section": "4.1. 结论",
    "text": "4.1. 结论\n如果质量分布肥尾，应该对所有创意都进行实验（小流量多数量）；\n如果质量分布细尾，应该将所有资源用于运行单个实验（大流量少数量）。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#解释-1",
    "href": "posts/流量分配与决策优化/index.html#解释-1",
    "title": "流量分配与决策优化",
    "section": "4.2. 解释",
    "text": "4.2. 解释\n假设创意质量分布期望为正向，基于4的最优发布策略，可以计算得到的投入用户进行实验的平均收益提升，称为生产函数：\n\\[f_i(n_i)\\equiv \\mathbb{E}[P(\\hat{\\Delta}_i)^+]-\\mathbb{E}[\\Delta_i]^+\\]\n由于总流量是确定的，需要分配给不同的创意（此处不考虑分层架构或者认为发生在特定流量层下），则实验流量分配转化为总成本固定下的最优化问题。\n生产函数的形状与质量分布是否肥尾有关，以质量分布为t分布建模：\n\n\n如自由度小于3，质量分布为肥尾，生产函数为凹函数；\n如自由度大于3，质量分布为细尾，生产函数为凸函数。\n\n如果共N个用户平均分配个I个创意进行实验（每个实验n个用户），产生的整体收益为：\n\\[Y = I \\cdot f(\\frac{N}{I}) = I \\cdot f(n)\\]\n根据生产函数形状可得到以上结论。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#质量分布如何得到",
    "href": "posts/流量分配与决策优化/index.html#质量分布如何得到",
    "title": "流量分配与决策优化",
    "section": "5.1. 质量分布如何得到？",
    "text": "5.1. 质量分布如何得到？\n以上推导都基于质量分布G，而现实中它是未知的，可以通过历史实验进行评估，比如使用最大似然估计法、Lindsey’s Method等，此处不做展开。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#以上结论是否有前置要求",
    "href": "posts/流量分配与决策优化/index.html#以上结论是否有前置要求",
    "title": "流量分配与决策优化",
    "section": "5.2. 以上结论是否有前置要求？",
    "text": "5.2. 以上结论是否有前置要求？\n在以上研究中，假设公司创意数量不是瓶颈，且创意质量不会随数量的增加而下降。"
  },
  {
    "objectID": "posts/流量分配与决策优化/index.html#分层模型hierarchical-model",
    "href": "posts/流量分配与决策优化/index.html#分层模型hierarchical-model",
    "title": "流量分配与决策优化",
    "section": "分层模型（hierarchical model ）",
    "text": "分层模型（hierarchical model ）\n此模型观测值分布的参数也是随机产生的，参数值来自另一个分布（套娃模式）。 一个现实的例子： 随机从学校抽取一个学生，让这个学生做一份试卷，最后试卷的评分。  上图为例子的一种建模： \\(\\theta \\sim N(\\mu,\\tau^2)\\)，代表不同学生知识掌握程度的建模，此处分布的两个参数是已知的； \\(Y \\sim N(\\theta, \\sigma^2)\\)，代表被抽取学生考试得分。 ## 肥尾分布（Fat-tailed distribution） 相对正态分布或指数分布来说中间更细尾巴更粗的分布。\n著名的肥尾分布是幂律分布、帕累托分布，伴随着它们出现的名词是“二八定律”、“黑天鹅”等。\n\n一个正态分布与肥尾分布对比的例子：\n正态分布：正负三个标准差可以覆盖99.7%的概率，正负四个标准差以外的事件几乎是不存在的；\n肥尾分布：4%的事件发生在八个标准差之外。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html",
    "href": "posts/错误的共享对照/index.html",
    "title": "实验间共享对照组缺陷及对策",
    "section": "",
    "text": "A/B实验目标是实现在线随机对照实验，因此需要满足「随机对照实验」的要求和前提。\n然而前支持的「对照组流量共享机制」违背了「随机对照实验」的基本要求。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#什么是随机对照实验随机",
    "href": "posts/错误的共享对照/index.html#什么是随机对照实验随机",
    "title": "实验间共享对照组缺陷及对策",
    "section": "1.什么是随机对照实验随机",
    "text": "1.什么是随机对照实验随机\n对照试验的基本方法是，将研究对象随机分组，对不同组实施不同的干预。\n在这种严格的条件下对照效果的不同。在研究对象数量足够的情况下，这种方法可以抵消已知和未知的混杂因素对各组的影响，被公认为是评价干预措施的金标准。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#在线随机的一般实现",
    "href": "posts/错误的共享对照/index.html#在线随机的一般实现",
    "title": "实验间共享对照组缺陷及对策",
    "section": "2.在线随机的一般实现",
    "text": "2.在线随机的一般实现\n根据随机实验定义我们要保证：统一群体随机分组，分组后用户属于哪个组稳定。 一般做法：用户标识 -&gt; 拼接salt，产生新字符串 -&gt; 哈希散列为数字 -&gt; 绝对值取余编号（分桶） -&gt; 桶编号范围分组 举例：假设一个实验将用户分100个桶，0 ~ 49号桶用户为对照组，50 ~ 99号桶用户为实验组"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#共享对照流量",
    "href": "posts/错误的共享对照/index.html#共享对照流量",
    "title": "实验间共享对照组缺陷及对策",
    "section": "1.共享对照流量",
    "text": "1.共享对照流量\n设计思路比较朴素：既然对照组为基线，那么切一部分做对照，剩下的只用于实验，都与对照流量对比即可。 示例：  这样做有效利用了流量，但存在重大缺陷：持续迭代下，违背了「随机对照实验」的前提。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#共享对照缺陷",
    "href": "posts/错误的共享对照/index.html#共享对照缺陷",
    "title": "实验间共享对照组缺陷及对策",
    "section": "2.共享对照缺陷",
    "text": "2.共享对照缺陷\n实验持续迭代，当旧实验结束后，新实验会使用其释放的流量。由于习得性效应（残留效应）影响，此时两人群常常是不同质的。 示例： 上例的实验3结束后，实验4继承了实验3的流量做实验。「共享对照组」和「实验4」还是期望同质的人群么？ 由于释放人群表现 = 原表现 + 实验3效果 —— 除非「实验3」没任何效果才能满足！"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#人群是否同质的谜题",
    "href": "posts/错误的共享对照/index.html#人群是否同质的谜题",
    "title": "实验间共享对照组缺陷及对策",
    "section": "3.人群是否同质的谜题",
    "text": "3.人群是否同质的谜题\n为什么讨论人群是否同质？其实是为了让实验正确决策。 - 随机对照实验下：实验组对照组期望同质，误判都是波动造成，通过统计模型可控。只要标准的统计推断即可保证「误判率」和「检出率」符合预设； - 共享对照实验下：实验组对照组期望同质不能保证，这让实验从科学变成了玄学；\n\n常见问题：实验AA组与对照组不一致，人群是不是不同质，效果可信么？ - 标准随机实验下：AA组与对照组期望同质，流量越大结果波动更小。因此建议流量合并当做对照组，再计算实验结果期望最优解。 - 共享对照实验下：无法解答，AA组和对照组都可能受残留效应影响。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#二次分流实验",
    "href": "posts/错误的共享对照/index.html#二次分流实验",
    "title": "实验间共享对照组缺陷及对策",
    "section": "1.二次分流实验",
    "text": "1.二次分流实验\n按实验分配流量（一个人群），实验内部再二次分配（随机分流）"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#基于二次分流的共享对照",
    "href": "posts/错误的共享对照/index.html#基于二次分流的共享对照",
    "title": "实验间共享对照组缺陷及对策",
    "section": "2.基于二次分流的共享对照",
    "text": "2.基于二次分流的共享对照\n每次实验内部重新随机，做多实验组是合理的，此时对照组流量共享。 有共享流量分配最优解的研究《A Common Control Group - Optimising the Experiment Design to Maximise Sensitivity》"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#增加流量的本质是什么",
    "href": "posts/错误的共享对照/index.html#增加流量的本质是什么",
    "title": "实验间共享对照组缺陷及对策",
    "section": "1.增加流量的本质是什么？",
    "text": "1.增加流量的本质是什么？\n流量越大结果越可信 = 样本越大均值波动越小 = 样本越大均值方差越小 = 样本越大标准误越小\n本质上我们是在追求更小的结果波动即更小的标准误。其样本量增加的收益是边际递减的。 \\[标准误 = \\sqrt{\\frac{样本方差}{对照组样本量} + \\frac{样本方差}{实验组样本量} } \\] 影响标准误的因素：样本方差、样本量"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#增加样本量的收益",
    "href": "posts/错误的共享对照/index.html#增加样本量的收益",
    "title": "实验间共享对照组缺陷及对策",
    "section": "2.增加样本量的收益",
    "text": "2.增加样本量的收益\n通过案例估算： 假设一些用户其样本方差约35000，分配比例1:1， 标准差随样本量变化曲线为：  由上可知：其边际收益递减，大约几十万样本后就不会有特别快的下降。"
  },
  {
    "objectID": "posts/错误的共享对照/index.html#降低样本方差可能是更好的方法",
    "href": "posts/错误的共享对照/index.html#降低样本方差可能是更好的方法",
    "title": "实验间共享对照组缺陷及对策",
    "section": "3.降低样本方差可能是更好的方法",
    "text": "3.降低样本方差可能是更好的方法\n控制变量法、过滤离群点等降噪方法可以降低样本方差，而且常常对一些指标来说方差很容易就可以下降50%以上 样本方差从35000降低到5000收益："
  },
  {
    "objectID": "posts/msprt/index.html",
    "href": "posts/msprt/index.html",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "",
    "text": "Optimizely通过mSPRT理论的扩展，提供了时时有效的P值与置信区间，解决了ab实验中的偷看问题。"
  },
  {
    "objectID": "posts/msprt/index.html#始终有效的p",
    "href": "posts/msprt/index.html#始终有效的p",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "2.1 始终有效的P",
    "text": "2.1 始终有效的P\n任意时间T，满足： \\[\\forall s\\ \\epsilon\\ [0,1],\\ \\mathbb{P}_{\\theta _{0}}(p_T \\leq s) \\leq s\\]"
  },
  {
    "objectID": "posts/msprt/index.html#始终有效的贯序检测",
    "href": "posts/msprt/index.html#始终有效的贯序检测",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "2.2 始终有效的贯序检测",
    "text": "2.2 始终有效的贯序检测\n依靠样本数据决策样本量。\n判决条件：\n\\((T(\\alpha), \\delta(\\alpha) )\\)\n\\(\\mathbb{P}_{\\theta _{0}}( \\delta(\\alpha) = 1) \\leq \\alpha\\)\n$T(),() \\(不会影响\\)$水平"
  },
  {
    "objectID": "posts/msprt/index.html#置信区间",
    "href": "posts/msprt/index.html#置信区间",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "2.3 置信区间",
    "text": "2.3 置信区间\n对\\(\\theta = \\widetilde{\\theta}\\)来说，如果\\(p_{n}^{\\widetilde{\\theta}}\\)始终有效，$I_{n} = {: p_{n}^{} &gt; } $就是始终有效的\\(1-\\alpha\\)水平置信区间。"
  },
  {
    "objectID": "posts/msprt/index.html#混合贯序检验msprt",
    "href": "posts/msprt/index.html#混合贯序检验msprt",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "3.1 混合贯序检验(mSPRT)",
    "text": "3.1 混合贯序检验(mSPRT)\nH为$\\(上的混合分布，概率密度函数为h。计算H的似然比除以\\)_{0}$的似然比： \\[\\Lambda _{n}^{H,\\theta _{0}} = \\int _{\\Theta }\\prod_{m=1}^{n}\\frac{f_{\\theta}(X_{m})}{f_{\\theta_{0}}(X_{m})}h(\\theta)d\\theta\\]\nmSPRT判断流程：\n选择\\(\\alpha\\)，则拒绝原假设条件为\\(\\Lambda_{T}^{H,\\theta_{0}} \\ge \\alpha^{-1}\\)，此时\\(T = T^{\\alpha}\\)。\n详细原理参照文末。"
  },
  {
    "objectID": "posts/msprt/index.html#msprt的p值与置信区间",
    "href": "posts/msprt/index.html#msprt的p值与置信区间",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "3.2 mSPRT的P值与置信区间",
    "text": "3.2 mSPRT的P值与置信区间\n\\(p_0 = 1;p_n=min\\{p_{n-1},1/\\Lambda _{n}^{H,\\theta _0 } \\}\\)\n$I_0 = ; I_n = I_{n-1} { : _n ^ {H, } ^{-1} } $\n如果数据自正态分布\\(N(\\theta, \\sigma^2)\\)，且混合分布\\(H = N(\\theta_0, \\tau^2)\\)，则\n\\[\\Lambda _{n}^{H,\\theta _{0}} = \\frac{\\sigma}{\\sqrt{\\sigma^2 + n\\tau^2 }} exp\\{\\frac{n^2\\tau^2(\\bar{X}_{n} - \\theta_0)^2}{2\\sigma^2(\\sigma^2 + n\\tau^2)}\\}\\]"
  },
  {
    "objectID": "posts/msprt/index.html#msprt扩展到ab",
    "href": "posts/msprt/index.html#msprt扩展到ab",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "3.3 mSPRT扩展到A/B",
    "text": "3.3 mSPRT扩展到A/B\n定义\\(Z_n = Y_n - X_n \\sim N(\\theta, 2\\sigma^2)\\)，并对其做mSPRT检测，则： \\[\\Lambda _{n}^{H,\\theta _{0}} = \\sqrt {\\frac {2\\sigma^2} {2\\sigma^2 + n \\tau^2 } } exp \\{ \\frac{n^2\\tau^2(\\bar{Y}_n - \\bar{X}_{n} - \\theta_0)^2}{4\\sigma^2(2\\sigma^2 + n\\tau^2)} \\}\\]\n对于0/1型数据，\\(\\bar{Y}_n - \\bar{X}_n\\)近似于正态分布\\(N(\\theta, V_n/n)\\)，\\(V_n = \\bar{X}_n(1-\\bar{X}_n) + \\bar{Y}_n(1- \\bar{Y}_n)\\)，则： \\[\\Lambda _{n}^{H,\\theta _{0}} = \\sqrt{\\frac{V_n}{V_n + n\\tau^2 }} exp\\{\\frac{n^2\\tau^2(\\bar{Y}_n - \\bar{X}_{n} - \\theta_0)^2}{2V_{n}(V_n + n\\tau^2)}\\}\\]"
  },
  {
    "objectID": "posts/msprt/index.html#实现细节",
    "href": "posts/msprt/index.html#实现细节",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "3.4 实现细节",
    "text": "3.4 实现细节\n对于一些连续性指标，比如“付费”（严重右斜）使用正态分布是不合适的，需要其它更适应这种偏斜的分布。\n由于为了保证单调性，可能导致后期\\(\\bar{Y}_n - \\bar{X}_n\\)跑出置信区间，此时Optimizely会重置显著性。这样的做法只会让p值更大、置信区间更宽，不会增加假阳性错误，但是可能增大假阴性错误。"
  },
  {
    "objectID": "posts/msprt/index.html#优化",
    "href": "posts/msprt/index.html#优化",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "4.1 优化",
    "text": "4.1 优化\n实验者不会永远等待，因此有最大等待样本量M。\n经过Optimizely验证，带M截断的mSPRT比一般的假设检验平均花费更少的样本量。"
  },
  {
    "objectID": "posts/msprt/index.html#混合分布的选择",
    "href": "posts/msprt/index.html#混合分布的选择",
    "title": "Peeking at A/B test：mSPRT简介",
    "section": "4.2 混合分布的选择",
    "text": "4.2 混合分布的选择\n之前选择了混合分布为\\(H = N(\\theta_0, \\tau^2)\\)。对于混合分布如何选择，没有现存的理论指导。\nOptimizely选择的先验为\\(G = N(0, \\tau_0^2)\\)，并且通过数据仿真得到\\(\\tau_0^2\\)。"
  },
  {
    "objectID": "posts/cuped/index.html",
    "href": "posts/cuped/index.html",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "",
    "text": "CUPED（Controlled-experiment Using Pre-Experiment Data）是一种通过联系实验前数据，让方差变小的方法。"
  },
  {
    "objectID": "posts/cuped/index.html#思路",
    "href": "posts/cuped/index.html#思路",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "1. 思路",
    "text": "1. 思路\n构建\\(\\Delta^*\\)，满足：\n\n\\(\\Delta^*\\)与\\(\\Delta\\)一样，是\\(E(Y_t - Y_c)\\)的无偏估计；\n\n\\(\\Delta^*\\)相对\\(\\Delta\\)，方差更小。\n\n使用\\(\\Delta^*\\)来评估实验效果，效果相似，方差变小。"
  },
  {
    "objectID": "posts/cuped/index.html#原理",
    "href": "posts/cuped/index.html#原理",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "2. 原理",
    "text": "2. 原理\n如果有另一随机变量\\(X\\)，并且已知\\(E(X)\\)。则有互相独立的二维随机变量\\((X_i, Y_i)\\)，定义：\n\\[\\hat{ Y }_{ cu } = \\bar{ Y } - \\theta \\bar{ X } + \\theta E(X)\\]\n由于$E( E(X) - { X } ) = 0 \\(，所以\\)_{cu} \\(是\\)E(Y)$的无偏估计，则\n\\[ var( \\hat{Y}_{cu} ) =   var(Y - \\theta X) / n = \\frac {1} {n} (var(Y) + \\theta^2 var(X) - 2\\theta cov(X,Y))\\]\n当\\(\\theta = cov(X,Y) / var(X)\\)时，$var(_{cu}) $的值最小（最小二乘法），此时：\n\\[var (\\hat{Y}_{cu}) = \\frac {1}{n}(var(Y)  - cov(X,Y)^{2}/var(X)) = \\frac{var(Y)}{n} (1 - \\frac { cov(X,Y)^{2}}{var(X)var(Y)}) = var ( \\bar{ Y } ) (1 - \\rho ^{2} ) \\leq var( \\bar { Y })\\]\n\\(X\\)与\\(Y\\)的相关系数越大，得到的方差越小。"
  },
  {
    "objectID": "posts/cuped/index.html#扩展到ab",
    "href": "posts/cuped/index.html#扩展到ab",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "3. 扩展到A/B",
    "text": "3. 扩展到A/B\n如果选择的\\(X\\)不会被实验干扰，则$ E( X ^ {t} ) - E( X ^ {c} ) = 0\\(， 实验组、对照组在零假设下还有**相同的\\)$**，得：\n\\[\\Delta_{cv} = \\hat {Y}_{cu} ^{t} - \\hat{Y}_{cu}^{c}  = ( \\bar {Y}_{cu} ^{t} - \\bar {Y}_{cu}^{c} ) - \\theta(\\bar{X}_{cu}^{t} - \\bar {X}_{cu}^{c})  + \\theta (E( X ^ {t}  -  X ^ {c} ) ) = \\Delta - \\theta \\Delta _ { x } \\]\n得到 \\[var(\\Delta_{cv}) = var(\\Delta)(1-\\rho ^2)\\]"
  },
  {
    "objectID": "posts/cuped/index.html#选择协变量x",
    "href": "posts/cuped/index.html#选择协变量x",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "1. 选择协变量(X)",
    "text": "1. 选择协变量(X)\n选择相关系数更大的协变量，效果更好。微软的建议：\n\n选择实验运行之前的指标数据最好；\n实验之前指标数据的时间粒度越长，效果越好；\n实验运行周期并不是越长越好。\n\n实验前数据并不是X得唯一选择，只要是不会被实验干预影响的变量，都可以选择。比如用户加入实验的日期。"
  },
  {
    "objectID": "posts/cuped/index.html#实验前数据缺失yi对应的xi不存在",
    "href": "posts/cuped/index.html#实验前数据缺失yi对应的xi不存在",
    "title": "A/B实验进阶：通过实验前数据减小方差（CUPED）",
    "section": "2. 实验前数据缺失(\\(Yi\\)对应的\\(Xi\\)不存在)",
    "text": "2. 实验前数据缺失(\\(Yi\\)对应的\\(Xi\\)不存在)\n新用户或太久没回归的用户，可能没有旧的记录。可以对缺失的数据，补为适当的值。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html",
    "href": "posts/实验设计_偷看问题/index.html",
    "title": "A/B实验设计：偷看问题",
    "section": "",
    "text": "偷看是ab测试中最常遇到的问题，本文将说明影响，分析用户为什么偷看，探讨如何应对。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#a.-我们有偷看的需求",
    "href": "posts/实验设计_偷看问题/index.html#a.-我们有偷看的需求",
    "title": "A/B实验设计：偷看问题",
    "section": "a. 我们有偷看的需求",
    "text": "a. 我们有偷看的需求\n\n及时止损，尽早结束失败（有害）的实验；\n\n扩大胜利成果，尽早发现成功的实验。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#b.-存在允许偷看的客观条件",
    "href": "posts/实验设计_偷看问题/index.html#b.-存在允许偷看的客观条件",
    "title": "A/B实验设计：偷看问题",
    "section": "b. 存在允许偷看的客观条件",
    "text": "b. 存在允许偷看的客观条件\n固定水平检验产生在大约100年前。我们来看下当年与现代的对比。\n100年前：\n- 数据成本高、收集缓慢\n著名的统计学家费希尔，使用假设检验对农业进行研究。作物的生长周期是很难改变的，无法预知结果…数据的采集、计算依赖人力。\n- 对操作者要求高\n实验者是经过训练的专家。\n现在：\n- 数据及时、廉价 科技降低了数据获取的成本，可以研究更精细的事物。互联网业采集、分析用户行为已经越来越成熟。 - 人人都可以是操作者 在成熟ab测试平台上，实验者可以轻松进行实验，也更容易在实验分析中犯错。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#c.-实验平台模板不适合",
    "href": "posts/实验设计_偷看问题/index.html#c.-实验平台模板不适合",
    "title": "A/B实验设计：偷看问题",
    "section": "c. 实验平台模板不适合",
    "text": "c. 实验平台模板不适合\n实验平台提供了固定的模板，以及在此模板下的终止条件，常见为限定实验周期、分析单位等，并以此得到结束条件。\n固化的模板不能通用于所有的实验，因此用户自己判断是否停止也不足为奇。\n平台需要增强实验个性化的能力。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#不偷看",
    "href": "posts/实验设计_偷看问题/index.html#不偷看",
    "title": "A/B实验设计：偷看问题",
    "section": "不偷看",
    "text": "不偷看\n这是最简单可靠的方案，但是经常很困难。参考以下场景：\n\n大佬：B方案显著正面了，上线了吧\n小弟：不行，我们还需要再等三天\n大佬：B方案负面显著了，快回滚\n小弟：还需要等三天……\n大佬：这个方案竟然不显著？在跑几天！\n小弟：不行，我们已经达到停止条件了"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#非固定水平检验",
    "href": "posts/实验设计_偷看问题/index.html#非固定水平检验",
    "title": "A/B实验设计：偷看问题",
    "section": "非固定水平检验",
    "text": "非固定水平检验\n比如贯序检验系列方法，他们一般掌握成本更高，过程更复杂。由于结束条件改变了，并不一定会比固定水平检验更快结束。 Optimizely采用了这种方案，过程中用户可以偷看，每次平台提供可靠的P值与置信区间，整个过程后假阳性依然控制在预定水平。"
  },
  {
    "objectID": "posts/实验设计_偷看问题/index.html#使用非检验方法",
    "href": "posts/实验设计_偷看问题/index.html#使用非检验方法",
    "title": "A/B实验设计：偷看问题",
    "section": "使用非检验方法",
    "text": "使用非检验方法\n有时我们不需要解释，只是希望得到最好的组合，这种问题为multi-armed bandit problem，已经有很多相关的研究。"
  },
  {
    "objectID": "posts/BMCP_2/index.html",
    "href": "posts/BMCP_2/index.html",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "",
    "text": "上一章中贝叶斯推断是关于基于数据和先验知识，通过贝叶斯公式计算后验概率，从而得到后验分布的过程。但是现实中远没有这么简单，成功的贝叶斯分析还有很多其它挑战。\n本章将讨论其中的一些，包括检验模型假设、诊断推理结果和模型比较原文链接。"
  },
  {
    "objectID": "posts/BMCP_2/index.html#推断之前和之后都有要做的事情",
    "href": "posts/BMCP_2/index.html#推断之前和之后都有要做的事情",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.1. 推断之前和之后都有要做的事情！",
    "text": "2.1. 推断之前和之后都有要做的事情！\n除推断外，一次成功的贝叶斯建模的工作列举：\n\n通过数值方法诊断推断结果质量；\n模型批判，评价模型假设和模型预测结果；\n模型比较，选择模型或者模型混合；\n为特定受众准备结果。\n\n以上工作统称为贝叶斯模型探索分析（Exploratory Analysis of Bayesian Models）。"
  },
  {
    "objectID": "posts/BMCP_2/index.html#理解你的假设",
    "href": "posts/BMCP_2/index.html#理解你的假设",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.2. 理解你的假设",
    "text": "2.2. 理解你的假设\n选择先验的一个问题是很难理解它们在模型计算中的效果。基于先验分布预测是一种理解假设的好方法。通过仅从先验预测分布抽样得到观察数据，我们完成从参数空间到观测空间的转换（参数分布 -&gt; 参数 -&gt; 先验预测分布 -&gt; 观测值）。 这被称为prior predictive checks。\n举一个对足球建模的例子，我们感兴趣的是点球得分率。\n\n模型假设期望射门角度\\(\\alpha\\)服从正态分布，进球概率模型为： \\[p\\left(|\\alpha| &lt; \\tan^{-1}\\left(\\frac{L}{x}\\right)\\right) = 2\\Phi\\left(\\frac{\\tan^{-1}\\left(\\frac{L}{x}\\right)}{\\sigma}\\right) - 1\n\\]\n上述公式表达的是，足球射出角度\\(\\alpha\\)在±\\(\\tan^{-1}\\left(\\frac{L}{x}\\right)\\)的概率（这样才能进球），其中\\(L\\)是球门二分之一宽度，\\(x\\)是球门中心到球员的距离。球员会尽量踢直线，但是有各种因素影响导致波动从而有标准差\\(\\sigma\\)\n上述公式中唯一未知的参数是\\(\\sigma\\)，我们可以选择它的先验来建模，例如服从Half-normal分布。则以上模型为：\n\\[\\sigma \\sim \\mathcal{HN}(\\sigma_{\\sigma})\\]\n\\[\\text{p\\_goal} = 2\\Phi\\left(\\frac{\\tan^{-1}\\left(\\frac{L}{x}\\right)}{\\sigma}\\right) - 1\\]\n\\[Y \\sim \\text{Bin}(n=1, p=\\text{p\\_goal})\\]\n我们很难直接抉择\\(\\sigma_{\\sigma}\\)怎么选择，但是我们可以通过先验预测分布来理解它的影响。\n\n%matplotlib inline\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pymc as pm\nfrom scipy import stats\nfrom pytensor import tensor as tt\nimport pandas as pd\n\n\naz.style.use(\"arviz-grayscale\")\nplt.rcParams['figure.dpi'] = 300\nnp.random.seed(5201)\n\n\nhalf_length = 3.66  # meters\npenalty_point = 11  # meters\ndef Phi(x):\n    \"\"\"Calculates the standard normal cumulative distribution function.\"\"\"\n    return 0.5 + 0.5 * tt.erf(x / tt.sqrt(2.0))\n\nppss = []\nsigmas_deg = [5, 20, 60]\nsigmas_rad = np.deg2rad(sigmas_deg)\nfor sigma in sigmas_rad:\n    with pm.Model() as model:\n        σ = pm.HalfNormal(\"σ\", sigma)\n        α = pm.Normal(\"α\", 0, σ)\n        p_goal = pm.Deterministic(\"p_goal\", 2 * Phi(tt.arctan(half_length / penalty_point) / σ) - 1)\n        pps = pm.sample_prior_predictive(250)\n        ppss.append(pps)\n\nSampling: [α, σ]\nSampling: [α, σ]\nSampling: [α, σ]\n\n\n\nfig, axes = plt.subplots(1, 3, subplot_kw=dict(projection=\"polar\"), figsize=(10, 4))\n\nmax_angle = np.arctan(half_length/penalty_point)\n\nfor sigma, pps, ax in zip(sigmas_deg, ppss, axes):\n    cutoff = pps.prior.data_vars.get(\"p_goal\")[0] &gt; 0.1\n    cax = ax.scatter(pps.prior.data_vars.get(\"α\")[0][cutoff], np.ones_like(pps.prior.data_vars.get(\"α\")[0][cutoff]), c=pps.prior.data_vars.get(\"p_goal\")[0][cutoff],\n               marker=\".\", cmap=\"viridis_r\", vmin=0.1)\n    ax.fill_between(np.linspace(-max_angle, max_angle, 100), 0, 1.01, alpha=0.25)\n    ax.set_yticks([])\n    ax.set_title(f\"$\\sigma = \\mathcal{{HN}}({sigma})$\")\n    ax.plot(0,0, 'o')\nfig.colorbar(cax, extend=\"min\", ticks=[1, 0.5, 0.1], shrink=0.7, aspect=40)\n\n&lt;matplotlib.colorbar.Colorbar at 0x17b8dc090&gt;\n\n\n\n\n\n对\\(\\sigma_\\sigma\\) 分别取5,20,60的三个先验分布向后采样得到上述结果。\n灰色区域表示「射门期望能进球」范围（对应\\(\\alpha\\)，没有风、摩擦等干扰因素），颜色表示进球概率（对应p_goal，实际收干扰后的概率）。可以发现即使射的在灰色范围内，也不能100%进球。而对60来说，某些射向相反方向也有可能进球，这个分布可能不太好。\n此时我们可以做更多选择：我们可以重新思考模型结构引入更多几何知识；或者我们可以使用先验来减少nonsensical的结果，或直接拟合看数据信息是否足够让后验结果合理。\n下面的示例为一个逻辑回归模型，它包含一些二元变量，每个变量回归系数的先验为\\(\\mathcal{N}(0, 1)\\)。\n\nfrom scipy.special import expit\nfig, axes = plt.subplots(1, 3, figsize=(10, 4), sharex=True,  sharey=True)\naxes = np.ravel(axes)\n\nfor dim, ax in zip([2, 5, 20], axes):\n    β = np.random.normal(0, 1, size=(10000, dim))\n    X = np.random.binomial(n=1, p=0.75, size=(dim, 500))\n    az.plot_kde(expit(β @ X).mean(1), ax=ax)\n    ax.set_title(f\"{dim} predictors\")\n    ax.set_xticks([0, 0.5, 1])\n    ax.set_yticks([0, 1, 2])\n\nfig.text(0.34, -0.075, size=18, s=\"mean of the simulated data\")\n\nText(0.34, -0.075, 'mean of the simulated data')\n\n\n\n\n\n可以发现随着predictors的增加先验预测结果分布更偏向于产生极值。 因此我们可能需要一些更强的正则化先验（比如拉普拉斯分布）以保持模型远离极值。\n上述的两个例子都表明先验不能孤立地理解，我们需要将它们放在特定模型的背景下。"
  },
  {
    "objectID": "posts/BMCP_2/index.html#理解你的预测",
    "href": "posts/BMCP_2/index.html#理解你的预测",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.3. 理解你的预测",
    "text": "2.3. 理解你的预测\n我们可以通过posterior predictive checks来理解模型预测的效果。基本思想是后验预测分布抽样应该与观测数据类似。\n下图是一个binomial model的例子。\n\nY = stats.bernoulli(0.7).rvs(100)\nwith pm.Model() as model:\n    θ = pm.Beta(\"θ\", 1, 1)\n    y_obs = pm.Binomial(\"y_obs\",n=1, p=θ, observed=Y)\n    trace_b = pm.sample(1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [θ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 18 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\npred_dist = pm.sample_posterior_predictive(trace_b, model=model).posterior_predictive.y_obs.values[0]\n\nSampling: [y_obs]\n\n\n\n\n\n\n\n    \n      \n      0.12% [5/4000 00:00&lt;00:09]\n    \n    \n\n\n\n_, ax = plt.subplots(1, 2, figsize=(12, 4), constrained_layout=True)\n\naz.plot_dist(pred_dist.sum(1),\n             hist_kwargs={\"color\":\"C2\"}, ax=ax[0])\nax[0].axvline(Y.sum(), color=\"C4\", lw=2.5);\nax[0].axvline(pred_dist.sum(1).mean(), color=\"k\", ls=\"--\")\nax[0].set_yticks([])\nax[0].set_xlabel(\"number of success\")\n\npps_ = pred_dist.mean(1)\nax[1].plot((np.zeros_like(pps_), np.ones_like(pps_)), (1-pps_, pps_), 'C1', alpha=0.01)\n\nax[1].plot((0, 1), (1-Y.mean(), Y.mean()), 'C4', lw=2.5)\nax[1].plot((0, 1), (1-pps_.mean(), pps_.mean()), 'k--')\nax[1].set_xticks((0,1))\nax[1].set_xlabel(\"observed values\")\nax[1].set_ylabel(\"probability\")\n\nText(0, 0.5, 'probability')\n\n\n\n\n\n左图可以比较观测成功数据（蓝色）和后验预测的成功数值分布。右边是另一种概率方式的呈现。上图可知我们后验模型在平均值方面的预测很好。\n后验预测还可以数值进行测试。一种计算方法是：\\[p_{B} = p(T_{sim} \\leq T_{obs} \\mid \\tilde Y)\\]\n其中\\(p_{B}\\)是Bayesian p-value：仿真生成的统计量\\(T_{sim}\\)小于等于观测统计量\\(T_{obs}\\)的概率。统计量\\(T\\)可以是任意指标。在上面的例子中，\\(T_{obs}\\)是成功率（均值）并且比较后验预测结果分布的成功率\\(T_{sim}\\)。当 \\(p_{B} = 0.5\\) 时 \\(T_{sim}\\) 一半大于观测结果一半小于观测结果，这是拟合良好的预期结果。\n以下是Bayesian p-value的绘制，注意 az.plot_bpv(idata, kind=\"p_value\") 新版本绘制有误\n\nidata = az.from_dict(posterior_predictive={\"y\":pred_dist.reshape(2, 500, 100)}, observed_data={\"y\":Y})\n\n\n_, ax = plt.subplots(1, 2, figsize=(10, 4))\naz.plot_bpv(idata, kind=\"p_value\", ax=ax[0])\nax[0].legend([f\"bpv={(Y.mean() &gt; pred_dist.mean(1)).mean():.2f}\"], handlelength=0)\naz.plot_bpv(idata, kind=\"u_value\", ax=ax[1])\nax[1].set_yticks([])\nax[1].set_xticks([0., 0.5, 1.])\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/xarray/core/utils.py:494: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  warnings.warn(\n\n\n\n\n\n以上是 Beta-Binomial model 的后验预测分布。左图显示有误待修复，右图中白色代表理想情况，黑线是预测值比例的KDE。\n\n_, ax = plt.subplots(1, 2, figsize=(10, 4))\naz.plot_bpv(idata, kind=\"t_stat\", t_stat=\"mean\", ax=ax[0])\nax[0].set_title(\"mean\")\naz.plot_bpv(idata, kind=\"t_stat\", t_stat=\"std\", ax=ax[1])\nax[1].set_title(\"standard deviation\")\nax[1].set_xticks([0.32, 0.41, 0.5])\n\n\n\n\n有很多 \\(T\\) 统计量可以被选择。上图中左边为均值，右边为标准差。\n下图有4个例子来帮助我们建立直觉。下图的蓝色线是同一份观测数据来自正态分布，并且有四个后验样本。\n\nn_obs = 500\nsamples = 2000\ny_obs = np.random.normal(0, 1, size=n_obs)\n\nidata1 = az.from_dict(posterior_predictive={\"y\":np.random.normal(0.5, 1, size=(1, samples, n_obs))},\n                      observed_data={\"y\":y_obs})\n\nidata2 = az.from_dict(posterior_predictive={\"y\":np.random.normal(0, 2, size=(1, samples, n_obs))},\n                      observed_data={\"y\":y_obs})\n\nidata3 = az.from_dict(posterior_predictive={\"y\":np.random.normal(0, 0.5, size=(1, samples,n_obs))},\n                      observed_data={\"y\":y_obs})\n\nidata4 = az.from_dict(posterior_predictive={\"y\":np.concatenate(\n                                                [np.random.normal(-0.25, 1, size=(1, samples//2, n_obs)),\n                                                 np.random.normal(0.25, 1, size=(1, samples//2, n_obs))]\n                                                                )},\n                      observed_data={\"y\":y_obs})\n\nidatas = [idata1,\n          idata2,\n          idata3,\n          idata4,\n]\n\n\n_, axes = plt.subplots(len(idatas), 3, figsize=(10, 10), sharex=\"col\")\n\nfor idata, ax in zip(idatas, axes):\n    az.plot_ppc(idata, ax=ax[0], color=\"C1\", alpha=0.01, mean=False, legend=False)\n    az.plot_kde(idata.observed_data[\"y\"].values, ax=ax[0], plot_kwargs={\"color\":\"C4\", \"zorder\":3})\n    ax[0].set_xlabel(\"\")\n    az.plot_bpv(idata, kind=\"p_value\", ax=ax[1])\n    az.plot_bpv(idata, kind=\"u_value\", ax=ax[2])\n    ax[2].set_yticks([])\n    ax[2].set_xticks([0., 0.5, 1.])\n    for ax_ in ax:\n        ax_.set_title(\"\")\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/ppcplot.py:241: FutureWarning: color has been deprecated in favor of colors\n  warnings.warn(\"color has been deprecated in favor of colors\", FutureWarning)\n\n\n\n\n\n以上四个分布：\n\n第一行的预测偏右\n\n第二行的预测结果更离散\n第三行的预测结果更集中\n第四行的预测结果来自高斯混合分布"
  },
  {
    "objectID": "posts/BMCP_2/index.html#数值诊断",
    "href": "posts/BMCP_2/index.html#数值诊断",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.4. 数值诊断",
    "text": "2.4. 数值诊断\n在本节中，我们将讨论马尔可夫链蒙特卡罗方法的最常见和最有用的诊断工具。\n为了演示我们创建人造的后验：\n第一个是good_chains来自 \\(\\Beta(2, 5)\\) ；\n第二个是 bad_chains0 代表不良的后验，通过对good_chains排序及增加小的高斯噪音产生：\n\n值之间不独立，相反它们是高度自相关的；\n两组抽样不是一个分部，因为经历 reshape 和 重排序后，拆分为两部分。\n\n第三个是 bad_chains1 基于 good_chains 并随机在一些位置上插入一些来自同一分布的样本。这种场景很常见，代表一个采样器在一些参数空间表现很好，但是有一些区域很难采样到\n\ngood_chains = stats.beta.rvs(2, 5,size=(2, 2000))\nbad_chains0 = np.random.normal(np.sort(good_chains, axis=None), 0.05,\n                               size=4000).reshape(2, -1)\n\nbad_chains1 = good_chains.copy()\nfor i in np.random.randint(1900, size=4):\n    bad_chains1[i%2:,i:i+100] = np.random.beta(i, 950, size=100)\n\nchains = {\"good_chains\":good_chains,\n          \"bad_chains0\":bad_chains0,\n          \"bad_chains1\":bad_chains1}\n\n\n2.4.1. Effective Sample Size\n当使用 MCMC 方法时，我们需要足够的样本来估计后验分布。样本量是否充足不能直接由抽样次数觉得，因为 MCMC 有自相关性，所以其中包含的信息量会少于iid抽样结果。\nEffective Sample Size (ESS) 可以被理解为考虑了自相关性后换算为iid抽样的样本量。\n\naz.ess(chains).data_vars\n\nData variables:\n    good_chains  float64 3.845e+03\n    bad_chains0  float64 2.443\n    bad_chains1  float64 597.0\n\n\n我们真实抽样次数为4000次，good_chains 与此结果很接近，bad_chains1 少了很多，bad_chains0 则更少。\n以上ess的算法为bulk即中心区域，可以切换为tail或quantile等。\n可视化可以更好的理解ESS在参数空间上的变化。可以用 az.plot_ess(., kind=\"quantiles\") 或者 az.plot_ess(., kind=\"local\")\n\n_, axes = plt.subplots(2, 3, sharey=True, sharex=True)\naz.plot_ess(chains, kind=\"local\", ax=axes[0]);\naz.plot_ess(chains, kind=\"quantile\", ax=axes[1]);\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/xarray/core/utils.py:494: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  warnings.warn(\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/xarray/core/utils.py:494: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  warnings.warn(\n\n\n\n\n\n一般认为 ESS 值要大于400，否则评估结果基本是不靠谱的。\n\n\n2.4.2. Potential Scale Reduction Factor \\(\\hat{R}\\)\n在一般条件下有理论可证明，无论马尔科夫蒙特卡洛方法的起点为哪里都会得到相同的结果。然而这是在无限抽样的情况下，现实中我们只能有限抽样因此需要校验其收敛性。 一种校验方法是从不同起点执行多个 MCMC 链看几个链是否相似。\\(\\hat{R}\\) 就是这种诊断方法的结果。\n\\(\\hat{R}\\) 被解释为 MCMC 有限抽样造成的方差高估，因此成为 “potential scale reduction factor(PSRF)” 。 \\(\\hat{R} = 1\\) 意味着增加样本量不会再降低结果的方差。然而在实践中，最好将其视为一种诊断工具，而不要过度解释它。\n\n计算方法\n假设有 k 个链，每个链有 n 个样本，感兴趣的量为 \\(\\phi\\)，其在目标分布下有期望 \\(\\mu\\) 和 方差 \\(\\sigma ^ 2\\)。\n记 \\(\\phi_{jt}\\) 为链 j 的第 t 个样本 \\(\\phi\\) 的值，那么混合样本中，\\(\\mu\\) 的无偏估计为 \\(\\mu = \\bar{\\phi}\\) 。链之间的方差 B/n 和链内的方差 W 分别为： \\[B/n = \\frac{1}{k-1} \\sum_{j = 1}^{k}(\\bar{\\phi_j} - \\bar{\\phi})^2 \\] \\[W = \\frac{1}{k(n-1)}\\sum_{j = 1}^{k}\\sum_{t=1}^{n}(\\phi_{jt} - \\bar{\\phi}_j) ^ 2\\] 从而可以通过 B 和 W 加权估计 \\(\\sigma ^ 2\\)： \\[\\hat{\\sigma}_{+} ^ 2 = \\frac{n - 1}{n}W + \\frac{B}{n}\\] 如果初始值是从目标分布中抽取的，\\(\\hat{\\sigma}_+^2\\)就是\\(\\sigma\\)的无偏估计。但是如过渡分散则会高估。考虑估计量\\(\\hat{\\mu}\\)的抽样波动，方差的估计值为\\(\\hat{V} = \\hat{\\sigma}^2_+ + \\frac{B}{kn}\\)\n比较混合和链内的推断可以通过： \\[R = \\frac{\\hat{V}}{\\sigma ^ 2}\\] 称 \\(\\sqrt{R}\\) 为 scale reduction factor(SRF) ，其估计值 potential scale reduction factor(PSRF) 为 \\[\\hat{R} = \\frac{\\hat{V}}{W}\\]\n\n理论上 \\(\\hat{R}\\) 应该为1，但是实际中会有一些误差。一般认为 \\(\\hat{R} &lt; 1.1\\) 时可以认为收敛。\n\naz.rhat(chains).data_vars\n\nData variables:\n    good_chains  float64 1.0\n    bad_chains0  float64 2.392\n    bad_chains1  float64 1.023\n\n\n以上结果说明 good_chains 收敛很好，bad_chains0 收敛很差，bad_chains1 稍微好一些但是仍然不符合标准。\n\n\n2.4.3. 蒙特卡洛标准误\n由于通过有限样本的 MCMC 来逼近后验，这引入了额外的不确定性。我们通过 Monte Carlo standard error (MCSE) 来评估引入的不确定性大小。\n如果我们评估参数的值精确度要到小数点后两位，则需要 MCSE 低于小数点后两位。\n当然 MCSE 仅在 ESS 足够高且 \\(\\hat{R}\\) 足够小时才有意义。\n\naz.mcse(chains).data_vars\n\nData variables:\n    good_chains  float64 0.002561\n    bad_chains0  float64 0.107\n    bad_chains1  float64 0.00688\n\n\n与 ESS 一样，MCSE 在参数空间中变化，可能需要在不同区间（比如分位点）评估。我们可以进行可视化：\n\naz.plot_mcse(chains);\n\n\n\n\nESS ，\\(\\hat{R}\\) 和 MCSE 可以通过 az.summary(.) 一起计算：\n\naz.summary(chains, kind=\"diagnostics\")\n\n\n\n\n\n\n\n\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ngood_chains\n0.003\n0.002\n3845.0\n3883.0\n1.00\n\n\nbad_chains0\n0.107\n0.087\n2.0\n11.0\n2.39\n\n\nbad_chains1\n0.007\n0.005\n597.0\n1268.0\n1.02\n\n\n\n\n\n\n\n\n\n2.4.4. Trace Plots\nTrace Plots 可能是最常用的分析方法。从中我们可以观察到不同 chains 是否收敛到相似分布。\n\naz.plot_trace(chains);\n\n\n\n\n\n\n2.4.5. Autocorrelation Plots\n自相关性是导致 MCMC 结果信息量不足的主要原因。我们可以通过自相关图来观察自相关性。\n\naz.plot_autocorr(chains, combined=True);\n\n\n\n\n\n\n2.4.6. Rank Plots\nRank Plots是另一种常见诊断方法。它先将所有链混合排序，在分别绘制各个链的rank分布。如果所有链都是从同一分布中抽取的，那么rank分布应该是相似的，并且为均匀分布。\n\naz.plot_rank(chains, kind=\"bars\");\n\n\n\n\n\naz.plot_rank(chains, kind=\"vlines\");\n\n\n\n\nRank Plots 可能比 Trace Plots 更敏感。可以将它们一起绘制\n\naz.plot_trace(chains, kind=\"rank_bars\");\n\n\n\n\n\naz.plot_trace(chains, kind=\"rank_vlines\");\n\n\n\n\n\n\n2.4.7. Divergences（散度）\n以上都是基于 MCMC 生成的样本进行诊断。另一种诊断方法是监控抽样过程。\n其中一个典型的例子是 Hamiltonian Monte Carlo (HMC) 中的Divergences，它是一种强大且敏感的方法，可以作为前面方法的补充。\n以下是一个示例\n\nmodel_0：\\(\\theta_2\\) 服从 \\([-\\theta_1, \\theta_1]\\)的均匀分布，而 \\(\\theta_1\\) 来自一个正态分布\nmodel_1：\\(\\theta_2\\) 服从 \\([-\\theta_1, \\theta_1]\\)的均匀分布，而 \\(\\theta_1\\) 来自一个半正态分布\nmodel_2：\\(\\theta_2\\) 服从 \\([-\\theta_1, \\theta_1]\\)的均匀分布，而 \\(\\theta_1\\) 来自一个正态分布\n\n\nwith pm.Model() as model_0:\n    theta_1 = pm.Normal(\"theta_1\", 0, 1, initval=0.1)\n    theta_2 = pm.Uniform(\"theta_2\", -theta_1, theta_1)\n    idata_0 = pm.sample(return_inferencedata=True)\n\nwith pm.Model() as model_1:\n    theta_1 = pm.HalfNormal(\"theta_1\",1 / (2/np.pi)**0.5)\n    theta_2 = pm.Uniform(\"theta_2\", -theta_1, theta_1)\n    idata_1 = pm.sample(return_inferencedata=True)\n\nwith pm.Model() as model_1bis:\n    theta_1 = pm.HalfNormal(\"theta_1\",1 / (2/np.pi)**0.5)\n    theta_2 = pm.Uniform(\"theta_2\", -theta_1, theta_1)\n    idata_1bis = pm.sample(return_inferencedata=True, target_accept=0.95)\n\nidatas = [idata_0, idata_1, idata_1bis]\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [theta_1, theta_2]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.\nThere were 2202 divergences after tuning. Increase `target_accept` or reparameterize.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [theta_1, theta_2]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 19 seconds.\nThere were 20 divergences after tuning. Increase `target_accept` or reparameterize.\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [theta_1, theta_2]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 19 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 2,202 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 20 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nfig, axes = plt.subplots(6, 2, figsize=(10, 10))\n\naxes = axes.reshape(3, 2, 2)\nfor idata, ax, color in zip(idatas, axes, [\"0.95\", \"1\", \"0.95\"]):\n    az.plot_trace(idata, kind=\"rank_vlines\", axes=ax);\n    [ax_.set_facecolor(color) for ax_ in ax.ravel()]\nfig.text(0.45, 1, s=\"model 0\", fontsize=16)\nfig.text(0.45, 0.67, s=\"model 1\", fontsize=16)\nfig.text(0.45, 0.33, s=\"model 1bis\", fontsize=16)\n\nText(0.45, 0.33, 'model 1bis')\n\n\n\n\n\n以上在KDEs图中可以看到底部的黑线，每个黑线代表一次divergence，说明抽样中产生了问题。\n\nmodel_0：有很多divergence，这是因为我们先验选择了正态分布，会出现 \\(-\\theta_1 &gt; \\theta_1\\) 的情况；\nmodel_1：divergence少了很多，因为我们先验选择了半正态分布，不会出现 \\(-\\theta_1 &gt; \\theta_1\\) 的情况；\nmodel_2：基于model_1，将 target_accept 从默认的0.8改为0.95，消除了所有divergence。\n\n我们也可以用散点图来观察divergence：\n\n_, axes = plt.subplots(1, 3, figsize=(12, 5), sharex=True, sharey=True)\n\nfor idata, ax, model in zip(idatas, axes, [\"model 0\", \"model 1\", \"model 1bis\"]):\n    az.plot_pair(idata, divergences=True, scatter_kwargs={\"color\":\"C1\"}, divergences_kwargs={\"color\":\"C4\"}, ax=ax)\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(\"\")\n    ax.set_title(model)\naxes[0].set_ylabel('θ2', rotation=0, labelpad=15)\naxes[1].set_xlabel('θ1', labelpad=10)\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/xarray/core/utils.py:494: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n  warnings.warn(\n\n\nText(0.5, 0, 'θ1')\n\n\n\n\n\n\n\n2.4.8. 采样器参数和其他诊断信息\n大部分抽样方法都有影响效果的超参数，比如有时增大 target_accept 可以消除 divergence。还有其他参数可以调整，比如有些模型更复杂需要更多的跌打，可以增加 tune 去增大 ESS 和减少 \\(\\hat{R}\\)。也可以增加采样次数，但是一般效果不大。重新参数化、改进模型结构、提供更多信息的先验，甚至更改模型通常会更有效。"
  },
  {
    "objectID": "posts/BMCP_2/index.html#模型比较",
    "href": "posts/BMCP_2/index.html#模型比较",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.5. 模型比较",
    "text": "2.5. 模型比较\n建模时不能过于简单从而丢失信息，也不能过于复杂从而过拟合。\n一种有用的解决方案是计算泛化误差，也称为样本外预测准确性。这是指模型在新数据上的表现。 \\[\\text{ELPD} = \\sum_{i=1}^{n} \\int p_t(\\tilde y_i) \\; \\log p(\\tilde y_i \\mid y_i) \\; d\\tilde y_i\\]\n上述公式被称为 expected log pointwise predictive density (ELPD)。其中 \\(p_t(\\tilde y_i)\\) 是真实分布，\\(p(\\tilde y_i \\mid y_i)\\) 是模型预测的后验分布。\n现实生活中无法知道 \\(p_t(\\tilde y_i)\\) ，因此 ELPD 无法直接计算，可以通过下面公式代替： \\[\\sum_{i=1}^{n} \\log \\int \\ p(y_i \\mid \\boldsymbol{\\theta}) \\; p(\\boldsymbol{\\theta} \\mid y) d\\boldsymbol{\\theta}\\]\n\n2.5.1. Cross-validation and LOO\nLeave-one-out cross-validation (LOO-CV) 是交叉验证的一种特别方法，每次只留一个数据点作为测试集，其余作为训练集。 \\[\\text{ELPD}_\\text{LOO-CV} = \\sum_{i=1}^{n} \\log\n    \\int \\ p(y_i \\mid \\boldsymbol{\\theta}) \\; p(\\boldsymbol{\\theta} \\mid y_{-i}) d\\boldsymbol{\\theta}\n\\]\n以上直接计算消耗很大，好在可以用 Pareto smoothed importance sampling leave-one-out cross validation (PSIS-LOO-CV) 近似，后面会称为 LOO 。以下是示例：\n\ny_obs =  np.random.normal(0, 1, size=100)\nidatas_cmp = {}\n\nwith pm.Model() as mA:\n    σ = pm.HalfNormal(\"σ\", 1)\n    y = pm.SkewNormal(\"y\", 0, σ, observed=y_obs)\n    loglik = pm.Deterministic('log_likelihood', pm.logp(y, y_obs))\n    idataA = pm.sample(return_inferencedata=True)\n    idataA.add_groups({\"posterior_predictive\": {\"y\":pm.sample_posterior_predictive(idataA).posterior_predictive.y.values}})\n    idataA.add_groups({\"log_likelihood\": {\"y\":idataA.posterior.log_likelihood}})\n    idatas_cmp[\"mA\"] = idataA\n\nwith pm.Model() as mB:\n    σ = pm.HalfNormal(\"σ\", 1)\n    y = pm.Normal(\"y\", 0, σ, observed=y_obs)\n    loglik = pm.Deterministic('log_likelihood', pm.logp(y, y_obs))\n    idataB = pm.sample(return_inferencedata=True)\n    idataB.add_groups({\"posterior_predictive\": {\"y\":pm.sample_posterior_predictive(idataB).posterior_predictive.y.values}})\n    idataB.add_groups({\"log_likelihood\": {\"y\":idataB.posterior.log_likelihood}})\n    idatas_cmp[\"mB\"] = idataB\n\nwith pm.Model() as mC:\n    μ = pm.Normal(\"μ\", 0, 1)\n    σ = pm.HalfNormal(\"σ\", 1)\n    y = pm.Normal(\"y\", μ, σ, observed=y_obs)\n    loglik = pm.Deterministic('log_likelihood', pm.logp(y, y_obs))\n    idataC = pm.sample(return_inferencedata=True)\n    idataC.add_groups({\"posterior_predictive\": {\"y\":pm.sample_posterior_predictive(idataC).posterior_predictive.y.values}})\n    idataC.add_groups({\"log_likelihood\": {\"y\":idataC.posterior.log_likelihood}})\n    idatas_cmp[\"mC\"] = idataC\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 20 seconds.\nThere were 29 divergences after tuning. Increase `target_accept` or reparameterize.\nSampling: [y]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 19 seconds.\nSampling: [y]\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [μ, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\nSampling: [y]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 29 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:01&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\ncmp = az.compare(idatas_cmp)\ncmp.round(2)\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'True' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmA\n0\n-140.80\n0.31\n0.00\n0.84\n6.50\n0.00\nTrue\nlog\n\n\nmB\n1\n-141.02\n0.89\n0.21\n0.16\n6.82\n0.80\nFalse\nlog\n\n\nmC\n2\n-142.10\n1.95\n1.30\n0.00\n6.84\n0.97\nFalse\nlog\n\n\n\n\n\n\n\n注意：PyMC更换新版本后计算结果与原文不一致，而且mA出现warning。以上模型中mB最好，但是给出的列表中mA最好（本应最差），这是因为mA的计算有问题。\n以上列含义：\n\nrank：对比排名；\nelpd_loo：ELPD值；\np_loo：惩罚项的值。我们可以粗略地认为这个值是估计的有效参数数量（但不要太认真）。该值可能低于具有更多结构（如分层模型）的模型中参数的实际数量，或者当模型具有非常弱的预测能力并且可能指示严重的模型错误指定时，该值可能远高于实际数量；\nelpd_diff：与最佳模型的ELPD差值；\nweight：分配给每个模型的权重。这些权重可以粗略地解释为给定数据的每个模型（在比较模型中）的概率；\nse：ELPD的标准误；\ndse：ELPD差值的标准误；\nwarning：如果为 True 则这是一个警告，表明 LOO 近似可能不可靠；\nscale：报告值的计算方式，默认为对数刻度。\n\n\n\n2.5.2. Expected Log Predictive Density\n上述是全局比较，因此将模型和数据简化为单个数字。但LOO是逐点的总和，因此也可以通过az.plot_elpd(.)进行局部比较。\n\n\n2.5.3. Pareto Shape Parameter\n以上通过 \\(\\text{ELPD}_\\text{LOO-CV}\\) 来逼近 LOO 。以上计算中 $$ 会有问题， 特别是 \\(\\hat \\kappa &gt; 0.7\\)时（mA）。\n这种情况下的建议为：\n\n使用匹配矩法。通过一些额外的计算，可以转换从后验分布得出的 MCMC，以获得更可靠的重要性采样估计；\n对有问题的观察结果执行精确的留一交叉验证或使用 k 折交叉验证；\n使用对异常观察更稳健的模型。\n\n当以上问题发生时会在得到warning，可以可视化检查 $$\n\n_, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\nfor idx, (model, ax) in enumerate(zip((\"mA\", \"mB\", \"mC\"), axes)):\n    loo_ = az.loo(idatas_cmp[model], pointwise=True)\n    az.plot_khat(loo_, ax=ax, threshold=0.09, show_hlines=True, hlines_kwargs={\"hlines\":0.09, \"ls\":\"--\"})\n    ax.set_title(model)\n    if idx:\n        axes[idx].set_ylabel(\"\")\n    if not idx % 2:\n        axes[idx].set_xlabel(\"\")\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\n\n\n\n\n\n2.5.4. \\(\\hat {\\kappa}\\) 很大时 p_loo 的含义\np_loo 可以宽松地解释为模型中参数的估计有效数量。当 \\(\\hat {\\kappa}\\) 很大时，它还可以提供额外信息。具体可参考原文。\n\n\n2.5.5. LOO-PIT\nLOO除了声明一个模型比另一个模型更好之外，还可以用于其他目的。我们可以通过比较模型来更好地理解它们。随着模型复杂性的增加，仅仅通过查看其数学定义或我们用来实现它的代码来理解它就变得更加困难。因此，使用 LOO 或其他工具（如后验预测检查）比较模型可以帮助我们更好地理解它们。\n对 posterior predictive checks（后验预测检查）的一个批评是我们使用数据两次，一次是为了拟合模型，一次是为了批评它。 LOO-PIT 为这个问题提供了答案。\n\n_, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\nfor model, ax in zip((\"mA\", \"mB\", \"mC\"), axes):\n    az.plot_loo_pit(idatas_cmp[model], y=\"y\", legend=False, use_hdi=True, ax=ax)\n    ax.set_title(model)\n    ax.set_xticks([0, 0.5, 1])\n    ax.set_yticks([0, 1, 2])\n\n\n\n\n\n\n2.5.6. Model Averaging\n像我们关于参数不确定性的贝叶斯学派一样。如果我们不能绝对确定模型就是模型（通常我们不能），那么我们应该在分析时考虑到这种不确定性。考虑模型不确定性的一种方法是对所有考虑的模型进行加权平均，为似乎能更好地解释或预测数据的模型赋予更多权重。\n贝叶斯模型加权的一种方法是通过其 marginal likelihoods ，这称为 Bayesian Model Averaging 贝叶斯模型平均。虽然这在理论上很有吸引力，但在实践中却存在问题。另一种方法是使用 LOO 的值来估计每个模型的权重： \\[w_i = \\frac {e^{-\\Delta_i }} {\\sum_j^k e^{-\\Delta_j }}\\]\n其中 $_i $ 是当前与最优模型的 LOO 之差。这种方法称为 pseudo Bayesian model averaging 伪贝叶斯模型平均。\n模型平均的另一个选择是叠加预测分布。主要思想是将多个模型组合在一个元模型中，从而最小化元模型和真实生成模型之间的差异。当使用对数评分规则时，这相当于计算： \\[\\max_{w} \\frac{1}{n} \\sum_{i=1}^{n}log\\sum_{j=1}^{k} w_j p(y_i \\mid y_{-i}, M_j)\\]\n其中 n 是样本个数，k 是模型个数。为了有解约束 \\(w_j \\geq 0\\) 而且 \\(\\sum_{j=1}^{k} w_j = 1\\) 。 \\(p(y_i \\mid y_{-i}, M_j)\\) 是第 j 个模型的 leave-one-out 预测分布。"
  },
  {
    "objectID": "posts/BMCP_2/index.html#练习",
    "href": "posts/BMCP_2/index.html#练习",
    "title": "【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析",
    "section": "2.6. 练习",
    "text": "2.6. 练习\n待完善"
  },
  {
    "objectID": "posts/BMCP_4/index.html",
    "href": "posts/BMCP_4/index.html",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "",
    "text": "在第 3 章中，我们展示了使用和扩展线性回归的多种方法。但我们还可以利用线性模型做更多的事情。\n从协变量变换、变方差到多层模型：这些想法中的每一个都提供了在更广泛的情况下使用线性回归的额外灵活性。"
  },
  {
    "objectID": "posts/BMCP_4/index.html#协变量变换",
    "href": "posts/BMCP_4/index.html#协变量变换",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.1 协变量变换",
    "text": "4.1 协变量变换\n在第 3 章中，我们看到，使用线性模型和链接函数，\\(x_i\\) 上的单位变化会在 \\(Y\\) 上产生 \\(\\beta_i\\) 的预期变化。然后我们看到了如何通过更改似然函数（例如从高斯函数到伯努利函数）来创建广义线性模型，这通常需要更改链接函数。\n对普通线性模型的另一个有用的修改是变换协变量 \\(X\\)，从而使得 \\(X\\) 和 \\(Y\\) 产生非线性关系。我们可以扩展： \\[\\begin{split}\n    \\mu =& \\beta_0 + \\beta_1 f_1(X_1) + \\dots + \\beta_m f_m(X_m) \\\\\nY \\sim& \\mathcal{N}(\\mu, \\sigma)\n\\end{split}\\]\n前面的章节中 \\(f_i(.)\\) 函数没有做任何变换或者做 centering。但是 \\(f_i(.)\\) 可以是任意变换。以下是 babies_data 的例子，我们先看下年龄与长度的关系：\n\nimport pymc as pm\nimport matplotlib.pyplot as plt\nimport arviz as az\nimport pandas as pd\nfrom scipy import special, stats\nimport numpy as np\n\nfrom pytensor import tensor as tt\n\nimport datetime\nprint(f\"Last Run {datetime.datetime.now()}\")\n\nLast Run 2024-01-20 10:41:37.885477\n\n\n\naz.style.use(\"arviz-grayscale\")\nplt.rcParams['figure.dpi'] = 300 \n\n\nbabies = pd.read_csv('../data/babies.csv')\n\n# Add a constant term so we can use a the dot product approach\nbabies[\"Intercept\"] = 1\n\nfig, ax = plt.subplots()\n\nax.plot(babies[\"Month\"], babies[\"Length\"], 'C0.', alpha=0.1)\nax.set_ylabel(\"Length\")\nax.set_xlabel(\"Month\");\n\n\n\n\n用普通线性模型拟合年龄与长度的关系：\n\nwith pm.Model() as model_baby_linear:\n    β = pm.Normal(\"β\", sigma=10, shape=2)\n\n    μ = pm.Deterministic(\"μ\", pm.math.dot(babies[[\"Intercept\", \"Month\"]], β))\n    ϵ = pm.HalfNormal(\"ϵ\", sigma=10)\n\n    length = pm.Normal(\"length\", mu=μ, sigma=ϵ, observed=babies[\"Length\"])\n\n    loglik = pm.Deterministic('log_likelihood', pm.logp(length, babies[\"Length\"]))\n\n    trace_linear = pm.sample(draws=2000, tune=4000)\n    pcc_linear = pm.sample_posterior_predictive(trace_linear)\n    trace_linear.extend(pcc_linear)\n    trace_linear.add_groups({\"log_likelihood\": {\"length\":trace_linear.posterior.log_likelihood}})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [β, ϵ]\nSampling 4 chains for 4_000 tune and 2_000 draw iterations (16_000 + 8_000 draws total) took 28 seconds.\nSampling: [length]\n\n\n\n\n\n\n\n    \n      \n      100.00% [24000/24000 00:09&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\nfig, ax = plt.subplots()\n\nax.set_ylabel(\"Length\")\nax.set_xlabel(\"Month\");\n\nμ_m = trace_linear.posterior[\"μ\"].values.reshape(-1, babies[\"Length\"].shape[0]).mean(axis=0)\n\nax.plot(babies[\"Month\"], μ_m, c='C4')\naz.plot_hdi(babies[\"Month\"], trace_linear.posterior_predictive[\"length\"], hdi_prob=.50, ax=ax)\naz.plot_hdi(babies[\"Month\"], trace_linear.posterior_predictive[\"length\"], hdi_prob=.94, ax=ax)\n\nax.plot(babies[\"Month\"], babies[\"Length\"], 'C0.', alpha=0.1)\n\n\n\n\n以上模型假设年龄与长度的关系是线性的，但是我们可以看到，年龄与长度的关系是非线性的。我们可以对年龄进行平方根变化，然后再拟合模型：\n\nwith pm.Model() as model_baby_sqrt:\n    β = pm.Normal(\"β\", sigma=10, shape=2)\n\n    μ = pm.Deterministic(\"μ\", β[0] + β[1] * np.sqrt(babies[\"Month\"]))\n    σ = pm.HalfNormal(\"σ\", sigma=10)\n\n    length = pm.Normal(\"length\", mu=μ, sigma=σ, observed=babies[\"Length\"])\n    loglik = pm.Deterministic('log_likelihood', pm.logp(length, babies[\"Length\"]))\n    inf_data_sqrt = pm.sample(draws=2000, tune=4000)\n    ppc_baby_sqrt = pm.sample_posterior_predictive(inf_data_sqrt)\n    inf_data_sqrt.extend(ppc_baby_sqrt)\n    inf_data_sqrt.add_groups({\"log_likelihood\": {\"length\":inf_data_sqrt.posterior.log_likelihood}})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [β, σ]\nSampling 4 chains for 4_000 tune and 2_000 draw iterations (16_000 + 8_000 draws total) took 29 seconds.\nSampling: [length]\n\n\n\n\n\n\n\n    \n      \n      100.00% [24000/24000 00:10&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\nfig, axes = plt.subplots(1,2)\naxes[0].plot(babies[\"Month\"], babies[\"Length\"], 'C0.', alpha=0.1)\n\nμ_m = inf_data_sqrt.posterior[\"μ\"].values.reshape(-1, babies[\"Length\"].shape[0]).mean(axis=0)\n\naxes[0].plot(babies[\"Month\"], μ_m, c='C4')\naz.plot_hdi(babies[\"Month\"], inf_data_sqrt.posterior_predictive[\"length\"], hdi_prob=.50, ax=axes[0])\naz.plot_hdi(babies[\"Month\"], inf_data_sqrt.posterior_predictive[\"length\"], hdi_prob=.94, ax=axes[0])\n\naxes[0].set_ylabel(\"Length\")\naxes[0].set_xlabel(\"Month\");\n\naxes[1].plot(np.sqrt(babies[\"Month\"]), babies[\"Length\"], 'C0.', alpha=0.1)\naxes[1].set_xlabel(\"Square Root of Month\");\n\naz.plot_hdi(np.sqrt(babies[\"Month\"]), inf_data_sqrt.posterior_predictive[\"length\"], hdi_prob=.50, ax=axes[1])\naz.plot_hdi(np.sqrt(babies[\"Month\"]), inf_data_sqrt.posterior_predictive[\"length\"], hdi_prob=.94, ax=axes[1])\naxes[1].plot(np.sqrt(babies[\"Month\"]), μ_m, c='C4')\n\naxes[1].set_yticks([])\naxes[1]\n\n&lt;Axes: xlabel='Square Root of Month'&gt;\n\n\n\n\n\n\naz.compare({\"Linear Model\":trace_linear, \"Non Linear Model\":inf_data_sqrt})\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/stats/stats.py:307: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'log' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df_comp.loc[val] = (\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nNon Linear Model\n0\n-1968.150184\n3.013602\n0.00000\n0.929245\n18.971148\n0.00000\nFalse\nlog\n\n\nLinear Model\n1\n-2133.262994\n3.165222\n165.11281\n0.070755\n18.580309\n20.06535\nFalse\nlog\n\n\n\n\n\n\n\n通过可视化和compare比较，我们可以看到，变换后的模型更好的拟合了数据。"
  },
  {
    "objectID": "posts/BMCP_4/index.html#变方差-varying-uncertainty",
    "href": "posts/BMCP_4/index.html#变方差-varying-uncertainty",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.2. 变方差 Varying Uncertainty",
    "text": "4.2. 变方差 Varying Uncertainty\n上述模型都假设残差的方差不变。然而固定方差假设可能是有缺陷的建模选择。将不确定性的变化也考虑进来： \\[\n\\begin{split}\n    \\mu =& \\beta_0 + \\beta_1 f_1(X_1) + \\dots + \\beta_m f_m(X_m) \\\\\n    \\sigma =& \\delta_0 + \\delta_1 g_1(X_1) + \\dots + \\delta_m g_m(X_m) \\\\\nY \\sim& \\mathcal{N}(\\mu, \\sigma)\n\\end{split}\n\\]\n第二列对 \\(\\sigma\\) 的估计与对均值的估计很想。我们可以用线性模型对模型参数建模。举个例子，我们可以假设 baby 的长度的差异随年龄增加。\n\nwith pm.Model() as model_baby_vv:\n    β = pm.Normal(\"β\", sigma=10, shape=2)\n    \n    # Additional variance terms\n    δ = pm.HalfNormal(\"δ\", sigma=10, shape=2)\n\n    μ = pm.Deterministic(\"μ\", β[0] + β[1] * np.sqrt(babies[\"Month\"]))\n    σ = pm.Deterministic(\"σ\", δ[0] + δ[1] * babies[\"Month\"])\n\n    length = pm.Normal(\"length\", mu=μ, sigma=σ, observed=babies[\"Length\"])\n    \n    trace_baby_vv = pm.sample(2000, target_accept=.95)\n    ppc_baby_vv = pm.sample_posterior_predictive(trace_baby_vv,\n                                                 var_names=[\"length\", \"σ\"])\n    trace_baby_vv.extend(ppc_baby_vv)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [β, δ]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 27 seconds.\nSampling: [length]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:08&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n为了模拟随着观察到的儿童年龄的增长，长度的离散性不断增加，我们改变了我们的定义 \\(\\sigma\\) 从固定值到随年龄变化的值。换句话说，我们将模型假设从同方差 homoscedastic 更改为异方差 heteroscedastic\n\naz.summary(trace_baby_vv, var_names=[\"δ\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nδ[0]\n2.388\n0.116\n2.177\n2.609\n0.002\n0.002\n2730.0\n2962.0\n1.0\n\n\nδ[1]\n0.038\n0.009\n0.022\n0.057\n0.000\n0.000\n2707.0\n2633.0\n1.0\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(2,1)\n\naxes[0].plot(babies[\"Month\"], babies[\"Length\"], 'C0.', alpha=0.1)\n\nμ_m = trace_baby_vv.posterior[\"μ\"].values.reshape(-1, babies[\"Length\"].shape[0]).mean(axis=0)\n\naxes[0].plot(babies[\"Month\"], μ_m, c='C4')\n\naz.plot_hdi(babies[\"Month\"], trace_baby_vv.posterior_predictive[\"length\"], hdi_prob=.50, ax=axes[0])\naz.plot_hdi(babies[\"Month\"], trace_baby_vv.posterior_predictive[\"length\"], hdi_prob=.94, ax=axes[0])\naxes[0].set_ylabel(\"Length\")\n\nσ_m = trace_baby_vv.posterior[\"σ\"].values.reshape(-1, 800).mean(axis=0)\n\naxes[1].plot(babies[\"Month\"], σ_m, c='C1')\n\naxes[1].set_ylabel(\"σ\")\naxes[1].set_xlabel(\"Month\")\n\naxes[0].set_xlim(0,24)\naxes[1].set_xlim(0,24)\n\n(0.0, 24.0)"
  },
  {
    "objectID": "posts/BMCP_4/index.html#交互作用",
    "href": "posts/BMCP_4/index.html#交互作用",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.3. 交互作用",
    "text": "4.3. 交互作用\n迄今为止在我们的所有模型中，我们假设一个协变量对响应变量的影响独立于任何其他协变量。这并非总是如此。考虑这样一种情况：我们想要为特定城镇的冰淇淋销售建模，只有当天气炎热并且有很多地方可以买到冰淇淋时，我们预计销量才会增加。对这种联合现象进行建模需要我们引入一种交互效应，其中一个协变量对输出变量的影响取决于其他协变量的值。我们可以将交互作用表示为： \\[\n\\begin{split}\n    \\mu =& \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1X_2\\\\\n    Y \\sim& \\mathcal{N}(\\mu, \\sigma)\n\\end{split}\n\\]\n让我们使用餐者留下的小费金额建模，我们将重点关注吸烟者与不吸烟者小费金额的差异。特别是我们将研究吸烟与总账单金额之间是否存在交互作用。\n首先我们先假设没有交互作用来建模：\n\ntips_df = pd.read_csv(\"../data/tips.csv\")\ntips = tips_df[\"tip\"]\ntotal_bill_c = (tips_df[\"total_bill\"] - tips_df[\"total_bill\"].mean())  \nsmoker = pd.Categorical(tips_df[\"smoker\"]).codes\ntips_df.head()\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4\n\n\n\n\n\n\n\n\nwith pm.Model() as model_no_interaction:\n    β = pm.Normal(\"β\", mu=0, sigma=1, shape=3)\n    σ = pm.HalfNormal(\"σ\", 1)\n\n    μ = (β[0] +\n         β[1] * total_bill_c + \n         β[2] * smoker)\n\n    obs = pm.Normal(\"obs\", μ, σ, observed=tips)\n    trace_no_interaction = pm.sample(1000, tune=1000)\n\n然后增加交互项建模：\n\nwith pm.Model() as model_interaction:\n    β = pm.Normal(\"β\", mu=0, sigma=1, shape=4)\n    σ = pm.HalfNormal(\"σ\", 1)\n\n    μ = (β[0]\n       + β[1] * total_bill_c\n       + β[2] * smoker\n       + β[3] * smoker * total_bill_c\n        )\n\n    obs = pm.Normal(\"obs\", μ, σ, observed=tips)\n    trace_interaction = pm.sample(1000, tune=1000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [β, σ]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 24 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n_, ax = plt.subplots(1, 2, figsize=(8, 4.5))\n\nβ0_nonint = trace_no_interaction.posterior['β'][:,:,0].values.reshape(-1)\nβ1_nonint = trace_no_interaction.posterior['β'][:,:,1].values.reshape(-1)\nβ2_nonint = trace_no_interaction.posterior['β'][:,:,2].values.reshape(-1)\n\npred_y_non_smokers = β0_nonint + β1_nonint * total_bill_c.values[:,None]\npred_y_smokers = β0_nonint + β1_nonint * total_bill_c.values[:,None] + β2_nonint\n\nax[0].scatter(total_bill_c[smoker==0], tips[smoker==0], label='non-smokers', marker='.')\nax[0].scatter(total_bill_c[smoker==1], tips[smoker==1], label='smokers', marker='.', c=\"C4\")\nax[0].set_xlabel('Total Bill (Centered)')\nax[0].set_ylabel('Tip')\nax[0].legend(frameon=True)\n\nax[0].plot(total_bill_c, pred_y_non_smokers.mean(1), lw=2)\nax[0].plot(total_bill_c, pred_y_smokers.mean(1), lw=2, c=\"C4\")\nax[0].set_title('No Interaction')\n\naz.plot_hdi(total_bill_c, pred_y_non_smokers.T, color='C0', ax=ax[0])\naz.plot_hdi(total_bill_c, pred_y_smokers.T, ax=ax[0], color=\"C4\");\n\nβ0_int = trace_interaction.posterior['β'][:,:,0].values.reshape(-1)\nβ1_int = trace_interaction.posterior['β'][:,:,1].values.reshape(-1)\nβ2_int = trace_interaction.posterior['β'][:,:,2].values.reshape(-1)\nβ3_int = trace_interaction.posterior['β'][:,:,3].values.reshape(-1)\n\n# Because smoker=0 I am ommiting the terms including the smoker covariate\npred_y_non_smokers = (β0_int +\n                      β1_int * total_bill_c.values[:, None])\n\n# Because x1=1 I am ommiting x1\npred_y_smokers = (β0_int +\n                  β1_int * total_bill_c.values[:, None] +\n                  β2_int +\n                  β3_int * total_bill_c.values[:, None])\n\nax[1].scatter(total_bill_c[smoker==0], tips[smoker==0], label='non-smokers', marker='.')\nax[1].scatter(total_bill_c[smoker==1], tips[smoker==1], label='smokers', marker='.', c=\"C4\")\nax[1].set_xlabel('Total Bill (Centered)')\nax[1].set_yticks([])\n\nax[1].set_title('Interaction')\n\nax[1].plot(total_bill_c, pred_y_non_smokers.mean(1), lw=2)\nax[1].plot(total_bill_c, pred_y_smokers.mean(1), lw=2)\naz.plot_hdi(total_bill_c, pred_y_non_smokers.T, color='C0', ax=ax[1])\naz.plot_hdi(total_bill_c, pred_y_smokers.T, ax=ax[1], color=\"C4\");\n\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n/Users/admin/blog/rock_blog/env/lib/python3.11/site-packages/arviz/plots/hdiplot.py:160: FutureWarning: hdi currently interprets 2d data as (draw, shape) but this will change in a future release to (chain, draw) for coherence with other functions\n  hdi_data = hdi(y, hdi_prob=hdi_prob, circular=circular, multimodal=False, **hdi_kwargs)\n\n\n\n\n\n比较左边的非交互模型和右边的交互模型，平均拟合线不再平行，吸烟者和非吸烟者的斜率不同！\n通过引入交互，我们正在构建一个模型，该模型可以有效地将数据分为两类：吸烟者和非吸烟者。使用交互的好处之一是我们使用所有可用数据来拟合单个模型，从而提高估计参数的准确性。针对相同数据构建一个有交互和无交互的模型，以便更轻松地使用 LOO 比较模型。虽然交互效应模型的主要区别在于对每组不同斜率进行建模的灵活性，但对所有数据进行建模会带来许多额外的好处。"
  },
  {
    "objectID": "posts/BMCP_4/index.html#稳健回归-robust-regression",
    "href": "posts/BMCP_4/index.html#稳健回归-robust-regression",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.4. 稳健回归 Robust Regression",
    "text": "4.4. 稳健回归 Robust Regression\n离群值，顾名思义是指超出“合理预期”范围的观察结果。异常值是不受欢迎的，因为这些数据点中的一个或几个可能会显着改变模型的参数估计。\n至少有两种方法可以解决异常值。一种是使用一些预定义的标准删除数据，例如 3 个标准差或 1.5 倍四分位数范围。另一种策略是选择一个可以处理异常值并仍然提供有用结果的模型。在回归中后者通常被称为稳健回归模型，特别是要注意这些模型对远离大量数据的观察不太敏感。从技术上讲，稳健回归是一种旨在较少受到底层数据生成过程违反假设的影响的方法。在贝叶斯回归中，一个例子是将可能性从高斯分布更改为学生 t 分布。\n高斯分布是由两个参数定义的，这些参数控制高斯分布的平均值和标准差。学生的 t 分布也有相同参数。然而还有一个附加参数，通常称为自由度 \\(\\nu\\) 。该参数控制学生 t 分布尾部的权重。将 3 个学生的 t 分布与正态分布进行比较，主要区别在于尾部的密度比例与分布主体的比例。 \\(\\nu\\) 较小时，尾部分布的质量较多，因为 \\(\\nu\\) 增加集中在体积上的密度比例也会增加，学生的 t 分布变得越来越接近高斯分布。当用学生 t 分布替换高斯似然值时，它可以提供对异常值的鲁棒性。\n\nmean = 5\nsigma = 2\n\nx = np.linspace(-5, 15, 1000)\nfig, ax = plt.subplots()\n\nax.plot(x, stats.norm(5,2).pdf(x), label=f\"Normal μ={mean}, σ={sigma}\", color=\"C4\")\n\nfor i, nu in enumerate([1, 2, 20],1):\n    ax.plot(x, stats.t(loc=5, scale=2, df=nu).pdf(x), label=f\"Student T μ={mean}, σ={sigma}, ν={nu}\", color=f\"C{i}\")\n\nax.set_xlim(-5, 18)\nax.legend(loc=\"upper right\", frameon=False)\nax.set_yticks([])\n\n[]\n\n\n\n\n\n假设在阿根廷拥有一家餐厅并销售肉馅卷饼。随着时间的推移，您收集了有关您的餐厅每天的顾客数量和阿根廷比索总收入的数据。大多数数据点都沿着一条线分布，但在几天内，每个客户售出的肉馅卷饼数量远高于周围的数据点。这些可能是大型庆祝活动的日子，例如 5 月 25 日或 7 月 9 日，人们会比平常消耗更多的肉馅卷饼。\n\ndef generate_sales(*, days, mean, std, label):\n    np.random.seed(0)\n    df = pd.DataFrame(index=range(1, days+1), columns=[\"customers\", \"sales\"])\n    for day in range(1, days+1):\n        num_customers = stats.randint(30, 100).rvs()+1\n        \n        # This is correct as there is an independent draw for each customers orders\n        dollar_sales = stats.norm(mean, std).rvs(num_customers).sum()\n        \n        df.loc[day, \"customers\"] = num_customers\n        df.loc[day, \"sales\"] = dollar_sales\n\n    # Fix the types as not to cause Theano errors\n    df = df.astype({'customers': 'int32', 'sales': 'float32'})\n    \n    # Sorting will make plotting the posterior predictive easier later\n    df[\"Food_Category\"] = label\n    df = df.sort_values(\"customers\")\n    return df\n\n\nfig, ax = plt.subplots()\n\nempanadas =  generate_sales(days=200, mean=180, std=30, label=\"Empanada\")\nempanadas.iloc[0] = [50, 92000, \"Empanada\"]\nempanadas.iloc[1] = [60, 90000, \"Empanada\"]\nempanadas.iloc[2] = [70, 96000, \"Empanada\"]\nempanadas.iloc[3] = [80, 91000, \"Empanada\"]\nempanadas.iloc[4] = [90, 99000, \"Empanada\"]\n\nempanadas = empanadas.sort_values(\"customers\")\n\nempanadas.sort_values(\"sales\")[:-5].plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax);\nempanadas.sort_values(\"sales\")[-5:].plot(x=\"customers\", y=\"sales\", kind=\"scatter\", c=\"C4\", ax=ax);\n\nax.set_ylabel(\"Argentine Peso\")\nax.set_xlabel(\"Customer Count\")\nax.set_title(\"Empanada Sales\")\n\nText(0.5, 1.0, 'Empanada Sales')\n\n\n\n\n\n我们都希望估计客户与收入之间的关系。线性回归似乎是合适的，例如使用高斯建模回归。\n\nwith pm.Model() as model_non_robust:\n    σ = pm.HalfNormal(\"σ\", 50)\n    β = pm.Normal(\"β\", mu=150, sigma=20)\n\n    μ = pm.Deterministic(\"μ\", β * empanadas[\"customers\"])\n\n    sales = pm.Normal(\"sales\", mu=μ, sigma=σ, observed=empanadas[\"sales\"])\n    \n    inf_data_non_robust = pm.sample()\n    ppc_empanada_sales = pm.sample_posterior_predictive(\n        inf_data_non_robust)\n    inf_data_non_robust.extend(ppc_empanada_sales)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\nSampling: [sales]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\nfig, axes = plt.subplots(2, 1, figsize=(8, 4), sharex=True)\nμ_m = inf_data_non_robust.posterior[\"μ\"].values.reshape(-1, empanadas.shape[0]).mean(axis=0)\n\nfor i in range(2):\n    empanadas.sort_values(\"sales\")[:-5].plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=axes[i]);\n    empanadas.sort_values(\"sales\")[-5:].plot(x=\"customers\", y=\"sales\", kind=\"scatter\", c=\"C4\", ax=axes[i]);\n    axes[i].plot(empanadas.customers, μ_m, c='C4')\n    az.plot_hdi(empanadas.customers, inf_data_non_robust.posterior_predictive[\"sales\"], hdi_prob=.95, ax=axes[i])\n\n    axes[1].set_ylabel(\"Argentine Peso\")\n\naxes[0].set_ylabel(\"\")\naxes[1].set_xlabel(\"Customer Count\")\naxes[1].set_ylim(400, 25000);\n\n\n\n\n\naz.summary(inf_data_non_robust, kind=\"stats\", var_names=[\"β\", \"σ\"]).round(1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nβ\n207.0\n2.9\n201.8\n212.5\n\n\nσ\n2950.5\n24.3\n2904.5\n2995.8\n\n\n\n\n\n\n\n在预测完成后，我们可视化结果并且，并且用表格列出参数情况。看起来结果不令人满意。\n我们可以重新训练模型，但是这次使用学生 t 分布来建模数据。结果 \\(\\sigma\\) 的估计值从2900下降到152\n\nwith pm.Model() as model_robust:\n    σ = pm.HalfNormal(\"σ\", 50)\n    β = pm.Normal(\"β\", mu=150, sigma=20)\n    ν = pm.HalfNormal(\"ν\", 20)\n\n    μ = pm.Deterministic(\"μ\", β * empanadas[\"customers\"])\n    \n    sales = pm.StudentT(\"sales\", mu=μ, sigma=σ, nu=ν,\n                        observed=empanadas[\"sales\"])\n        \n    inf_data_robust = pm.sample(random_seed=0)\n    ppc_empanada_sales_robust = pm.sample_posterior_predictive(\n                                        inf_data_robust)\n    \n    inf_data_robust.extend(ppc_empanada_sales_robust)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β, ν]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\nSampling: [sales]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\naz.summary(inf_data_robust, var_names=[\"β\", \"σ\", \"ν\"], kind=\"stats\").round(1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nβ\n179.6\n0.2\n179.1\n180.1\n\n\nσ\n152.2\n13.8\n127.0\n178.7\n\n\nν\n1.3\n0.2\n1.0\n1.6\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\nμ_m = inf_data_robust.posterior[\"μ\"].values.reshape(-1, empanadas.shape[0]).mean(axis=0)\n\nax.plot(empanadas.customers, μ_m, c='C4')\naz.plot_hdi(empanadas.customers, inf_data_robust.posterior_predictive[\"sales\"], hdi_prob=.95, ax=ax)\n\nempanadas.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax)\nax.set_ylim(4000, 20000);\nax.set_ylabel(\"Argentine Peso\")\nax.set_xlabel(\"Customer Count\")\nax.set_title(\"Empanada Sales with Robust Regression Fit\")\n\nText(0.5, 1.0, 'Empanada Sales with Robust Regression Fit')\n\n\n\n\n\n在这个例子中，“异常值”实际上是我们想要建模的问题的一部分，从某种意义上说，它们不是测量误差、数据输入错误等，而是在某些条件下实际发生的观察结果。因此，如果我们想要对“正常”一天的肉馅卷饼平均数量进行建模，那么将它们视为异常值是可以的，但如果我们使用这个平均值来制定下一个节日的计划则会导致灾难。因此可能使用混合模型或多级模型更好地建模效果更好。"
  },
  {
    "objectID": "posts/BMCP_4/index.html#pooling-multilevel-models-and-mixed-effects",
    "href": "posts/BMCP_4/index.html#pooling-multilevel-models-and-mixed-effects",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.5. Pooling, Multilevel Models, and Mixed Effects",
    "text": "4.5. Pooling, Multilevel Models, and Mixed Effects\n我们的数据集中的预测变量经常包含额外的嵌套结构，这为数据分组提供了一种分层方式。我们也可以将其视为不同的数据生成过程。我们将用一个例子来说明这一点。\n假设你在一家销售沙拉的餐厅公司工作。这家公司在一些地理市场上有着长期的业务，并且由于客户需求，刚刚在新市场开设了一个地点。你需要预测这个新市场的餐厅每天将赚取多少美元，以便进行财务规划。你有两个数据集，一个是3天的沙拉销售数据，另一个是在同一市场上大约一年的披萨和三明治销售数据。\n\ndef generate_sales(*, days, mean, std, label):\n    np.random.seed(0)\n    df = pd.DataFrame(index=range(1, days+1), columns=[\"customers\", \"sales\"])\n    for day in range(1, days+1):\n        num_customers = stats.randint(30, 100).rvs()+1\n        \n        # This is correct as there is an independent draw for each customers orders\n        dollar_sales = stats.norm(mean, std).rvs(num_customers).sum()\n        \n        df.loc[day, \"customers\"] = num_customers\n        df.loc[day, \"sales\"] = dollar_sales\n        \n    # Fix the types as not to cause Theano errors\n    df = df.astype({'customers': 'int32', 'sales': 'float32'})\n    \n    # Sorting will make plotting the posterior predictive easier later\n    df[\"Food_Category\"] = label\n    df = df.sort_values(\"customers\")\n    return df\n\n\npizza_df = generate_sales(days=365, mean=13, std=5, label=\"Pizza\")\nsandwich_df = generate_sales(days=100, mean=6, std=5, label=\"Sandwich\")\n\nsalad_days = 3\nsalad_df = generate_sales(days=salad_days, mean=8 ,std=3, label=\"Salad\")\n\n\nsales_df = pd.concat([pizza_df, sandwich_df, salad_df]).reset_index(drop=True)\nsales_df[\"Food_Category\"] = pd.Categorical(sales_df[\"Food_Category\"])\nsales_df\n\n\n\n\n\n\n\n\ncustomers\nsales\nFood_Category\n\n\n\n\n0\n31\n459.895203\nPizza\n\n\n1\n31\n401.147736\nPizza\n\n\n2\n31\n413.345245\nPizza\n\n\n3\n31\n371.909241\nPizza\n\n\n4\n32\n433.797089\nPizza\n\n\n...\n...\n...\n...\n\n\n463\n100\n611.736816\nSandwich\n\n\n464\n100\n667.152954\nSandwich\n\n\n465\n42\n331.625702\nSalad\n\n\n466\n66\n520.900940\nSalad\n\n\n467\n75\n628.937622\nSalad\n\n\n\n\n468 rows × 3 columns\n\n\n\n\nfig, ax = plt.subplots()\npizza_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, c=\"C1\", label=\"Pizza\", marker=\"^\", s=60);\nsandwich_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax,  label=\"Sandwich\", marker=\"s\");\nsalad_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, label=\"Salad\", c=\"C4\");\n\nax.set_xlabel(\"Number of Customers\")\nax.set_ylabel(\"Daily Sales Dollars\")\nax.set_title(\"Aggregated Sales Dollars\")\nax.legend()\n\n&lt;matplotlib.legend.Legend at 0x17f2e1750&gt;\n\n\n\n\n\n从专家知识和数据来看，这三类食品的销售情况存在相似之处。它们都吸引同一类型的顾客，代表相同的快速食品“食品类别”，但它们也不完全相同。在下面的部分中，我们将讨论如何对这种相似但不相似的情况进行建模，但让我们从更简单的情况开始，所有组都彼此无关。\n\n4.5.1. Unpooled Parameters\n我们可以创建一个回归模型，其中我们将每个组（在这种情况下是食品类别）视为与其他组完全分离。这与为每个类别单独运行回归是一样的，这就是我们称其为非池化回归的原因。运行分离的回归与此的唯一区别是，我们正在编写一个单一的模型，并同时估计所有的系数。 \n\\[\\begin{split}\n\\beta_{mj} \\sim& \\overbrace{\\mathcal{N}(\\mu_{\\beta m}, \\sigma_{\\beta m})}^{\\text{Group-specific}}\\\\\n\\sigma_{j} \\sim& \\overbrace{\\mathcal{HN}(\\sigma_{\\sigma})}^{\\text{Group-specific}}\\\\\n\\mu_{j} =& \\beta_{1j} X_1 + \\dots + \\beta_{mj} X_m \\\\\nY \\sim& \\mathcal{N}(\\mu_{j}, \\sigma_{j})\n\\end{split}\\]\n我们不包含截距参数，因为如果一家餐厅的顾客为零，那么总销售额也将为零。\n\ncustomers = sales_df.loc[:, \"customers\"].values\nsales_observed = sales_df.loc[:, \"sales\"].values\nfood_category = pd.Categorical(sales_df[\"Food_Category\"])\n\nwith pm.Model() as model_sales_unpooled:\n    σ = pm.HalfNormal(\"σ\", 20, shape=3)\n    β = pm.Normal(\"β\", mu=10, sigma=10, shape=3)\n    \n    μ = pm.Deterministic(\"μ\", β[food_category.codes] *customers)\n    \n    sales = pm.Normal(\"sales\", mu=μ, sigma=σ[food_category.codes],\n                      observed=sales_observed)\n    \n    trace_sales_unpooled = pm.sample(target_accept=.9)\n    inf_data_sales_unpooled = trace_sales_unpooled.assign_coords({\"β_dim_0\":food_category.categories,\n                \"σ_dim_0\":food_category.categories})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 26 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nsales_unpooled_diagram = pm.model_to_graphviz(model_sales_unpooled)\nsales_unpooled_diagram\n\n\n\n\n在建模后，我们可以绘制参数的 forest plots。可以发现沙拉食品类别不确定性很高。\n\naxes = az.plot_forest([inf_data_sales_unpooled],\n                      model_names = [\"Unpooled\",],\n                      var_names=[\"β\"], combined=True, figsize=(7, 1.8));\naxes[0].set_title(\"β parameter estimates 94% HDI\")\n\nText(0.5, 1.0, 'β parameter estimates 94% HDI')\n\n\n\n\n\n\naxes = az.plot_forest([inf_data_sales_unpooled,],\n                      model_names = [\"Unpooled\",],\n                      var_names=[\"σ\"], combined=True, figsize=(7, 1.8));\naxes[0].set_title(\"σ parameter estimates 94% HDI\")\n\nText(0.5, 1.0, 'σ parameter estimates 94% HDI')\n\n\n\n\n\n非合并模型与我们使用数据子集创建三个独立模型没有什么不同，就像我们在比较两个（或更多）组部分中所做的那样，其中每个组的参数是单独估计的，因此我们可以考虑非合并模型用于对每组的独立线性回归进行建模的架构语法糖。更重要的是，现在我们可以使用非池化模型及其估计参数作为基线来比较以下部分中的其他模型，特别是了解额外的复杂性是否合理。\n\n\n4.5.2. Pooled Parameters\n池参数是忽略组区别的参数。\n\n\\[\\begin{split}\n\\beta \\sim& \\overbrace{\\mathcal{N}(\\mu_{\\beta}, \\sigma_{\\beta})}^{\\text{Common}}\\\\\n\\sigma \\sim& \\overbrace{\\mathcal{HN}(\\sigma_{\\sigma})}^{\\text{Common}}\\\\\n\\mu =& \\beta_{1} X_{1} + \\dots + \\beta_{m} X_{m} \\\\\nY \\sim& \\mathcal{N}(\\mu, \\sigma)\n\\end{split}\\]\n\nwith pm.Model() as model_sales_pooled:\n    σ = pm.HalfNormal(\"σ\", 20)\n    β = pm.Normal(\"β\", mu=10, sigma=10)\n\n    μ = pm.Deterministic(\"μ\", β * customers)\n    \n    sales = pm.Normal(\"sales\", mu=μ, sigma=σ, observed=sales_observed)\n                        \n    inf_data_sales_pooled = pm.sample()\n    ppc_sales_pooled = pm.sample_posterior_predictive(inf_data_sales_pooled)\n    inf_data_sales_pooled.extend(ppc_sales_pooled)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 21 seconds.\nSampling: [sales]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\npooled_sales_diagram = pm.model_to_graphviz(model_sales_pooled)\npooled_sales_diagram\n\n\n\n\n\naxes = az.plot_forest([inf_data_sales_pooled, inf_data_sales_unpooled],\n                      model_names = [\"Pooled\", \"Unpooled\"], var_names=[\"σ\"], combined=True, figsize=(7, 1.8));\naxes[0].set_title(\"Comparison of pooled and unpooled models \\n 94% HDI\")\n\nText(0.5, 1.0, 'Comparison of pooled and unpooled models \\n 94% HDI')\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\nμ_m = inf_data_sales_pooled.posterior[\"μ\"].values.reshape(-1, sales_df.shape[0]).mean(axis=0)\nσ_m = inf_data_sales_pooled.posterior[\"σ\"].mean().values\n\nax.plot(customers, μ_m, c='C4')\n\naz.plot_hdi(customers, inf_data_sales_pooled.posterior_predictive[\"sales\"], hdi_prob=.50, ax=ax)\naz.plot_hdi(customers, inf_data_sales_pooled.posterior_predictive[\"sales\"], hdi_prob=.94, ax=ax)\n\n\npizza_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, c=\"C1\", label=\"Pizza\", marker=\"^\", s=60);\nsandwich_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax,  label=\"Sandwich\", marker=\"s\");\nsalad_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, label=\"Salad\", c=\"C4\");\n\n\nax.set_xlabel(\"Number of Customers\")\nax.set_ylabel(\"Daily Sales Dollars\")\nax.set_title(\"Pooled Regression\")\n\nText(0.5, 1.0, 'Pooled Regression')\n\n\n\n\n\n从上面的可视化发现，池化的好处是不确定性降低了，但是预测结果对每组都不太好。\n\n\n4.5.3. Mixing Group and Common Parameters\nunpooled 方法对分组差异区别的很好，但是小样本组不确定性很高；pooled 方法样本量增加了，但是无法区分组差异。我们可以将两种方法结合起来，使用混合参数模型。 \\[\n\\begin{split}\n\\beta_{mj} \\sim& \\overbrace{\\mathcal{N}(\\mu_{\\beta m}, \\sigma_{\\beta m})}^{\\text{Group-specific}}\\\\\n\\sigma \\sim& \\overbrace{\\mathcal{HN}(\\sigma_{\\sigma})}^{\\text{Common}}\\\\\n\\mu_{j} =& \\beta_{1j} X_{1} + \\dots + \\beta_{m} X_{m} \\\\\nY \\sim& \\mathcal{N}(\\mu_{j}, \\sigma)\n\\end{split}\n\\]\n用以上思路重新对数据建模：\n\nwith pm.Model() as model_pooled_sigma_sales:\n    σ = pm.HalfNormal(\"σ\", 20)\n    β = pm.Normal(\"β\", mu=10, sigma=20, shape=3)\n    \n    μ = pm.Deterministic(\"μ\", β[food_category.codes] * customers)\n    \n    sales = pm.Normal(\"sales\", mu=μ, sigma=σ, observed=sales_observed)\n    \n    trace_pooled_sigma_sales = pm.sample()\n    ppc_pooled_sigma_sales = pm.sample_posterior_predictive(trace_pooled_sigma_sales)\n    trace_pooled_sigma_sales.extend(ppc_pooled_sigma_sales)\n\n    inf_data_pooled_sigma_sales = trace_pooled_sigma_sales.assign_coords({\"β_dim_0\":food_category.categories})\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 23 seconds.\nSampling: [sales]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\n\n\n\n\n    \n      \n      100.00% [4000/4000 00:00&lt;00:00]\n    \n    \n\n\n\nmultilevel_sales_diagram = pm.model_to_graphviz(model_pooled_sigma_sales)\nmultilevel_sales_diagram\n\n\n\n\n\naz.summary(inf_data_pooled_sigma_sales, var_names=[\"β\", \"σ\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nβ[Pizza]\n13.024\n0.030\n12.967\n13.080\n0.000\n0.000\n5844.0\n3063.0\n1.0\n\n\nβ[Salad]\n8.127\n0.352\n7.470\n8.786\n0.004\n0.003\n6614.0\n3169.0\n1.0\n\n\nβ[Sandwich]\n6.113\n0.057\n6.006\n6.216\n0.001\n0.000\n6661.0\n3254.0\n1.0\n\n\nσ\n39.260\n1.295\n36.927\n41.748\n0.016\n0.011\n6897.0\n3266.0\n1.0\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 6))\nσ_m = inf_data_sales_pooled.posterior[\"σ\"].mean().values\n\n# Salads\n\nfor i in range(3):\n    category_mask = (food_category.codes==i)\n    μ_m_salads = inf_data_pooled_sigma_sales.posterior[\"μ\"][:,:, category_mask].mean(axis=(0,1))\n    ax.plot(sales_df.customers[category_mask], μ_m_salads, c='C4')\n    az.plot_hdi(sales_df.customers[category_mask], inf_data_pooled_sigma_sales.posterior_predictive[\"sales\"][:,:, (category_mask)], hdi_prob=.50, ax=ax, fill_kwargs={\"alpha\": .5})\n    #az.plot_hdi(sales_df.customers[category_mask], inf_data_pooled_sigma_sales.posterior_predictive[\"sales\"][:,:, (category_mask)], hdi_prob=.94, ax=ax)\n\n\npizza_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, c=\"C1\", label=\"Pizza\", marker=\"^\", s=60);\nsandwich_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax,  label=\"Sandwich\", marker=\"s\");\nsalad_df.plot(x=\"customers\", y=\"sales\", kind=\"scatter\", ax=ax, label=\"Salad\", c=\"C4\");\n\n\nax.set_xlabel(\"Number of Customers\")\nax.set_ylabel(\"Daily Sales Dollars\")\nax.set_title(\"Unpooled Slope Pooled Sigma Regression\")\n\nText(0.5, 1.0, 'Unpooled Slope Pooled Sigma Regression')\n\n\n\n\n\n\naxes = az.plot_forest([inf_data_sales_unpooled,\n                       inf_data_pooled_sigma_sales\n                      ],\n                      model_names = [\"Unpooled\",\n                                     \"Multilevel \"\n                                    ],\n                      var_names=[\"σ\"], combined=True, figsize=(7, 1.8));\naxes[0].set_title(\"Comparison of σ parameters 94% HDI\")\n\nText(0.5, 1.0, 'Comparison of σ parameters 94% HDI')\n\n\n\n\n\n\naxes = az.plot_forest([inf_data_sales_unpooled,\n                       inf_data_pooled_sigma_sales\n                      ],\n                      model_names = [\"Unpooled\",\n                                     \"Multilevel\"\n                                    ],\n                      var_names=[\"β\"], combined=True, figsize=(7, 2.8));\naxes[0].set_title(\"Comparison of β parameters 94% HDI\")\n\nText(0.5, 1.0, 'Comparison of β parameters 94% HDI')"
  },
  {
    "objectID": "posts/BMCP_4/index.html#分层模型",
    "href": "posts/BMCP_4/index.html#分层模型",
    "title": "【Bayesian Modeling and Computation in Python】4.拓展线性模型",
    "section": "4.6. 分层模型",
    "text": "4.6. 分层模型\n在我们迄今为止的数据处理中，我们有两种处理组的选项，池化（pooled）是指没有区分各个组，非池化（unpooled）是指完全区分各个组。然而，回想一下我们初始的餐厅例子，我们认为3种食品类别的参数相似，但并不完全相同。在贝叶斯建模中，我们可以用分层模型来表达这个想法。在分层模型中，参数是部分池化的。部分这个词指的是各个组并不共享一个固定的参数，而是共享一个超先验分布，这个分布描述了先验本身参数的分布。\n\n\\[\\begin{split}\n\\beta_{mj} \\sim& \\mathcal{N}(\\mu_{\\beta m}, \\sigma_{\\beta m}) \\\\\n\\sigma_{h} \\sim& \\overbrace{\\mathcal{HN}(\\sigma)}^{\\text{Hyperprior}} \\\\\n\\sigma_{j} \\sim& \\overbrace{\\mathcal{HN}(\\sigma_{h})}^{\\substack{\\text{Group-specific} \\\\ \\text{pooled}}} \\\\\n\\mu_{j} =& \\beta_{1j} X_1 + \\dots + \\beta_{mj} X_m \\\\\nY \\sim& \\mathcal{N}(\\mu_{j},\\sigma_{j})\n\\end{split}\\]\n\nwith pm.Model() as model_hierarchical_sales:\n    σ_hyperprior = pm.HalfNormal(\"σ_hyperprior\", 20)\n    σ = pm.HalfNormal(\"σ\", σ_hyperprior, shape=3)\n    \n    β = pm.Normal(\"β\", mu=10, sigma=20, shape=3)\n    μ = pm.Deterministic(\"μ\", β[food_category.codes] * customers)\n    \n    sales = pm.Normal(\"sales\", mu=μ, sigma=σ[food_category.codes],\n                      observed=sales_observed)\n    \n    trace_hierarchical_sales = pm.sample(target_accept=.9)\n    \n    inf_data_hierarchical_sales = trace_hierarchical_sales.assign_coords(\n        {\"β_dim_0\":food_category.categories,\n                \"σ_dim_0\":food_category.categories}\n    )\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [σ_hyperprior, σ, β]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 26 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n\nhierarchial_sales_diagram = pm.model_to_graphviz(model_hierarchical_sales)\nhierarchial_sales_diagram\n\n\n\n\n\naxes = az.plot_forest(inf_data_hierarchical_sales, var_names=[\"β\"], combined=True,  figsize=(7, 1.5))\naxes[0].set_title(\"Hierarchical β estimates 94% HDI\")\n\nText(0.5, 1.0, 'Hierarchical β estimates 94% HDI')\n\n\n\n\n\n\naxes = az.plot_forest(inf_data_hierarchical_sales, var_names=[\"σ\", \"σ_hyperprior\"], combined=True,  figsize=(7, 1.8))\naxes[0].set_title(\"Hierarchical σ estimates 94% HDI\")\n\nText(0.5, 1.0, 'Hierarchical σ estimates 94% HDI')\n\n\n\n\n\n\naxes = az.plot_forest([inf_data_sales_unpooled.posterior[\"σ\"].isel(σ_dim_0=1),\n                       inf_data_hierarchical_sales\n                      ],\n                      model_names = [\"sales_unpooled\",\n                                     \"sales_hierarchical\"\n                                    ], combined=True, figsize=(7, 2.6),\n                     var_names=[\"σ\", \"σ_hyperprior\"]\n                     );\naxes[0].set_title(\"Comparison of σ parameters from unpooled \\n and hierarchical models \\n 94% HDI\")\n\nText(0.5, 1.0, 'Comparison of σ parameters from unpooled \\n and hierarchical models \\n 94% HDI')\n\n\n\n\n\n在非池化估计中，沙拉的sigma估计的平均值是21.6，而在分层估计中，同一参数估计的平均值现在是25.7，被披萨和三明治类别的平均值”拉”高了。此外，分层类别中披萨和三明治类别的估计值，虽然稍微向平均值回归，但基本上与非池化估计值保持一致。注意每个sigma的估计值是如何明显不同的。考虑到我们观察到的数据和模型并没有在组之间共享信息，这与我们的预期一致。\n\naz.summary(inf_data_sales_unpooled.posterior[\"σ\"], kind=\"stats\").round(1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nσ[Pizza]\n40.2\n1.4\n37.5\n43.0\n\n\nσ[Salad]\n21.6\n8.7\n8.6\n37.6\n\n\nσ[Sandwich]\n35.9\n2.5\n31.2\n40.5\n\n\n\n\n\n\n\n\naz.summary(inf_data_hierarchical_sales, var_names=[\"σ\", \"σ_hyperprior\"], kind=\"stats\").round(1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nσ[Pizza]\n40.3\n1.5\n37.5\n43.1\n\n\nσ[Salad]\n25.7\n12.7\n8.9\n48.7\n\n\nσ[Sandwich]\n36.3\n2.6\n31.6\n41.2\n\n\nσ_hyperprior\n31.3\n8.7\n17.4\n47.8\n\n\n\n\n\n\n\n层次估计不仅仅限于两个层次。例如，餐厅销售模型可以扩展为三级分层模型，其中顶层代表公司级别，下一级代表地理市场（纽约、芝加哥、洛杉矶），最底层代表个人地点。通过这样做，我们可以得到一个描述整个公司表现如何的超先验，表明一个地区表现如何的超先验，以及表示每个商店表现如何的先验。这样可以轻松比较平均值和变化，并基于单个模型以多种不同方式扩展应用程序。\n\n4.6.1. 后验分布的几何形状很重要 Posterior Geometry Matters\n到目前为止，我们主要关注的是模型背后的结构和数学原理，并假设我们的采样器能够为我们提供后验的“准确”估计。对于相对简单的模型，这基本上是正确的，最新版本的通用推理引擎大多数情况下都能“正常工作”，但重要的一点是，它们并不总是能够正常工作。某些后验的几何形状对采样器来说是具有挑战性的，一个常见的例子是Neal的漏斗，如图所示。正如漏斗这个名字所暗示的，一端的形状非常宽，然后缩小到一个小颈部。回想一下DIY采样器，不要在家尝试这一节，采样器的功能是从一组参数值步进到另一组，一个关键的设置是在探索后验表面时应该走多大的步子。在复杂的几何形状中，比如Neal的漏斗，一个在某个区域工作得很好的步长，在另一个区域可能会失败得很惨。\n\n在分层模型中，几何形状主要由超先验与其他参数的相关性定义，这可能导致难以采样的漏斗几何形状。不幸的是，这不仅是一个理论问题，而且是一个实际问题，它可以相对快速地悄悄出现在毫无戒心的贝叶斯建模者面前。幸运的是，有一个相对简单的模型调整，被称为非中心参数化，可以帮助缓解这个问题。\n继续我们的沙拉例子，假设我们开了6家沙拉餐厅，和之前一样，我们对预测销售额作为客户数量的函数感兴趣。这个合成数据集是用Python生成的。由于餐厅销售的产品完全相同，分层模型适合在各组之间共享信息。 \\[\\begin{split}\n\\beta_{\\mu h} \\sim& \\mathcal{N} \\\\\n\\beta_{\\sigma h} \\sim& \\mathcal{HN} \\\\\n\\beta_m \\sim& \\overbrace{\\mathcal{N}(\\beta_{\\mu h},\\beta_{\\sigma h})}^{\\text{Centered}}  \\\\\n\\sigma_{h} \\sim& \\mathcal{HN} \\\\\n\\sigma_{m} \\sim& \\mathcal{HN}(\\sigma_{h}) \\\\\nY \\sim& \\mathcal{N}(\\beta_{m} * X_m,\\sigma_{m})\n\\end{split}\\]\n运行我们的模型后，首先出现问题的迹象是发散，我们在divergences一节中详细介绍了这个问题。样本空间的绘图是一个诊断工具。注意，当超先验\\(\\beta_{\\sigma h}\\)接近零时，\\(\\beta_m\\)参数的后验估计的宽度趋于缩小。特别注意，附近没有样本。换句话说，当\\(\\beta_{\\sigma h}\\)的值接近零时，用于采样参数\\(\\beta_m\\)的区域会崩溃，采样器无法有效地描述这个后验的空间。\n\n为了缓解这个问题，可以将中心参数化转换为非中心参数化。关键的区别是，它不是直接估计斜率\\(\\beta_m\\)的参数，而是将其建模为所有组共享的公共项和每个组的项，这个项捕获了从公共项的偏差。这以一种方式修改了后验几何形状，使得采样器更容易探索\\(\\beta_{\\sigma h}\\)的所有可能值。\n\\[\n\\begin{split}\n\\beta_{\\mu h} \\sim& \\mathcal{N} \\\\\n\\beta_{\\sigma h} \\sim& \\mathcal{HN} \\\\\n\\beta_\\text{m\\_offset} \\sim& \\mathcal{N}(0,1) \\\\\n\\beta_m =& \\overbrace{\\beta_{\\mu h} + \\beta_\\text{m\\_offset}*\\beta_{\\sigma h}}^{\\text{Non-centered}}  \\\\\n\\sigma_{h} \\sim& \\mathcal{HN} \\\\\n\\sigma_{m} \\sim& \\mathcal{HN}(\\sigma_{h}) \\\\\nY \\sim& \\mathcal{N}(\\beta_{m} * X_m,\\sigma_{m})\n\\end{split}\n\\]\n\n采样的改进对估计分布产生了实质性的影响。虽然再次被提醒这个事实可能会让人感到不安，但采样器只是估计后验分布，虽然在许多情况下它们做得很好，但这并不是保证！一定要注意诊断结果，如果出现警告，就要更深入地调查。\n值得注意的是，对于中心化或非中心化参数化，没有一种适合所有情况的解决方案。这是个体在组级别的可能性信息、组级别先验的信息性以及参数化之间复杂的相互作用（通常，你对特定组有的数据越多，可能性函数就越有信息）。一个通用的启发式规则是，如果没有很多观察值，那么优先选择非中心化参数化。然而，在实践中，你应该尝试几种不同的中心化和非中心化参数化的组合，以及不同的先验规格。你甚至可能发现在一个模型中需要同时使用中心化和非中心化参数化。如果你怀疑模型参数化正在导致你的采样问题，我们建议你阅读Michael Betancourt的案例研究Hierarchical Modeling。\n\n\n\n4.6.2. Predictions at Multiple Levels\n分层模型的一个微妙特性是它们能够在多个层次上进行估计。虽然这看起来很明显，但它非常有用，因为它让我们可以使用一个模型来回答比单层模型更多的问题。在第三章中，我们可以构建一个模型来估计单个物种的质量，或者构建一个模型来估计任何企鹅的质量，而不考虑物种。使用分层模型，我们可以同时用一个模型估计所有企鹅的质量，以及每个企鹅物种的质量。使用我们的沙拉销售模型，我们既可以对个别位置进行估计，也可以对整个人口进行估计。\n另一个使用具有超先验的分层模型进行预测的特性是，我们可以对从未见过的组进行预测。在这种情况下，假设我们在一个新的地点开设了另一家沙拉餐厅，我们可以通过首先从超先验中抽样以获取新地点的 \\(\\beta_{i+1}\\) 和 \\(\\sigma_{i+1}\\)，然后从后验预测分布中抽样以获取沙拉销售预测，从而对沙拉销售可能的情况进行一些预测。\n除了分层建模的数学优势外，从计算角度来看，我们只需要构建和拟合一个模型，这也是一个优点。这加快了建模过程和后续的模型维护过程，如果模型在一段时间内被多次重用的话。\n\n\n4.6.3. Priors for Multilevel Models\n对于多层模型，先验选择更为重要，因为先验如何与可能性的信息性相互作用，如上文“后验几何形状的重要性”一节所示。此外，不仅先验分布的形状很重要，我们还有如何参数化它们的额外选择。这并不限制我们使用高斯先验，因为它适用于 location-scale 分布家族中的所有分布。\n在多层模型中，先验分布不仅描述了组内变异，还描述了组间变异。从某种意义上说，选择超先验就是定义“变异的变异”，这可能使表达和推理关于先验信息变得困难。此外，由于部分池化的效果是超先验的信息性、你拥有的组数以及每个组中的观察数的组合。因此，如果你在使用相同的模型对类似的数据集进行推断，但组数较少，那么相同的超先验可能就不起作用了。\n因此，除了经验性的经验（例如，发表在文章中的一般建议）或一般性的建议，我们还可以进行敏感性研究，以更好地指导我们的先验选择。例如，Lemoine 展示了当使用模型结构对生态数据建模时\n\\[\\begin{split}\n    \\alpha_i \\sim& \\mathcal{N}(\\mu_{\\alpha},\\sigma^2_{\\alpha}) \\\\\n    \\mu_{i} =& \\alpha_i + \\beta Day_i \\\\\n    Y \\sim& \\mathcal{N}(\\mu_{j},\\sigma^2)\n\\end{split}\\]\n其中，截距是未池化的，Cauchy先验在少量数据点提供正则化，并且在模型拟合额外数据时不会模糊后验。这是通过对先验参数化和不同数量的数据进行先验敏感性分析来完成的。在你自己的多层模型中，一定要注意先验选择影响推断的多种方式，并使用你的领域专业知识或者如先验预测分布这样的工具来做出明智的选择。"
  },
  {
    "objectID": "posts/delta方法/index.html",
    "href": "posts/delta方法/index.html",
    "title": "ab实验与Delta方法",
    "section": "",
    "text": "背景\n互联网实验一般使用基于正态分布模型的检验方法，但是在ab实验中我们可能遇到这样的情况：\n1.实验结果分析，实验组均值比对照组均值提升了10%，相对提升的置信区间是多少呢？ 2.实验组用户合计点击率为26%，对照组未25%，置信度与置信区间如何计算？\n在场景1中，实验组均值、对照组均值是分别服从正态分布的，但是它们的比值会服从正态分布么？标准差怎么计算？\n而场景2中，平均浏览数、平均点击数是服从正态分布的，但平均点击率等于平均点击除以平均浏览。我们又陷入了正态分布随机变量除以正态分布随机变量的问题！\nDelta method可以帮助我们解决这类问题。\n\n\nDelta method是什么\nDelta method说的是当一个随机变量服从正态分布时，经过可导的函数变化后仍然概率趋向正态分布，并且提供了期望、方差的计算公式。\n\n单变量下：\n如 \\(\\sqrt{n}[X - \\theta] \\overset{\\nu }{\\rightarrow} N(0, \\sigma^2)\\)，且函数g(x)可导，\n则\\(\\sqrt{n}[g(X) - g(\\theta)] \\overset{\\nu }{\\rightarrow} N(0, \\sigma^2 * [g’(\\theta)]^2)\\)\n\n\n多变量下：\n如 \\(\\sqrt{n}[B - \\beta] \\overset{\\nu }{\\rightarrow} N(0, \\Sigma)\\)，且函数g(x)可导，\n则\\(\\sqrt{n}[h(B) - h(\\theta)] \\overset{\\nu }{\\rightarrow} N(0, \\Delta h(B)^T * \\Sigma * \\Delta h(B))\\)。\n其中\\(\\Sigma\\)是多元正态分布的协方差矩阵，\\(\\Delta h\\)为\\(h\\)函数的梯度向量。\n\n\n\nDelta method的直观理解\n以下为单变量下的个人理解，不等于严格证明。\n泰勒公式：\n\\(f(x) = f(a) + \\frac{f'(a) }{1!}(x -a)+\\frac{f''(a) }{2!}(x -a)^2+...\\)\n根据泰勒公式：\n\\(g(X) \\approx g(\\theta) + g'(\\theta)(X - \\theta)\\)\n则：\n\\(g(X) - g(\\theta) \\approx g'(\\theta)(X - \\theta) \\overset{\\nu }{\\rightarrow} N(0, \\sigma^2 * [g’(\\theta)]^2)\\)\n由于\\(g'(\\theta)(X - \\theta)\\)服从正态分布，左边也近似服从相同的正态分布，且有接近的均值与方差。\n\n\n为什么可以解决AB的问题\n场景1与场景2都是两个正态分布随机变量做除法运算的问题，设一个为Xn，一个为Yn，则(Xn, Yn)服从二元正态分布：\n$ (X_n, Y_n) N((_x，_y), )$\n我们对Xn,Yn的操作等于函数\\(h((x, y)) = y/x\\) ，根据Delta方法：\n\\(\\frac{Yn}{Xn} \\overset{\\nu }{\\rightarrow} N(\\frac{ E[Yn] }{ E[Xn] }, \\Delta h( (X_n, Y_n))^T * \\Sigma * \\Delta h( (X_n, Y_n)))\\)\n其中\\(\\Delta h((x, y)) = [-\\frac{ y}{x^2}, \\frac{1}{x}]^T\\)，\\(\\Sigma = \\begin{bmatrix} {\\sigma(X_n)^2 }&{cov(X_n, Y_n)}\\\\ {cov(X_n, Y_n)}&{\\sigma(Y_n)^2}\\\\ \\end{bmatrix}\\)\n\n\n联系背景问题\n于是我们可以对两个问题的解决方案：\n场景1：\\(X_n\\)对照组均值，\\(Y_n\\)为实验组均值，使用样本均值、样本方差做期望、方差的点估计；\n场景2：\\(X_n\\)为平均用户页面浏览次数，\\(Y_n\\)为平均用户页面点击次数，同样使用样本均值、样本方差做期望、方差的点估计。\n\n\n总结\nDelta方法对实验分析至关重要，已经几乎成为所有AB实验平台的一部分，主要用来解决随机化单位与分析单位不同的问题。\nDelta方法还可以扩展到更高维度，如微软的CUPED论文中通过四元正态分布的Delta方法解决比例型指标的CUPED计算难点。"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html",
    "href": "posts/实验设计_如何选择样本量/index.html",
    "title": "A/B实验设计：样本量计算",
    "section": "",
    "text": "本文介绍样本量对实验效果的影响，以及如何正确选择样本量。仅作为实验设计者可跳过最后数学推导过程，直接使用工具运算。"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html#实验角度样本量越多越好",
    "href": "posts/实验设计_如何选择样本量/index.html#实验角度样本量越多越好",
    "title": "A/B实验设计：样本量计算",
    "section": "实验角度，样本量越多越好",
    "text": "实验角度，样本量越多越好\n样本数量变多，实验则有了更多的“证据”，实验的“可靠性”也就越强。"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html#业务角度样本量越少越好",
    "href": "posts/实验设计_如何选择样本量/index.html#业务角度样本量越少越好",
    "title": "A/B实验设计：样本量计算",
    "section": "业务角度，样本量越少越好",
    "text": "业务角度，样本量越少越好\n样本量应该越少越好，因为：\n\n试错成本大。假设我们拿50%用的户来跑实验，但不幸的是，1周后结果表明实验组的总收入下降了20%。算下来，你的实验在一周内给整个公司带来了10%的损失。这个试错成本未免高了一些…\n其它风险增加。移动端例子，假设B方案崩溃率增长，1%流量我们可以从容处理，50%流量会对业务造成严重影响，甚至事故定责。\n流量有限。流量总数是确定的，同类型的实验不能重叠，实验流量更小，就可以同时运行更多的实验。"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html#参数解释",
    "href": "posts/实验设计_如何选择样本量/index.html#参数解释",
    "title": "A/B实验设计：样本量计算",
    "section": "参数解释",
    "text": "参数解释\n\nBaseline conversion rate：填入实验前估测到的转化率，可以通过旧数据统计作为估算。\nMinimum Detectable Effect：填入希望观测到的最小效果。填入实验的预期。\nStatistical power：1 - 假阴性概率。实验效果真实有效时，能被正确发现的概率。\nSignificance level：假阳性概率。实验实际没有效果时，被错误发现的概率。"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html#单尾假设检验",
    "href": "posts/实验设计_如何选择样本量/index.html#单尾假设检验",
    "title": "A/B实验设计：样本量计算",
    "section": "单尾假设检验",
    "text": "单尾假设检验\n\n定义θ = μ2 - μ1，图中对应假设可转换为： 原假设：θ = 0，此时对应红色曲线 备择假设：θ &gt; 0，此时对应绿色曲线\nμ1：方案A的期望值，不可改变。 μ2：方案B的期望值，不可改变。 $ x$：方案A的均值，会随机波动。 $ y$：方案B的均值，会随机波动。\n$ = ( &gt; C | = ) $ ，红色曲线下，红色面积占比。 $ = ( &lt;= C | &gt; ) $ 。 $ power = ( &gt; C | &gt; ) $ ，绿色曲线下，绿色面积占比。 MDE：根据期望效果取的值，会参与样本量计算 μ2 - μ1 &gt;= mde时，power大于等于预设值，实验容易显著。 μ2 - μ1 &lt; mde时，power小于预设，实验不容易显著。\n在$ &gt; C \\(中，C为预设常量，\\) x\\(、\\) y\\(通过实验获取无法控制，唯一可以改变的是\\)SD( y - x))$，样本量增大 -&gt; $ SD( y - x)) $减少 -&gt; 实验显著概率升高。\n计算过程： \\({SD( \\bar y - \\bar x)} = MDE / [ \\phi^{-1} (\\alpha) + \\phi^{-1} (power )]\\) ,\nx、y样本量同为n，标准差同为$$时， \\({SD( \\bar y - \\bar x)} = \\sqrt{2\\sigma ^{2}/ n}\\),\n易得\\(n = 2\\sigma ^{2} [ \\phi^{-1} (1- \\alpha) + \\phi^{-1} (power )]^{2}/MDE^{2}\\)"
  },
  {
    "objectID": "posts/实验设计_如何选择样本量/index.html#双尾假设检验",
    "href": "posts/实验设计_如何选择样本量/index.html#双尾假设检验",
    "title": "A/B实验设计：样本量计算",
    "section": "双尾假设检验",
    "text": "双尾假设检验\n定义θ = μ2 - μ1，双尾情况下对应假设： 原假设：θ = 0； 备择假设：θ ≠ 0 ，等价于 θ &gt; 0 or θ &lt; 0。\n双尾假设检验一般是对称的，在此情况下有： 1. $= ( &gt; C1 | = ) + ( &lt; C2 | = ) $ 2. $( &gt; C1 | = ) = ( &lt; C2 | = ) $\n正态分布的概率密度函数特点为左右对称(钟形曲线)，由此可知： $ C1 &gt; 0, C2 &lt; 0, |C1| = |C2| $\n可以理解为一个α水平的双尾假设检验，等于两个α/2水平的单尾假设检验。 将α/2带入单尾计算公式，得到双尾检验需要的样本量为： \\(n = 2\\sigma ^{2} [ \\phi^{-1} (1 - \\alpha/2) + \\phi^{-1} (power )]^{2}/MDE^{2}\\)"
  },
  {
    "objectID": "posts/BMCP_1/index.html",
    "href": "posts/BMCP_1/index.html",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "",
    "text": "现代贝叶斯主要通过计算机程序来执行，但是还是需要知道基本原理。\n第一章中主要介绍贝叶斯相关概念和方法原文链接。"
  },
  {
    "objectID": "posts/BMCP_1/index.html#贝叶斯建模",
    "href": "posts/BMCP_1/index.html#贝叶斯建模",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "1.1. 贝叶斯建模",
    "text": "1.1. 贝叶斯建模\n建设模型需要结合领域知识和统计技能。数据是原材料、统计分布是塑造统计模型的主要数据工具。\n\n1.1.1 贝叶斯模型\n贝叶斯建模的两个特点：\n\n用概率分布描绘未知数值。这些数值称为「参数」；\n\n结合观测数值，通过贝叶斯定理更新参数值。\n\n贝叶斯建模的三个步骤：\n\n建模。给定一些数值及这些数值如何被生成的假设，通过随机变量的组合和转换来设计模型；\n\n推断。结合观测到的数据，基于贝叶斯定理更新我们的模型得到后验分布。这个过程称为推断，通过数据来减少不确定性；\n\n验证。通过数据和领域知识来批判模型。有时需要比较多个模型好坏。\n\n第3步验证非常重要！\n\n\n1.1.2 贝叶斯推断\n推断一般指通过证据和理由得出结论贝叶斯推断是统计推断的一种。\n贝叶斯理论给了一种基于\\(\\boldsymbol{Y}\\)来估计\\(\\theta\\)的通用框架：\n\\[\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} = \\frac{\\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}}{\\underbrace{{p(\\boldsymbol{Y})}}_{\\text{marginal likelihood}}}\\]\n先验分布代表不确定性，通过似然函数(likelihood function)链接观测值和不确定的参数。相乘后得到后验的联合分布。\n\n\n\nFig. 1.1\n\n\n计算后验概率还需要知道归一化常数\\(p(\\boldsymbol{Y})\\)：\n\\[{p(\\boldsymbol{Y}) = \\int_{\\boldsymbol{\\Theta}} p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) d\\boldsymbol{\\theta}}\\]\n计算上面的积分常常非常困难，好在一些数值方案可以应对。由于边际似然通常不计算，因此贝叶斯定理经常表示为比例：\n\\[\\underbrace{p(\\boldsymbol{\\theta} \\mid \\boldsymbol{Y})}_{\\text{posterior}} \\propto \\overbrace{p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta})}^{\\text{likelihood}}\\; \\overbrace{p(\\boldsymbol{\\theta})}^{\\text{prior}}\n\\]\n错误的数据和模型会导致无意义的结果。我们必须始终对我们的数据、模型和结果保持一定程度的怀疑：\n\\[p(\\boldsymbol{\\theta} \\mid  \\boldsymbol{Y}, M) \\propto  p(\\boldsymbol{Y} \\mid \\boldsymbol{\\theta}, M) \\; p(\\boldsymbol{\\theta}, M)\n\\]\n推断永远基于假设模型\\(\\boldsymbol{M}\\)。"
  },
  {
    "objectID": "posts/BMCP_1/index.html#一个diy采样器请勿在家里尝试",
    "href": "posts/BMCP_1/index.html#一个diy采样器请勿在家里尝试",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "1.2. 一个DIY采样器，请勿在家里尝试",
    "text": "1.2. 一个DIY采样器，请勿在家里尝试\n归一化常数常不能直接计算，现代贝叶斯推断一般用称为Universal Inference Engines的数值方法。\nUniversal Inference Engines有多种算法。应用可能最广泛也最强大的是Markov chain Monte Carlo methods (MCMC)。从很高的视角来看，所有的MCMC方法都是通过抽样来逼近后验分布。后验分布的样本是通过接受或拒绝proposal distribution生成样本而得到的。因此MCMC也称为采样器，它们都能够评估给定参数值的先验和可能性。也就是说，即使我们不知道整个后验是什么样子，我们也可以逐点询问得到密度。\nMCMC的一种算法是Metropolis-Hastings。它不是一个非常现代或特别有效的算法，但 Metropolis-Hastings 很容易理解，并且还为理解更复杂和强大的方法提供基础。\nMetropolis-Hasting算法：\n\n以\\(x_i\\)初始化参数值\\(\\boldsymbol{X}\\)\n\n通过proposal distribution \\(q(x_{i+1} \\mid x_i)\\)从\\(x_i\\)产生\\(x_{i+1}\\)\n\n计算接受新值的概率： \\[p_a (x_{i + 1} \\mid x_i) = \\min \\left (1, \\frac{p(x_{i + 1}) \\;q(x_i \\mid x_{i + 1})} {p(x_i) \\; q (x_{i + 1} \\mid x_i)} \\right)\\]\n\n\\(R \\sim U(0, 1)\\)，如果\\(p_a &gt; R\\)，保存新值，否则保存旧值\n\n重复2到4的步骤直到生成足够大的值样本\n\n\n举一个具体的例子，简单的Beta-Binomial模型：\n\\[\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\]\n\\[Y \\sim \\text{Bin}(n=1, p=\\theta)\\]\n以上模型有解析解（共轭先验），但是这里我们通过Metropolis-Hastings来计算近：\n\nfrom scipy import stats\n\ndef post(θ, Y, α=1, β=1):\n    if 0 &lt;= θ &lt;= 1:\n        prior = stats.beta(α, β).pdf(θ)\n        like  = stats.bernoulli(θ).pmf(Y).prod()\n        prob = like * prior\n    else:\n        prob = -np.inf\n    return prob\n\n此随机生成一些假数据做观测数据来进行推断：\n\nY = stats.bernoulli(0.7).rvs(20)\n\n之后即可运行Metropolis-Hastings：\n\nimport numpy as np\n\nn_iters = 2000\ncan_sd = 0.05\nα = β =  1\nθ = 0.5\ntrace = {\"θ\":np.zeros(n_iters)}\np2 = post(θ, Y, α, β)\n\nfor iter in range(n_iters):\n    θ_can = stats.norm(θ, can_sd).rvs(1)\n    p1 = post(θ_can, Y, α, β)\n    pa = p1 / p2\n\n    if pa &gt; stats.uniform(0, 1).rvs(1):\n        θ = θ_can\n        p2 = p1\n\n    trace[\"θ\"][iter] = θ\n\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/3034504359.py:19: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  trace[\"θ\"][iter] = θ\n\n\n以上代码仅是示例，并不高效而且可能因为计算精度产生溢出等问题。同样理论上can_sd并不影响结果，但是实践中它非常重要，会影响方法效率。\n现在我们有了 MCMC 示例，我们想要了解它是什么样的。检查贝叶斯推理结果的常见方法是将每次迭代的采样值与直方图或其他可视化工具一起绘制以表示分布：\n\nimport matplotlib.pyplot as plt \n\n_, axes = plt.subplots(1,2, sharey=True)\naxes[0].plot(trace['θ'], '0.5')\naxes[0].set_ylabel('θ', rotation=0, labelpad=15)\naxes[1].hist(trace['θ'], color='0.5', orientation=\"horizontal\", density=True)\naxes[1].set_xticks([])\n\n[]\n\n\n\n\n\n计算一些数值摘要也很有用：\n\nimport arviz as az\n\naz.summary(trace, kind=\"stats\", round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nθ\n0.72\n0.09\n0.55\n0.89\n\n\n\n\n\n\n\nArviZ函数summary计算了均值、标注差和\\(\\theta\\)的94%最高密度区间（HDI）\n也可以通过az.plot_posterior(trace)得到类似的结果。图通过kernel density estimator (KDE)计算生成。\n\naz.plot_posterior(trace)\n\n&lt;Axes: title={'center': 'θ'}&gt;\n\n\n\n\n\nHDI一般选择50%或95%水平，但是ArviZ选择94%。这样的原因是94%跟95%差不多，而且提醒用户95%没什么特别之处。"
  },
  {
    "objectID": "posts/BMCP_1/index.html#要自动推断不要自动建模",
    "href": "posts/BMCP_1/index.html#要自动推断不要自动建模",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "1.3. 要自动推断，不要自动建模",
    "text": "1.3. 要自动推断，不要自动建模\n我们应该拥抱 Probabilistic Programming Languages (PPL) 但不是用scipy.stats自己造轮子。\n有很多工具允许用户贝叶斯建模，并且自动化执行贝叶斯推断。不幸的是Universal Inference Engines并不是真正的universal。现代贝叶斯实践者需要理解并解决这些限制。\n本书中将使用PyMC和TensorFlow Probability。让我们用PyMC对上面的例子建模：\n\nimport pymc as pm\n\n# Declare a model in PyMC\nwith pm.Model() as model:\n    # Specify the prior distribution of unknown parameter\n    θ = pm.Beta(\"θ\", alpha=1, beta=1)\n\n    # Specify the likelihood distribution and condition on the observed data\n    y_obs = pm.Binomial(\"y_obs\", n=1, p=θ, observed=Y)\n\n    # Sample from the posterior distribution\n    idata = pm.sample(2000, return_inferencedata=True)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [θ]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 20 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\n以上代码写起来更加简洁，并且可以通过pm.model_to_graphviz(model)对模型进行可视化。\n\npm.model_to_graphviz(model)\n\n\n\n\nProbabilistic Programming Language不仅能计算后验分布，而且可以模拟各种分布\n\npred_dists = (pm.sample_prior_predictive(2000, model).prior_predictive.y_obs.to_numpy()[0],\n              pm.sample_posterior_predictive(idata, predictions=True, model = model).predictions.y_obs.to_numpy()[0])\n\nSampling: [y_obs, θ]\nSampling: [y_obs]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\nfig, axes = plt.subplots(4, 1, figsize=(9, 9))\n\nplt.subplots_adjust(hspace=1) \n\nfor idx, n_d, dist in zip((1, 3), (\"Prior\", \"Posterior\"), pred_dists):\n    az.plot_dist(dist.sum(1), hist_kwargs={\"color\":\"0.5\", \"bins\":range(0, 22)},\n                                           ax=axes[idx])\n    axes[idx].set_title(f\"{n_d} predictive distribution\",fontweight='bold')\n    axes[idx].set_xlim(-1, 21)\n    axes[idx].set_ylim(0, 0.15)\n    axes[idx].set_xlabel(\"number of success\")\n\naz.plot_dist(pm.draw(θ, 1000), plot_kwargs={\"color\":\"0.5\"},\n             fill_kwargs={'alpha':1}, ax=axes[0])\naxes[0].set_title(\"Prior distribution\", fontweight='bold')\naxes[0].set_xlim(0, 1)\naxes[0].set_ylim(0, 4)\naxes[0].tick_params(axis='both', pad=7)\naxes[0].set_xlabel(\"θ\")\n\naz.plot_dist(idata.posterior[\"θ\"], plot_kwargs={\"color\":\"0.5\"},\n             fill_kwargs={'alpha':1}, ax=axes[2])\naxes[2].set_title(\"Posterior distribution\", fontweight='bold')\naxes[2].set_xlim(0, 1)\naxes[2].set_ylim(0, 5)\naxes[2].tick_params(axis='both', pad=7)\naxes[2].set_xlabel(\"θ\")\n\nText(0.5, 0, 'θ')\n\n\n\n\n\n\nwith model:\n    y_obs_test = pm.Binomial(\"y_obs_new\", n=1, p=idata.posterior[\"θ\"].mean().item(), observed=Y)\n    \ntemp = pm.draw(y_obs_test, 2000)\n\n值得注意的是，后验预测分布依然保留了先验的不确定性，所以对比以后验参数预测均值做参数值产生的预测分布，它会更宽。\n\npredictions = (temp, pred_dists[1])\n\nfor d, c, l in zip(predictions, (\"C0\", \"C4\"), (\"posterior mean\", \"posterior predictive\")):\n    ax = az.plot_dist(d.sum(1),\n                      label=l,\n                      figsize=(10, 5),\n                      hist_kwargs={\"alpha\": 0.5, \"color\":c, \"bins\":range(0, 22)})\n    ax.set_yticks([])\n    ax.set_xlabel(\"number of success\")"
  },
  {
    "objectID": "posts/BMCP_1/index.html#先验的几种选择",
    "href": "posts/BMCP_1/index.html#先验的几种选择",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "1.4. 先验的几种选择",
    "text": "1.4. 先验的几种选择\n必须选择先验分布既是一种负担也是一种福利。从业者了解模型假设并能够灵活地改变它们是有优势的。先验只是假设的一种形式。\n本节讨论几种选择先验分布的常见方法，信息梯度（nformativeness gradient）从不包含任何信息的“白板”到包含尽可能多的信息的高信息量。\n\n1.4.1. 共轭先验\n如果后验分布与先验分布属于同一分布族，则先验与似然共轭。例如似然是泊松分布，先验是伽马分布，那么后验也是伽马分布。\n共轭先验在数学上很方便，不需要复杂的计算，可通过笔和纸完成。现代一般有更好的选择，因为计算几乎允许使用任何先验进行推理，不仅仅包含共轭先验。 但是在学习中和特定场景近实时推断时，它依然很有用。以下对Beta Binomial模型举例：\n如上所述，Binomial分布的共轭先验是Beta分布。我们可以通过以下方式计算后验分布：\n\\[\np(\\theta \\mid Y) \\propto \\overbrace{\\frac{N!}{y!(N-y)!} \\theta^y (1 - \\theta)^{N-y}}^{\\text{binomial-likelihood}} \\: \\overbrace{\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\, \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}^{\\text{beta.prior}}\n\\]\n由于不包含\\(\\theta\\)的项都是常数，因此可以简化为：\n\\[\np(\\theta \\mid Y) \\propto \\overbrace{\\theta^y (1 - \\theta)^{N-y}}^{\\text{binomial-likelihood}} \\: \\overbrace{ \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}^{\\text{beta.prior}}\n\\]\n整理后：\n\\[\np(\\theta \\mid Y) \\propto \\theta^{\\alpha-1+y}(1-\\theta)^{\\beta-1+N-y}\n\\]\n后验分布依然是有效分布，需要添加归一化常数来保证pdf的积分为1。由于上述公式看起来是Beta分布公式里的一部分，因此容易得到后验分布为：\n\\[\np(\\theta \\mid Y) \\propto \\frac{\\Gamma(\\alpha_{post}+\\beta_{post})}{\\Gamma(\\alpha_{post})\\Gamma(\\beta_{post})} \\theta^{\\alpha_{post}-1}(1-\\theta)^{\\beta_{post}-1} = \\text{Beta}(\\alpha_{post}, \\beta_{post})\n\\]\n其中\\(\\alpha_{post} = \\alpha + y\\)，\\(\\beta_{post} = \\beta + N - y\\)\n因为 Beta-Binomial 模型的后验为Beta分布，所以我们可以基于后验分布继续进行推断。这意味着如果我们一次更新前一个数据点或者一次使用整个数据集，我们将得到相同的结果。\n例如下面的例子：\n\nviridish = [(0.2823529411764706, 0.11372549019607843, 0.43529411764705883, 1.0),\n            (0.1450980392156863, 0.6705882352941176, 0.5098039215686274, 1.0),\n            (0.6901960784313725, 0.8666666666666667, 0.1843137254901961, 1.0)]\n\n_, axes = plt.subplots(2,3, sharey=True, sharex=True)\naxes = np.ravel(axes)\n\nn_trials = [0, 1, 2, 3, 12, 180]\nsuccess = [0, 1, 1, 1, 6, 59]\ndata = zip(n_trials, success)\n\nbeta_params = [(0.5, 0.5), (1, 1), (10, 10)]\nθ = np.linspace(0, 1, 1500)\nfor idx, (N, y) in enumerate(data):\n    s_n = (\"s\" if (N &gt; 1) else \"\")\n    for jdx, (a_prior, b_prior) in enumerate(beta_params):\n        p_theta_given_y = stats.beta.pdf(θ, a_prior + y, b_prior + N - y)\n\n        axes[idx].plot(θ, p_theta_given_y, lw=4, color=viridish[jdx])\n        axes[idx].set_yticks([])\n        axes[idx].set_ylim(0, 12)\n        axes[idx].plot(np.divide(y, N), 0, color=\"k\", marker=\"o\", ms=12)\n        axes[idx].set_title(f\"{N:4d} trial{s_n} {y:4d} success\")\n\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/4213617618.py:22: RuntimeWarning: invalid value encountered in divide\n  axes[idx].plot(np.divide(y, N), 0, color=\"k\", marker=\"o\", ms=12)\n\n\n\n\n\n先验的期望为：\n\\[\n\\mathbb{E}[\\theta]  = \\frac{\\alpha}{\\alpha + \\beta}\n\\]\n后验的期望为：\n\\[\n\\mathbb{E}[\\theta \\mid Y]  = \\frac{\\alpha + y}{\\alpha + \\beta + N}\n\\]\n从上可知，当\\(n \\rightarrow \\infty\\)，期望会趋向于\\(\\hat \\theta = \\frac{y}{n}\\)\n后验分布众数：\n\\[\n\\operatorname*{argmax}_{\\theta}{[\\theta \\mid Y]}  = \\frac{\\alpha + y - 1}{\\alpha + \\beta + n - 2}\n\\]\n后验众数常称为maximum a posterior（MAP）。\n\n\n1.4.2. 客观先验\n当没有先验知识时，遵循principle of indifference听起来是合理的。在贝叶斯统计的背景下，这一原理推动了客观先验（objective priors）的研究和使用。这些方法尽量减少对先验对分析结果的影响，即消除“主观性“。当然这并没有消除其他主观性，比如似然函数、数据选择过程、建模选择等等。\n客观先验的一种方法是Jeffreys’ prior (JP)。Jeffreys’ prior（JP）具有在重新参数化下不变的特性，即，以不同但数学上等价的方式写出表达式。\n举例说明：Alice有一个binomial likelihood包含未知参数\\(\\theta\\)，她选择了一个先验并计算得到了后验。Bob对同个问题感兴趣但是他需要的结果是赔率\\(\\kappa\\)，即\\(\\kappa = \\frac{\\theta}{1 - \\theta}\\)。他有两种选择：基于Alice的后验结果\\(\\theta\\)计算\\(\\kappa\\)，或者对\\(\\kappa\\)选择一个先验分布来计算后验。如果使用了JPs，则无论Bob选择哪种方式，他会得到相同的结果。\n一维情况下：\n\\[p(\\theta) \\propto \\sqrt{I(\\theta)}\\]\n其中\\(I(\\theta)\\)是费希尔信息的期望：\n\\[I(\\theta) = - \\mathbb{E_{Y}}\\left[\\frac{d^2}{d\\theta^2} \\log p(Y \\mid \\theta)\\right]\\]\n因此似然函数\\(p(Y \\mid \\theta)\\)选好后，JP就已经确定。\n回到上述例子，对Alice来说JP为：\n\\[p(\\theta) \\propto \\theta^{-0.5} (1-\\theta)^{-0.5}\\]\n对Bob来说JP为：\n\\[p(\\kappa) \\propto \\kappa^{-0.5} (1 + \\kappa)^{-1}\\]\n\nθ = np.linspace(0, 1, 100)\nκ = (θ / (1-θ))\ny = 2\nn = 7\n\n_, axes = plt.subplots(2, 2, figsize=(10, 5),\n                     sharex='col', sharey='row', constrained_layout=False)\n\naxes[0, 0].set_title(\"Jeffreys' prior for Alice\")\naxes[0, 0].plot(θ, θ**(-0.5) * (1-θ)**(-0.5))\naxes[1, 0].set_title(\"Jeffreys' posterior for Alice\")\naxes[1, 0].plot(θ, θ**(y-0.5) * (1-θ)**(n-y-0.5))\naxes[1, 0].set_xlabel(\"θ\")\naxes[0, 1].set_title(\"Jeffreys' prior for Bob\")\naxes[0, 1].plot(κ, κ**(-0.5) * (1 + κ)**(-1))\naxes[1, 1].set_title(\"Jeffreys' posterior for Bob\")\naxes[1, 1].plot(κ, κ**(y-0.5) * (1 + κ)**(-n-1))\naxes[1, 1].set_xlim(-0.5, 10)\naxes[1, 1].set_xlabel(\"κ\")\naxes[1, 1].text(-4.0, 0.030, size=18, s=r'$p(\\theta \\mid Y) \\, \\frac{d\\theta}{d\\kappa}$')\naxes[1, 1].annotate(\"\", xy=(-0.5, 0.025), xytext=(-4.5, 0.025),\n                  arrowprops=dict(facecolor='black', shrink=0.05))\naxes[1, 1].text(-4.0, 0.007, size=18, s= r'$p(\\kappa \\mid Y) \\, \\frac{d\\kappa}{d\\theta}$')\naxes[1, 1].annotate(\"\", xy=(-4.5, 0.015), xytext=(-0.5, 0.015),\n                  arrowprops=dict(facecolor='black', shrink=0.05),\n                  annotation_clip=False)\n\nplt.subplots_adjust(wspace=0.4, hspace=0.4)\nplt.tight_layout()\n\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/1380693406.py:2: RuntimeWarning: divide by zero encountered in divide\n  κ = (θ / (1-θ))\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/1380693406.py:10: RuntimeWarning: divide by zero encountered in power\n  axes[0, 0].plot(θ, θ**(-0.5) * (1-θ)**(-0.5))\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/1380693406.py:15: RuntimeWarning: divide by zero encountered in power\n  axes[0, 1].plot(κ, κ**(-0.5) * (1 + κ)**(-1))\n/var/folders/mf/vz25j9w14ng0kgrg7jz5tc7w0000gn/T/ipykernel_51324/1380693406.py:17: RuntimeWarning: invalid value encountered in multiply\n  axes[1, 1].plot(κ, κ**(y-0.5) * (1 + κ)**(-n-1))\n\n\n\n\n\nJP 可能是Improper prior，这意味着它的积分可能不为 1。\nJPs不是唯一的客观先验方法。比如另一种Bernardo reference priors通过最大化先验与后验的Kullback-Leibler divergence期望来选择。\n\n\n1.4.3. 最大熵先验\n证明先验选择合理性的另一种方法是选择具有最高熵的先验。\n为了得到最大熵先验，我们需要在约束条件下解决最优化问题。数学上称为拉格朗日乘子法。\n\nfrom scipy.optimize import minimize\nfrom scipy.stats import entropy\n\ncons = [[{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1}],\n        [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1},\n         {\"type\": \"eq\", \"fun\": lambda x: 1.5 - np.sum(x * np.arange(1, 7))}],\n        [{\"type\": \"eq\", \"fun\": lambda x: np.sum(x) - 1},\n         {\"type\": \"eq\", \"fun\": lambda x: np.sum(x[[2, 3]]) - 0.8}]]\n\nmax_ent = []\nfor i, c in enumerate(cons):\n    val = minimize(lambda x: -entropy(x), x0=[1/6]*6, bounds=[(0., 1.)] * 6,\n                   constraints=c)['x']\n    max_ent.append(entropy(val))\n    plt.plot(np.arange(1, 7), val, 'o--', color=viridish[i], lw=2.5)\nplt.xlabel(\"$t$\")\nplt.ylabel(\"$p(t)$\")\n\nText(0, 0.5, '$p(t)$')\n\n\n\n\n\n上图是通过最大熵得到的三种分布。紫色分布无约束，它是一个均匀分布；青色分布增加了约束条件，它的均值为1.5，得到了一个类指数分布；最后一个约束条件为已知3和4的出现概率为0.8。\n可以将最大熵理解为对未知分配均等概率的过程。无约束时均匀分布；已知3和4合计出现概率时，对3和4均等分配概率，其它也均等分配概率；类指数分布虽然看起来不均匀，但是已经是此约束下最均匀的分配方式。\n\nite = 100_000\nentropies = np.zeros((3, ite))\nfor idx in range(ite):\n    rnds = np.zeros(6)\n    total = 0\n    x_ = np.random.choice(np.arange(1, 7), size=6, replace=False)\n    for i in x_[:-1]:\n        rnd = np.random.uniform(0, 1-total)\n        rnds[i-1] = rnd\n        total = rnds.sum()\n    rnds[-1] = 1 - rnds[:-1].sum()\n    H = entropy(rnds)\n    entropies[0, idx] = H\n    if abs(1.5 - np.sum(rnds * x_)) &lt; 0.01:\n        entropies[1, idx] = H\n    prob_34 = sum(rnds[np.argwhere((x_ == 3) | (x_ == 4)).ravel()])\n    if abs(0.8 - prob_34) &lt; 0.01:\n        entropies[2, idx] = H\n\n\n_, ax = plt.subplots(1, 3, figsize=(12,4), sharex=True, sharey=True, constrained_layout=True)\n\nfor i in range(3):\n    az.plot_kde(entropies[i][np.nonzero(entropies[i])], ax=ax[i], plot_kwargs={\"color\":viridish[i], \"lw\":4})\n    ax[i].axvline(max_ent[i], 0, 1, ls=\"--\")\n    ax[i].set_yticks([])\n    ax[i].set_xlabel(\"entropy\")\n\n\n\n\n上图是同一份样本下三个分布的熵。看起来没有一个随机生成的分布的熵大于具有最大熵的分布。\n一些约束下的最大熵分布：\n\n无约束：均匀分布\n范围 \\([0, \\infty)\\)，均值为正：指数分布\n范围 \\((-\\infty, \\infty)\\)，且约束条件为均值绝对偏差（即所有观察值与均值的绝对差的平均值）为定值：拉普拉斯分布（也被称为双指数分布）\n范围 \\((-\\infty, \\infty)\\)，已知均值和方差：正态分布\n范围 \\([-\\pi, \\pi]\\)，已知均值和方差：Von Mises\n只有两种无序的结果和一个常数均值：二项分布，或者如果我们有稀有事件，则使用泊松分布（泊松分布可以被视为二项分布的一个特殊情况）\n\n\n\n1.4.4. 弱信息先验和正则化先验\n上面使用通用程序生成模糊的、无信息的先验，旨在不将太多信息放入我们的分析中。这些生成先验的过程还提供了一种“以某种方式”自动生成先验的方法。\n在本书中我们不会过多依赖这些先验。先验启发（与其他建模决策一样）应该依赖于上下文，这意味着特定问题的细节甚至给定科学领域的特质可以影响我们对先验的选择。\n弱信息先验的构成通常不像 JP 或 MaxEnt 那样在数学上得到明确的定义。它们更加注重实证和模型驱动，是通过领域专业知识和模型本身组合定义的。\n\nx = np.linspace(0, 1, 500)\nparams = [(0.5, 0.5), (1, 1), (3,3), (100, 25)]\n\nlabels = [\"Jeffreys\", \"MaxEnt\", \"Weakly  Informative\",\n          \"Informative\"]\n\n_, ax = plt.subplots()\nfor (α, β), label, c in zip(params, labels, (0, 1, 4, 2)):\n    pdf = stats.beta.pdf(x, α, β)\n    ax.plot(x, pdf, label=f\"{label}\", c=f\"C{c}\", lw=3)\n    ax.set(yticks=[], xlabel=\"θ\", title=\"Priors\")\n    ax.legend()\n\n\n\n\n上图是对Beta-Binomial例子的四种先验。前两种是JP和MaxEnt；第三种是弱信息先验，偏好于0.5但是不确定性还是很高；最后一个是信息丰富的先验，主要围绕0.8附近。如果我们从理论、先前的实验、观察数据等中获得了高质量的信息，那么使用信息先验是一个有效的选择，但是“非凡的主张需要非凡的证据”.\n由于弱信息先验可以将后验分布保持在一定的合理范围内，因此它们也称为正则化先验。正则化是一种添加信息的过程，目的是解决不适定问题或减少过度拟合的机会，而先验提供了执行正则化的原则方法。在本书中通常会使用弱信息先验。\n\n\n1.4.5. 使用先验预测分布来评估先验\n先验预测分布是个方便的工具，从观测值思考比从模型参数思考更容易。计算先前的预测可以帮助我们确保我们的模型已正确编写，并且能够在我们的概率编程语言中运行，甚至可以帮助我们调试我们的模型。"
  },
  {
    "objectID": "posts/BMCP_1/index.html#练习",
    "href": "posts/BMCP_1/index.html#练习",
    "title": "【Bayesian Modeling and Computation in Python】1.贝叶斯推断",
    "section": "1.5. 练习",
    "text": "1.5. 练习\n待完善"
  },
  {
    "objectID": "posts/sprt证明/index.html",
    "href": "posts/sprt证明/index.html",
    "title": "SPRT可控制两种错误的证明",
    "section": "",
    "text": "SPRT是在二战中由Wald发明的，最初用于检验炮弹质量。\n如果X1, X2,…是iid的分布为P的随机变量，H0 : P = P0， H1：P= P1\nSPRT抽样数量为：\n\\(N = inf\\{n \\ge 1: R_n \\geq A\\ or\\ R_n \\leq B \\}\\)\n其中A &gt; 1 &gt; B &gt; 0，被称为停止边界，根据α、β选取。\n其中Rn为似然比：\n\\(R_n = \\prod_{i=1}^{n}\\frac{f_1(X_i)}{f_0(X_i)}\\)\nRN &gt;= A时接受H1，RN &lt;= B时接受H0。"
  },
  {
    "objectID": "posts/sprt证明/index.html#sprt简介",
    "href": "posts/sprt证明/index.html#sprt简介",
    "title": "SPRT可控制两种错误的证明",
    "section": "",
    "text": "SPRT是在二战中由Wald发明的，最初用于检验炮弹质量。\n如果X1, X2,…是iid的分布为P的随机变量，H0 : P = P0， H1：P= P1\nSPRT抽样数量为：\n\\(N = inf\\{n \\ge 1: R_n \\geq A\\ or\\ R_n \\leq B \\}\\)\n其中A &gt; 1 &gt; B &gt; 0，被称为停止边界，根据α、β选取。\n其中Rn为似然比：\n\\(R_n = \\prod_{i=1}^{n}\\frac{f_1(X_i)}{f_0(X_i)}\\)\nRN &gt;= A时接受H1，RN &lt;= B时接受H0。"
  },
  {
    "objectID": "posts/sprt证明/index.html#鞅的定义",
    "href": "posts/sprt证明/index.html#鞅的定义",
    "title": "SPRT可控制两种错误的证明",
    "section": "2. 鞅的定义",
    "text": "2. 鞅的定义\n设X和Y是两个随机过程，满足以下条件则过程X是关于Y的鞅。\n若对每个n &gt;=0 :\n(1) E(|Xn|) &lt; 无穷\n(2) Xn是Y0, Y1, … Yn的函数\n(3) E(Xn+1 | Y0,…Yn) = Xn"
  },
  {
    "objectID": "posts/sprt证明/index.html#doobs-martingale-inequality",
    "href": "posts/sprt证明/index.html#doobs-martingale-inequality",
    "title": "SPRT可控制两种错误的证明",
    "section": "3. Doob’s martingale inequality",
    "text": "3. Doob’s martingale inequality\n设{Xn; n &gt;=0} 为鞅或非负下鞅，那么：\n\\(P(\\sup_{0&lt;k&lt;n}|X_k| \\ge C) \\leq \\frac{ E( |X_n|)}{C}\\)"
  },
  {
    "objectID": "posts/sprt证明/index.html#一类错误被控制的证明",
    "href": "posts/sprt证明/index.html#一类错误被控制的证明",
    "title": "SPRT可控制两种错误的证明",
    "section": "4. 一类错误被控制的证明",
    "text": "4. 一类错误被控制的证明\n此时H0为真时，则：\n### (1) 似然比过程是一个鞅 \\(E(R_{1} | X_1) = \\int^{+\\infty}_{{-\\infty}}\\frac{f_1(x_{1})}{f_0(x_{1})}{f_0(x_{1})}dx = 1\\)\n\\(E(R_{n+1} | X_1,..X_n) = E(R_n\\frac{f_1(X_{n + 1})}{f_0(X_{n+1})}) = R_nE(\\frac{f_1(X_{n + 1})}{f_0(X_{n+1})}) = R_n\\int^{+\\infty}_{{-\\infty}}\\frac{f_1(x_{n + 1})}{f_0(x_{n+1})}{f_0(x_{n+1})}dx \\\\= R_n\\)\n### (2) 带入Doob’s martingale inequality \\(P(\\sup_{0&lt;i&lt;n}|R_n| \\ge \\frac{1}{\\alpha}) \\leq \\frac{E(|R_n|)}{\\frac{1}{\\alpha}} = \\alpha\\)\n## 其他 同理也可以证明H1为真时，对二类错误的控制是正确的。\nmSPRT使用分部积分法展开，也可以用类似的过程证明。\nPS：欢迎对ab testing希望知其然知其所以然的朋友私信我，交个朋友以后共同探讨。"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html",
    "href": "posts/实验统计原理简介/index.html",
    "title": "实验统计简介",
    "section": "",
    "text": "两个现实中的问题 - 应用新版本发布7天后，新版用户留存率比老版本用户留存率提升10%，是否说明新版本取得了成功？ - 对商品涨价后，单月收入环比上月提升30%，同比去年提升10%，收入增长了么？赚了多少？\n虽然有了数据，我们仍然很难得到判断，因为我们关注的是因果（反事实）。而随机实验可以观测因果，所以要做实验"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#为什么要做实验",
    "href": "posts/实验统计原理简介/index.html#为什么要做实验",
    "title": "实验统计简介",
    "section": "",
    "text": "两个现实中的问题 - 应用新版本发布7天后，新版用户留存率比老版本用户留存率提升10%，是否说明新版本取得了成功？ - 对商品涨价后，单月收入环比上月提升30%，同比去年提升10%，收入增长了么？赚了多少？\n虽然有了数据，我们仍然很难得到判断，因为我们关注的是因果（反事实）。而随机实验可以观测因果，所以要做实验"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#实验结果可信么",
    "href": "posts/实验统计原理简介/index.html#实验结果可信么",
    "title": "实验统计简介",
    "section": "实验结果可信么？",
    "text": "实验结果可信么？\n我做了AB实验，实验组平均付费比对照组提升了1.1元，我的实验策略是否是有效的？\n由于现实中充满波动性，这个问题很难直接回答。但如果知道事件随机发生概率是多少，我们至少有一些把握\n以最简单的抛硬币为例：\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\ndef binom_plot(n, obs, p=0.5):\n    dist = stats.binom(n, p)\n    x = np.arange(0, n+1)\n    pmf = dist.pmf(x)\n\n    thres = np.abs(np.abs(obs) - n/2)\n    plt.bar(x, pmf, color=['red' if np.abs(np.abs(i) - n/2) &gt;= thres else 'blue' for i in range(len(x))], alpha=0.5)\n    plt.show()\n\n\n一枚硬币扔了10次，其中6次正面，硬币是否均匀？\n如果硬币是均匀的，得到这种情况或者更极端情况的概率是多少：\\[P(投10次6次以上某一面 | 硬币均匀)\\]\n\n\nbinom_plot(10, 6)\n\n\n\n\n\n一枚硬币扔了100次，其中60次正面，它是否均匀？\n\\[P(投100次60次以上某一面 | 硬币均匀)\\]\n\n\nbinom_plot(100, 60)\n\n\n\n\n\n一枚硬币扔了1000次，其中600次正面，它是否均匀？\n\\[P(投1000次600次以上某一面 | 硬币均匀)\\]\n\n\nbinom_plot(1000, 600)\n\n\n\n\n实验也可以用类似的方法计算概率。其中最常用的是基于正态分布来计算：\n由于实验样本量一般较大，分组样本一般满足中心极限定律 &gt; 中心极限定律：\n&gt; 当大量随机变量相互独立时，它们的和或平均值的分布接近于正态分布。\n由此可得： \\[\\bar{X}_A \\sim N(E(X_A), \\sigma^2/cnt_A),\\ \\ \\  \\bar{X}_B \\sim N(E(X_B), \\sigma^2 / cnt_B)\\]\n若实验策略无效，实验组与对照组期望效果相同：\\(E(X_A) = E(X_B)\\)\n根据两个正态分母随机变量相减仍然服从正态分布的性质，则此时： \\[\\bar{X}_A - \\bar{X}_B \\sim N(0, \\sigma^2/cnt_A + \\sigma^2/cnt_B)\\]\n因此可以计算：在实验策略无效的情况下，得到这样的数据或者更极端数据的概率是多少？ —— 此概率越低，则实验策略有效概率越大"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#有了概率后如何决策",
    "href": "posts/实验统计原理简介/index.html#有了概率后如何决策",
    "title": "实验统计简介",
    "section": "有了概率后如何决策？",
    "text": "有了概率后如何决策？\n自然发生概率越低，实验策略有效概率越大。我们应该怎么基于这个数值进行决策？\n真相只有一个，但有两种可能，随之会导致两种决策错误：\n- 假阳性。实验策略无效，被误认为有效，类比于没得新冠检验阳性\n- 假阴性。实验策略有效，被误认为无效，类比于得了新冠检验阴性\n只要控制住这两种错误发生的概率，决策就是可靠且风险成承受的\n\n如何选取阈值要基于业务场景：\n- 互联网业务下，一般冒然变更风险大于收益，更看重于控制假阳性。最常见的阈值是：假阳性控制在0.05以内，假阴性控制在0.2以内；\n- 生命只有一次，医院检查中更看重控制假阴性。"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#假阳性如何控制",
    "href": "posts/实验统计原理简介/index.html#假阳性如何控制",
    "title": "实验统计简介",
    "section": "假阳性如何控制",
    "text": "假阳性如何控制\n由于没有效果时期望为0，即\\(E(\\bar{X}_A - \\bar{X}_B) = 0\\)，假阳性是很容易控制的\n假设我们对无效的实验做了100w次，并且根据假阳性0.05选择阈值，模拟可以得到下面的结果：\n\ndef h0_simulation(alpha = 0.05, trans = 0.5, ax=None, std_err = 1):\n    norm_sample = np.random.normal(0, std_err, 1000000)\n    if ax:\n        _, bins, patches = ax.hist(norm_sample, bins=1000, alpha=trans);\n    else:\n        _, bins, patches = plt.hist(norm_sample, bins=1000, alpha=trans);\n    for index, bin in enumerate(bins):\n        if index &gt;= len(patches):\n            break\n        if -np.abs(bin) &lt;= stats.norm.ppf(alpha / 2) * std_err:\n            patches[index].set_facecolor('red')\n        else:\n            patches[index].set_facecolor('blue')\n    return norm_sample\n\nnorm_sample = h0_simulation()\n\n\n\n\n对每个情况计算起随机产生的概率值（pValue），它的分布如下：\n\ndef p_calculator(norm_sample, alpha=0.05):\n    p_values = stats.norm.cdf(-np.abs(norm_sample)) * 2\n    # counts, bins = np.histogram(p_values, bins=100)\n    _, bins, patches = plt.hist(p_values, bins=100,alpha=0.5);\n    for i in range(int(100 * alpha + 1)):\n        patches[i].set_facecolor('red')\n    for i in range(int(100 * alpha + 1), len(patches)):\n        patches[i].set_facecolor('blue')\n    return p_values\n\np_values = p_calculator(norm_sample)\n\n\n\n\n由于实验无效，每次判断都是误判。\n统计我们决策错误的频率，会发现基本等于我们的控制目标0.05。 统计下频率：\n\n(p_values &lt;= 0.05).mean()\n\n0.050165"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#假阴性控制",
    "href": "posts/实验统计原理简介/index.html#假阴性控制",
    "title": "实验统计简介",
    "section": "假阴性控制",
    "text": "假阴性控制\n假设实验策略有效：\\(\\Delta = E(\\bar{X}_A - \\bar{X}_B)\\) 依据为控制假阳性所选取的阈值，范假阴性错误的几率是多少？\n\nh0_sample = h0_simulation(trans=0.4)\n\ndef h1_simulation(h0_sample, delta = 1, alpha = 0.05, ax=None, std_err=1):\n    h1_sample = h0_sample + delta\n    if ax:\n        _, bins, patches = ax.hist(h1_sample, bins=1000, alpha=0.5);\n    else:\n        _, bins, patches = plt.hist(h1_sample, bins=1000, alpha=0.5);\n    for index, bin in enumerate(bins):\n        if index &gt;= len(patches):\n            break\n        if bin &gt;= stats.norm.ppf(1 - alpha / 2) * std_err:\n            patches[index].set_facecolor('blue')\n        else:\n            patches[index].set_facecolor('red')\n\n    return h1_sample\n\nh1_simulation(h0_sample);\n\n\n\n\n要降低假阴性，我们可以怎么做？ - 尽量增大实验效果，增大两峰之间距离 —— 这与创意质量相关，实验无法影响\n\n_, axs = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n\nh0_sample = h0_simulation(trans=0.4, ax=axs[0])\nh1_simulation(h0_sample, ax=axs[0]);\n\nh0_sample = h0_simulation(trans=0.4, ax=axs[1])\nh1_simulation(h0_sample, delta=2 ,ax=axs[1]);\n\n\n\n\n\n降低假阳性的要求 —— 有时实验常常取0.1做为阈值\n\n\n_, axs = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n\nh0_sample = h0_simulation(trans=0.4, ax=axs[0])\nh1_simulation(h0_sample, ax=axs[0]);\n\nh0_sample = h0_simulation(trans=0.4, alpha=0.1, ax=axs[1])\nh1_simulation(h0_sample, alpha=0.1, ax=axs[1]);\n\n\n\n\n\n减少结果波动性（降低标准误），让分布变得更加「高瘦」—— 这是实验可以改善的\n\n\n_, axs = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n\nh0_sample = h0_simulation(trans=0.4, ax=axs[0])\nh1_simulation(h0_sample, ax=axs[0]);\n\nh0_sample = h0_simulation(trans=0.4, std_err=0.5, ax=axs[1])\nh1_simulation(h0_sample, std_err=0.5, ax=axs[1]);\n\n\n\n\n降低波动是控制检出率的关键。减少波动方法：\n- 增加样本量 —— 最常用方案，通过增加数量减小标准误\n- 处理离群值 —— 减少极值影响，通过降低样本方差减小标准误\n- 降噪算法 —— 控制变量法等"
  },
  {
    "objectID": "posts/实验统计原理简介/index.html#控制假阴性需要多少流量",
    "href": "posts/实验统计原理简介/index.html#控制假阴性需要多少流量",
    "title": "实验统计简介",
    "section": "控制假阴性需要多少流量?",
    "text": "控制假阴性需要多少流量?\n以上可知，假阴性与「真实效果」、「假阳性水平」、「样本方差」、「样本量」等因素相关，那么多大的样本量可以控制假阴性呢？\n\\[样本量 = f(真实效果,假阴性水平,假阳性水平, 流量分配比例, 样本方差)\\]\n其中入参中真实效果是未知的，导致无法直接计算，该如何解决？\n解决方案是引入最小检测效果（Minimum Detectable Effect）。基于此值计算样本量，可保证实验效果大于等于此值时「假阴性」符合标准\n控制假阴性是为了保证检出率，检出率定义为「功效（power）」：\\[功效 = 1 - 假阴性控制水平\\] 分析达到目标功效需要多少流量，称为功效分析\n以双尾等流量实验为例：\n\n定义假阳性控制目标为\\(\\alpha\\)，等流量双尾检验下，控制power需要满足条件： \\[ \\frac{MDE}{\\sqrt{(\\sigma^2 / n + \\sigma^2 / n)}} \\geq \\phi^{-1}(1 - \\alpha / 2) + \\phi^{-1}(power) \\]\n其中\\(\\phi^{-1}\\)是正态分布的逆累积分布函数，由上可推出：\\[n \\geq 2\\sigma ^{2} [ \\phi^{-1} (1 - \\alpha/2) + \\phi^{-1} (power )]^{2}/MDE^2\\]\n以mde = 1, alpha = 0.05, power = 0.8, var = 100计算需要样本量，按此样本量仿真100w次，结果如下：\n\nmde = 1\nalpha = 0.05\npower = 0.8\nvar = 100\n\nn = int(2 * var * (stats.norm.ppf(1 - alpha / 2) + stats.norm.ppf(power)) ** 2 / mde ** 2)\nstd_err = np.sqrt(var / n * 2)\n\nh0_sample = h0_simulation(trans=0.4, std_err=std_err)\nh1_sample = h1_simulation(h0_sample, std_err=std_err)\n\n\n\n\n\np_values = stats.norm.cdf(-np.abs(h1_sample) / std_err) * 2\nN, bins, patches = plt.hist(p_values, bins=100,alpha=0.5);\nfor i in range(11):\n    patches[i].set_facecolor('blue')\nfor i in range(11, len(patches)):\n    patches[i].set_facecolor('red')\n\n\n\n\n统计一下：\n\n(p_values &lt;= 0.05).mean()\n\n0.800013"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "学习 & 思考",
    "section": "",
    "text": "【Bayesian Modeling and Computation in Python】5.样条曲线 Splines\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2024\n\n\n\n\n\n\n  \n\n\n\n\n【Bayesian Modeling and Computation in Python】4.拓展线性模型\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2024\n\n\n\n\n\n\n  \n\n\n\n\n【Bayesian Modeling and Computation in Python】3.线性模型和概率编程语言\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2024\n\n\n\n\n\n\n  \n\n\n\n\n什么是高斯过程\n\n\n\n\n\n\n\n随机过程\n\n\n\n\n\n\n\n\n\n\n\nJan 4, 2024\n\n\n\n\n\n\n  \n\n\n\n\n【Bayesian Modeling and Computation in Python】11.相关主题\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2023\n\n\n\n\n\n\n  \n\n\n\n\n【Bayesian Modeling and Computation in Python】2.贝叶斯模型探索分析\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\n【Bayesian Modeling and Computation in Python】1.贝叶斯推断\n\n\n\n\n\n\n\n读书摘录\n\n\n贝叶斯建模\n\n\nBayesian Modeling and Computation in Python\n\n\n贝叶斯\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2023\n\n\n\n\n\n\n  \n\n\n\n\n实验间共享对照组缺陷及对策\n\n\n\n\n\n\n\nAB\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\n实验统计简介\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\n流量分配与决策优化\n\n\n\n\n\n\n\nAB\n\n\n实验设计\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2022\n\n\n\n\n\n\n  \n\n\n\n\nSPRT可控制两种错误的证明\n\n\n\n\n\n\n\nAB\n\n\n序贯检验\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2021\n\n\n\n\n\n\n  \n\n\n\n\nSQR：平衡实验速度、质量和风险的框架\n\n\n\n\n\n\n\nAB\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\n贝叶斯和多臂老虎机\n\n\n\n\n\n\n\n贝叶斯\n\n\n多臂老虎机\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\n因果推断：准实验法评估App新版本增益\n\n\n\n\n\n\n\n因果推断\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2021\n\n\n\n\n\n\n  \n\n\n\n\n荟萃分析简介\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2021\n\n\n\n\n\n\n  \n\n\n\n\n双样本经验贝叶斯检验\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n贝叶斯\n\n\n序贯检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2021\n\n\n\n\n\n\n  \n\n\n\n\n成组序贯检验：alpha消耗函数法\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n序贯检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2021\n\n\n\n\n\n\n  \n\n\n\n\nab实验与Delta方法\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nJan 16, 2021\n\n\n\n\n\n\n  \n\n\n\n\n如何评估假设检验的好坏\n\n\n\n\n\n\n\nAB\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\n赌徒破产和序贯检验\n\n\n\n\n\n\n\nAB\n\n\n序贯检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2020\n\n\n\n\n\n\n  \n\n\n\n\nA/B实验进阶：通过实验前数据减小方差（CUPED）\n\n\n\n\n\n\n\nAB\n\n\n方差缩减\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\n多重检验控制策略：FWER/FDR/FCR\n\n\n\n\n\n\n\nAB\n\n\n多重检验\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nPeeking at A/B test：mSPRT简介\n\n\n\n\n\n\n\nAB\n\n\n序贯检验\n\n\n假设检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nA/B实验设计：偷看问题\n\n\n\n\n\n\n\nAB\n\n\n实验设计\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2020\n\n\n\n\n\n\n  \n\n\n\n\nA/B实验设计：多重检验\n\n\n\n\n\n\n\nAB\n\n\n实验设计\n\n\n多重检验\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2020\n\n\n\n\n\n\n  \n\n\n\n\nA/B实验设计：样本量计算\n\n\n\n\n\n\n\nAB\n\n\n实验设计\n\n\n旧文迁移\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2020\n\n\n\n\n\n\nNo matching items"
  }
]